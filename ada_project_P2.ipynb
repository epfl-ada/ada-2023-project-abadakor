{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)  # Display all columns without truncation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_df :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>free_ID</th>\n",
       "      <th>mov_name</th>\n",
       "      <th>release</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>languages</th>\n",
       "      <th>countries</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3196793</td>\n",
       "      <td>/m/08yl5d</td>\n",
       "      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n",
       "      <td>2000-02-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28463795</td>\n",
       "      <td>/m/0crgdbh</td>\n",
       "      <td>Brun bitter</td>\n",
       "      <td>1988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>{\"/m/05f_3\": \"Norwegian Language\"}</td>\n",
       "      <td>{\"/m/05b4w\": \"Norway\"}</td>\n",
       "      <td>{\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9363483</td>\n",
       "      <td>/m/0285_cd</td>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/07ssc\": \"United Kingdom\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261236</td>\n",
       "      <td>/m/01mrr1</td>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>1983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>{\"/m/04306rv\": \"German Language\"}</td>\n",
       "      <td>{\"/m/0345h\": \"Germany\"}</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wiki_ID     free_ID                                           mov_name  \\\n",
       "0    975900   /m/03vyhn                                     Ghosts of Mars   \n",
       "1   3196793   /m/08yl5d  Getting Away with Murder: The JonBenét Ramsey ...   \n",
       "2  28463795  /m/0crgdbh                                        Brun bitter   \n",
       "3   9363483  /m/0285_cd                                   White Of The Eye   \n",
       "4    261236   /m/01mrr1                                  A Woman in Flames   \n",
       "\n",
       "      release     revenue  runtime                           languages  \\\n",
       "0  2001-08-24  14010832.0     98.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "1  2000-02-16         NaN     95.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "2        1988         NaN     83.0  {\"/m/05f_3\": \"Norwegian Language\"}   \n",
       "3        1987         NaN    110.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "4        1983         NaN    106.0   {\"/m/04306rv\": \"German Language\"}   \n",
       "\n",
       "                                   countries  \\\n",
       "0  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "1  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "2                     {\"/m/05b4w\": \"Norway\"}   \n",
       "3             {\"/m/07ssc\": \"United Kingdom\"}   \n",
       "4                    {\"/m/0345h\": \"Germany\"}   \n",
       "\n",
       "                                              genres  \n",
       "0  {\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...  \n",
       "1  {\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...  \n",
       "2  {\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...  \n",
       "3  {\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...  \n",
       "4                            {\"/m/07s9rl0\": \"Drama\"}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "character_df :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>char_name</th>\n",
       "      <th>free_ID</th>\n",
       "      <th>release</th>\n",
       "      <th>DOB</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>act_name</th>\n",
       "      <th>age_at_release</th>\n",
       "      <th>free_char_map1</th>\n",
       "      <th>free_char_map2</th>\n",
       "      <th>free_char_map3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>Akooshay</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "      <td>42.0</td>\n",
       "      <td>/m/0bgchxw</td>\n",
       "      <td>/m/0bgcj3x</td>\n",
       "      <td>/m/03wcfv7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975900</td>\n",
       "      <td>Lieutenant Melanie Ballard</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.780</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0jys3m</td>\n",
       "      <td>/m/0bgchn4</td>\n",
       "      <td>/m/0346l4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>975900</td>\n",
       "      <td>Desolation Williams</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>1969-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>1.727</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>Ice Cube</td>\n",
       "      <td>32.0</td>\n",
       "      <td>/m/0jys3g</td>\n",
       "      <td>/m/0bgchn_</td>\n",
       "      <td>/m/01vw26l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>975900</td>\n",
       "      <td>Sgt Jericho Butler</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>33.0</td>\n",
       "      <td>/m/02vchl6</td>\n",
       "      <td>/m/0bgchnq</td>\n",
       "      <td>/m/034hyc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975900</td>\n",
       "      <td>Bashira Kincaid</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>1977-09-25</td>\n",
       "      <td>F</td>\n",
       "      <td>1.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clea DuVall</td>\n",
       "      <td>23.0</td>\n",
       "      <td>/m/02vbb3r</td>\n",
       "      <td>/m/0bgchp9</td>\n",
       "      <td>/m/01y9xg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wiki_ID                   char_name    free_ID     release         DOB  \\\n",
       "0   975900                    Akooshay  /m/03vyhn  2001-08-24  1958-08-26   \n",
       "1   975900  Lieutenant Melanie Ballard  /m/03vyhn  2001-08-24  1974-08-15   \n",
       "2   975900         Desolation Williams  /m/03vyhn  2001-08-24  1969-06-15   \n",
       "3   975900          Sgt Jericho Butler  /m/03vyhn  2001-08-24  1967-09-12   \n",
       "4   975900             Bashira Kincaid  /m/03vyhn  2001-08-24  1977-09-25   \n",
       "\n",
       "  gender  height   ethnicity            act_name  age_at_release  \\\n",
       "0      F   1.620         NaN      Wanda De Jesus            42.0   \n",
       "1      F   1.780  /m/044038p  Natasha Henstridge            27.0   \n",
       "2      M   1.727     /m/0x67            Ice Cube            32.0   \n",
       "3      M   1.750         NaN       Jason Statham            33.0   \n",
       "4      F   1.650         NaN         Clea DuVall            23.0   \n",
       "\n",
       "  free_char_map1 free_char_map2 free_char_map3  \n",
       "0     /m/0bgchxw     /m/0bgcj3x     /m/03wcfv7  \n",
       "1      /m/0jys3m     /m/0bgchn4      /m/0346l4  \n",
       "2      /m/0jys3g     /m/0bgchn_     /m/01vw26l  \n",
       "3     /m/02vchl6     /m/0bgchnq      /m/034hyc  \n",
       "4     /m/02vbb3r     /m/0bgchp9      /m/01y9xg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_by_movie_df :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>char_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>Lieutenant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7668793</td>\n",
       "      <td>Lieutenant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24226493</td>\n",
       "      <td>Lieutenant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3388805</td>\n",
       "      <td>Lieutenant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8231713</td>\n",
       "      <td>Lieutenant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wiki_ID  char_words\n",
       "0    975900  Lieutenant\n",
       "1   7668793  Lieutenant\n",
       "2  24226493  Lieutenant\n",
       "3   3388805  Lieutenant\n",
       "4   8231713  Lieutenant"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder_processed_data_path = './data/processed_data/'\n",
    "\n",
    "movie_df = pd.read_csv(os.path.join(folder_processed_data_path, 'movie_df.csv'))\n",
    "character_df = pd.read_csv(os.path.join(folder_processed_data_path, 'character_df.csv'))\n",
    "name_by_movie_df = pd.read_csv(os.path.join(folder_processed_data_path, 'name_by_movie_df.csv'))\n",
    "\n",
    "print(\"movie_df :\")\n",
    "display(movie_df.head())\n",
    "print(\"character_df :\")\n",
    "display(character_df.head())\n",
    "print(\"name_by_movie_df :\")\n",
    "display(name_by_movie_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets check the data for a specific popular movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chosen movie : The Shawshank Redemption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useless I think"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Summaries Data :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "plot_summaries_path = 'MovieSummaries\\\\plot_summaries.txt'\n",
    "plot_summaries_data = pd.read_csv(plot_summaries_path, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column names deduced from README\n",
    "plot_summaries_data.columns = ['wiki_ID', 'summary']\n",
    "\n",
    "display(plot_summaries_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core NLP Summaries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Specify the folder containing the compressed .gz files\n",
    "folder_path = './MovieSummaries/corenlp_plot_summaries/'\n",
    "\n",
    "# Create a list to store the parsed XML data\n",
    "xml_data = []\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.gz'):\n",
    "        gz_file_path = os.path.join(folder_path, file_name)\n",
    "        with gzip.open(gz_file_path, 'rt') as xml_file:\n",
    "            xml_content = xml_file.read()\n",
    "            root = ET.fromstring(xml_content)\n",
    "            xml_data.append(root)\n",
    "\n",
    "# Now you should have the parsed XML data in the `xml_data` list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Specify the folder containing the compressed .gz files\n",
    "folder_path = './MovieSummaries/corenlp_plot_summaries/'\n",
    "\n",
    "# Create a list to store the parsed XML data\n",
    "xml_data = []\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    print(f\"file_name = {file_name}\")\n",
    "    if file_name.endswith('.gz'):\n",
    "        gz_file_path = os.path.join(folder_path, file_name)\n",
    "        with gzip.open(gz_file_path, 'rt') as xml_file:\n",
    "            xml_content = xml_file.read()\n",
    "            root = ET.fromstring(xml_content)\n",
    "            xml_data.append(root)\n",
    "\n",
    "# Combine all the parsed XML data into a single XML element\n",
    "combined_root = ET.Element(\"root\")  # Create a new root element\n",
    "\n",
    "for xml_element in xml_data:\n",
    "    combined_root.append(xml_element)\n",
    "\n",
    "# Create an ElementTree from the combined XML data\n",
    "combined_tree = ET.ElementTree(combined_root)\n",
    "\n",
    "# Define the output file path for the combined XML\n",
    "output_xml_file = 'combined_data.xml'\n",
    "\n",
    "# Write the combined XML data to the output file\n",
    "combined_tree.write(output_xml_file)\n",
    "\n",
    "print(f\"Combined XML data saved to {output_xml_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Metadata :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "character_metadata_path = 'MovieSummaries\\\\character.metadata.tsv'\n",
    "character_metadata_data = pd.read_csv(character_metadata_path, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column names deduced from README\n",
    "character_metadata_data.columns = ['wiki_ID', 'free_ID', 'release', 'char_name', 'DOB', 'gender', 'height', 'ethnicity', 'act_name', 'age_at_release', 'free_char_map1', 'free_char_map2', 'free_char_map3']\n",
    "\n",
    "display(character_metadata_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Metadata :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "movie_metadata_path = 'MovieSummaries\\\\movie.metadata.tsv'\n",
    "movie_metadata_data = pd.read_csv(movie_metadata_path, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column names deduced from README\n",
    "movie_metadata_data.columns = ['wiki_ID', 'free_ID', 'mov_name', 'release', 'revenue', 'runtime', 'languages', 'countries', 'genres']\n",
    "\n",
    "display(movie_metadata_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Clusters Test Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "name_clusters_path = 'MovieSummaries\\\\name.clusters.txt'\n",
    "name_clusters_data = pd.read_csv(name_clusters_path, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(name_clusters_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVTropes Clusters Test Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "tvtropes_clusters_path = 'MovieSummaries\\\\tvtropes.clusters.txt'\n",
    "tvtropes_clusters_data = pd.read_csv(tvtropes_clusters_path, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tvtropes_clusters_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
