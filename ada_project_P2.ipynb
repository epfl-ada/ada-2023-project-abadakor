{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)  # Display all columns without truncation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the indexing unique in movie_df ? True\n",
      "Is the indexing unique in character_df ? True\n",
      "Is the indexing unique in name_by_movie_df ? True\n",
      "Is the indexing unique in baby_name_df ? True\n",
      "movie_df :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>free_ID</th>\n",
       "      <th>mov_name</th>\n",
       "      <th>release</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>languages</th>\n",
       "      <th>countries</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>975900</th>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196793</th>\n",
       "      <td>/m/08yl5d</td>\n",
       "      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n",
       "      <td>2000-02-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28463795</th>\n",
       "      <td>/m/0crgdbh</td>\n",
       "      <td>Brun bitter</td>\n",
       "      <td>1988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>{\"/m/05f_3\": \"Norwegian Language\"}</td>\n",
       "      <td>{\"/m/05b4w\": \"Norway\"}</td>\n",
       "      <td>{\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9363483</th>\n",
       "      <td>/m/0285_cd</td>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/07ssc\": \"United Kingdom\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261236</th>\n",
       "      <td>/m/01mrr1</td>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>1983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>{\"/m/04306rv\": \"German Language\"}</td>\n",
       "      <td>{\"/m/0345h\": \"Germany\"}</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             free_ID                                           mov_name  \\\n",
       "wiki_ID                                                                   \n",
       "975900     /m/03vyhn                                     Ghosts of Mars   \n",
       "3196793    /m/08yl5d  Getting Away with Murder: The JonBenét Ramsey ...   \n",
       "28463795  /m/0crgdbh                                        Brun bitter   \n",
       "9363483   /m/0285_cd                                   White Of The Eye   \n",
       "261236     /m/01mrr1                                  A Woman in Flames   \n",
       "\n",
       "             release     revenue  runtime                           languages  \\\n",
       "wiki_ID                                                                         \n",
       "975900    2001-08-24  14010832.0     98.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "3196793   2000-02-16         NaN     95.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "28463795        1988         NaN     83.0  {\"/m/05f_3\": \"Norwegian Language\"}   \n",
       "9363483         1987         NaN    110.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "261236          1983         NaN    106.0   {\"/m/04306rv\": \"German Language\"}   \n",
       "\n",
       "                                          countries  \\\n",
       "wiki_ID                                               \n",
       "975900    {\"/m/09c7w0\": \"United States of America\"}   \n",
       "3196793   {\"/m/09c7w0\": \"United States of America\"}   \n",
       "28463795                     {\"/m/05b4w\": \"Norway\"}   \n",
       "9363483              {\"/m/07ssc\": \"United Kingdom\"}   \n",
       "261236                      {\"/m/0345h\": \"Germany\"}   \n",
       "\n",
       "                                                     genres  \n",
       "wiki_ID                                                      \n",
       "975900    {\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...  \n",
       "3196793   {\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...  \n",
       "28463795  {\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...  \n",
       "9363483   {\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...  \n",
       "261236                              {\"/m/07s9rl0\": \"Drama\"}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "character_df :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>free_ID</th>\n",
       "      <th>release</th>\n",
       "      <th>DOB</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>act_name</th>\n",
       "      <th>age_at_release</th>\n",
       "      <th>free_char_map1</th>\n",
       "      <th>free_char_map2</th>\n",
       "      <th>free_char_map3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>char_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">975900</th>\n",
       "      <th>Akooshay</th>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "      <td>42.0</td>\n",
       "      <td>/m/0bgchxw</td>\n",
       "      <td>/m/0bgcj3x</td>\n",
       "      <td>/m/03wcfv7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lieutenant Melanie Ballard</th>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.780</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0jys3m</td>\n",
       "      <td>/m/0bgchn4</td>\n",
       "      <td>/m/0346l4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Desolation Williams</th>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>1969-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>1.727</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>Ice Cube</td>\n",
       "      <td>32.0</td>\n",
       "      <td>/m/0jys3g</td>\n",
       "      <td>/m/0bgchn_</td>\n",
       "      <td>/m/01vw26l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sgt Jericho Butler</th>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>33.0</td>\n",
       "      <td>/m/02vchl6</td>\n",
       "      <td>/m/0bgchnq</td>\n",
       "      <td>/m/034hyc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bashira Kincaid</th>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>1977-09-25</td>\n",
       "      <td>F</td>\n",
       "      <td>1.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clea DuVall</td>\n",
       "      <td>23.0</td>\n",
       "      <td>/m/02vbb3r</td>\n",
       "      <td>/m/0bgchp9</td>\n",
       "      <td>/m/01y9xg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      free_ID     release         DOB gender  \\\n",
       "wiki_ID char_name                                                              \n",
       "975900  Akooshay                    /m/03vyhn  2001-08-24  1958-08-26      F   \n",
       "        Lieutenant Melanie Ballard  /m/03vyhn  2001-08-24  1974-08-15      F   \n",
       "        Desolation Williams         /m/03vyhn  2001-08-24  1969-06-15      M   \n",
       "        Sgt Jericho Butler          /m/03vyhn  2001-08-24  1967-09-12      M   \n",
       "        Bashira Kincaid             /m/03vyhn  2001-08-24  1977-09-25      F   \n",
       "\n",
       "                                    height   ethnicity            act_name  \\\n",
       "wiki_ID char_name                                                            \n",
       "975900  Akooshay                     1.620         NaN      Wanda De Jesus   \n",
       "        Lieutenant Melanie Ballard   1.780  /m/044038p  Natasha Henstridge   \n",
       "        Desolation Williams          1.727     /m/0x67            Ice Cube   \n",
       "        Sgt Jericho Butler           1.750         NaN       Jason Statham   \n",
       "        Bashira Kincaid              1.650         NaN         Clea DuVall   \n",
       "\n",
       "                                    age_at_release free_char_map1  \\\n",
       "wiki_ID char_name                                                   \n",
       "975900  Akooshay                              42.0     /m/0bgchxw   \n",
       "        Lieutenant Melanie Ballard            27.0      /m/0jys3m   \n",
       "        Desolation Williams                   32.0      /m/0jys3g   \n",
       "        Sgt Jericho Butler                    33.0     /m/02vchl6   \n",
       "        Bashira Kincaid                       23.0     /m/02vbb3r   \n",
       "\n",
       "                                   free_char_map2 free_char_map3  \n",
       "wiki_ID char_name                                                 \n",
       "975900  Akooshay                       /m/0bgcj3x     /m/03wcfv7  \n",
       "        Lieutenant Melanie Ballard     /m/0bgchn4      /m/0346l4  \n",
       "        Desolation Williams            /m/0bgchn_     /m/01vw26l  \n",
       "        Sgt Jericho Butler             /m/0bgchnq      /m/034hyc  \n",
       "        Bashira Kincaid                /m/0bgchp9      /m/01y9xg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_by_movie_df :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>char_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>975900</th>\n",
       "      <th>Lieutenant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7668793</th>\n",
       "      <th>Lieutenant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24226493</th>\n",
       "      <th>Lieutenant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388805</th>\n",
       "      <th>Lieutenant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8231713</th>\n",
       "      <th>Lieutenant</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [(975900, Lieutenant), (7668793, Lieutenant), (24226493, Lieutenant), (3388805, Lieutenant), (8231713, Lieutenant)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baby_name_df :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mary</th>\n",
       "      <th>F</th>\n",
       "      <th>1880</th>\n",
       "      <td>7065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anna</th>\n",
       "      <th>F</th>\n",
       "      <th>1880</th>\n",
       "      <td>2604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emma</th>\n",
       "      <th>F</th>\n",
       "      <th>1880</th>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elizabeth</th>\n",
       "      <th>F</th>\n",
       "      <th>1880</th>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnie</th>\n",
       "      <th>F</th>\n",
       "      <th>1880</th>\n",
       "      <td>1746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       number\n",
       "name      gender year        \n",
       "Mary      F      1880    7065\n",
       "Anna      F      1880    2604\n",
       "Emma      F      1880    2003\n",
       "Elizabeth F      1880    1939\n",
       "Minnie    F      1880    1746"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder_processed_data_path = './data/processed_data/'\n",
    "\n",
    "movie_df = pd.read_csv(os.path.join(folder_processed_data_path, 'movie_df.csv'))\n",
    "movie_df.set_index(['wiki_ID'], inplace=True)\n",
    "# Verify the indexes are unique\n",
    "print(f\"Is the indexing unique in movie_df ? {movie_df.index.is_unique}\")\n",
    "\n",
    "character_df = pd.read_csv(os.path.join(folder_processed_data_path, 'character_df.csv'))\n",
    "character_df.set_index(['wiki_ID', 'char_name'], inplace=True)\n",
    "# Verify the indexes are unique\n",
    "print(f\"Is the indexing unique in character_df ? {character_df.index.is_unique}\")\n",
    "\n",
    "name_by_movie_df = pd.read_csv(os.path.join(folder_processed_data_path, 'name_by_movie_df.csv'))\n",
    "name_by_movie_df.set_index(['wiki_ID', 'char_words'], inplace=True)\n",
    "# Verify the indexes are unique\n",
    "print(f\"Is the indexing unique in name_by_movie_df ? {name_by_movie_df.index.is_unique}\")\n",
    "\n",
    "baby_name_df = pd.read_csv(os.path.join(folder_processed_data_path, 'baby_name_df.csv'))\n",
    "baby_name_df.set_index(['name', 'gender', 'year'], inplace=True)\n",
    "# Verify the indexes are unique\n",
    "print(f\"Is the indexing unique in baby_name_df ? {baby_name_df.index.is_unique}\")\n",
    "\n",
    "print(\"movie_df :\")\n",
    "display(movie_df.head())\n",
    "print(\"character_df :\")\n",
    "display(character_df.head())\n",
    "print(\"name_by_movie_df :\")\n",
    "display(name_by_movie_df.head())\n",
    "print(\"baby_name_df :\")\n",
    "display(baby_name_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets check the data for a specific popular movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chosen movie : The Shawshank Redemption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30625\n",
      "['Captain' 'Andy' 'Brooks' 'Tommy' 'Boyd' 'Ellis' 'Warden' 'Norton'\n",
      " 'Ernie' 'Diamond' 'Hadley' 'Floyd' 'Heywood' 'Redding' 'Skeet' 'Mert']\n"
     ]
    }
   ],
   "source": [
    "chosen_movie_name = 'The Shawshank Redemption'\n",
    "chosen_movie_ID = movie_df.query('mov_name == @chosen_movie_name').index.values[0]\n",
    "print(chosen_movie_ID)\n",
    "chosen_movie_names = name_by_movie_df.loc[chosen_movie_ID].index.values\n",
    "print(chosen_movie_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = baby_name_df[1]\n",
    "baby_name_df[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useless I think"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Summaries Data :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "plot_summaries_path = 'MovieSummaries\\\\plot_summaries.txt'\n",
    "plot_summaries_data = pd.read_csv(plot_summaries_path, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column names deduced from README\n",
    "plot_summaries_data.columns = ['wiki_ID', 'summary']\n",
    "\n",
    "display(plot_summaries_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core NLP Summaries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Specify the folder containing the compressed .gz files\n",
    "folder_path = './MovieSummaries/corenlp_plot_summaries/'\n",
    "\n",
    "# Create a list to store the parsed XML data\n",
    "xml_data = []\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.gz'):\n",
    "        gz_file_path = os.path.join(folder_path, file_name)\n",
    "        with gzip.open(gz_file_path, 'rt') as xml_file:\n",
    "            xml_content = xml_file.read()\n",
    "            root = ET.fromstring(xml_content)\n",
    "            xml_data.append(root)\n",
    "\n",
    "# Now you should have the parsed XML data in the `xml_data` list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Specify the folder containing the compressed .gz files\n",
    "folder_path = './MovieSummaries/corenlp_plot_summaries/'\n",
    "\n",
    "# Create a list to store the parsed XML data\n",
    "xml_data = []\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    print(f\"file_name = {file_name}\")\n",
    "    if file_name.endswith('.gz'):\n",
    "        gz_file_path = os.path.join(folder_path, file_name)\n",
    "        with gzip.open(gz_file_path, 'rt') as xml_file:\n",
    "            xml_content = xml_file.read()\n",
    "            root = ET.fromstring(xml_content)\n",
    "            xml_data.append(root)\n",
    "\n",
    "# Combine all the parsed XML data into a single XML element\n",
    "combined_root = ET.Element(\"root\")  # Create a new root element\n",
    "\n",
    "for xml_element in xml_data:\n",
    "    combined_root.append(xml_element)\n",
    "\n",
    "# Create an ElementTree from the combined XML data\n",
    "combined_tree = ET.ElementTree(combined_root)\n",
    "\n",
    "# Define the output file path for the combined XML\n",
    "output_xml_file = 'combined_data.xml'\n",
    "\n",
    "# Write the combined XML data to the output file\n",
    "combined_tree.write(output_xml_file)\n",
    "\n",
    "print(f\"Combined XML data saved to {output_xml_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Metadata :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "character_metadata_path = 'MovieSummaries\\\\character.metadata.tsv'\n",
    "character_metadata_data = pd.read_csv(character_metadata_path, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column names deduced from README\n",
    "character_metadata_data.columns = ['wiki_ID', 'free_ID', 'release', 'char_name', 'DOB', 'gender', 'height', 'ethnicity', 'act_name', 'age_at_release', 'free_char_map1', 'free_char_map2', 'free_char_map3']\n",
    "\n",
    "display(character_metadata_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Metadata :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "movie_metadata_path = 'MovieSummaries\\\\movie.metadata.tsv'\n",
    "movie_metadata_data = pd.read_csv(movie_metadata_path, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column names deduced from README\n",
    "movie_metadata_data.columns = ['wiki_ID', 'free_ID', 'mov_name', 'release', 'revenue', 'runtime', 'languages', 'countries', 'genres']\n",
    "\n",
    "display(movie_metadata_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Clusters Test Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "name_clusters_path = 'MovieSummaries\\\\name.clusters.txt'\n",
    "name_clusters_data = pd.read_csv(name_clusters_path, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(name_clusters_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TVTropes Clusters Test Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "tvtropes_clusters_path = 'MovieSummaries\\\\tvtropes.clusters.txt'\n",
    "tvtropes_clusters_data = pd.read_csv(tvtropes_clusters_path, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tvtropes_clusters_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
