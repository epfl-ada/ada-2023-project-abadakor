{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tconst</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tt0000001</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0000002</th>\n",
       "      <td>5.8</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0000003</th>\n",
       "      <td>6.5</td>\n",
       "      <td>1904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0000004</th>\n",
       "      <td>5.5</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0000005</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt9916730</th>\n",
       "      <td>7.6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt9916766</th>\n",
       "      <td>7.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt9916778</th>\n",
       "      <td>7.2</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt9916840</th>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt9916880</th>\n",
       "      <td>8.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1366302 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           averageRating  numVotes\n",
       "tconst                            \n",
       "tt0000001            5.7      2004\n",
       "tt0000002            5.8       269\n",
       "tt0000003            6.5      1904\n",
       "tt0000004            5.5       178\n",
       "tt0000005            6.2      2685\n",
       "...                  ...       ...\n",
       "tt9916730            7.6        11\n",
       "tt9916766            7.0        22\n",
       "tt9916778            7.2        36\n",
       "tt9916840            8.8         6\n",
       "tt9916880            8.2         6\n",
       "\n",
       "[1366302 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import imdb data\n",
    "raw_folder = './raw_data/'\n",
    "imdb_rating_folder = raw_folder + 'imdb_rating/'\n",
    "cmu_folder = raw_folder + 'cmu/'\n",
    "baby_names_folder = raw_folder + 'baby_names_national/'\n",
    "\n",
    "rating_df = pd.read_csv(imdb_rating_folder + 'imdb_rating.tsv', sep='\\t', index_col='tconst')\n",
    "display(rating_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the indexing unique ? True\n"
     ]
    }
   ],
   "source": [
    "# Verify the indexes are unique\n",
    "print(f\"Is the indexing unique ? {rating_df.index.is_unique}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Character MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>free_ID</th>\n",
       "      <th>release</th>\n",
       "      <th>char_name</th>\n",
       "      <th>DOB</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>act_name</th>\n",
       "      <th>age_at_release</th>\n",
       "      <th>free_char_map1</th>\n",
       "      <th>free_char_map2</th>\n",
       "      <th>free_char_map3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Akooshay</td>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "      <td>42.0</td>\n",
       "      <td>/m/0bgchxw</td>\n",
       "      <td>/m/0bgcj3x</td>\n",
       "      <td>/m/03wcfv7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Lieutenant Melanie Ballard</td>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.780</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0jys3m</td>\n",
       "      <td>/m/0bgchn4</td>\n",
       "      <td>/m/0346l4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Desolation Williams</td>\n",
       "      <td>1969-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>1.727</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>Ice Cube</td>\n",
       "      <td>32.0</td>\n",
       "      <td>/m/0jys3g</td>\n",
       "      <td>/m/0bgchn_</td>\n",
       "      <td>/m/01vw26l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Sgt Jericho Butler</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>33.0</td>\n",
       "      <td>/m/02vchl6</td>\n",
       "      <td>/m/0bgchnq</td>\n",
       "      <td>/m/034hyc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Bashira Kincaid</td>\n",
       "      <td>1977-09-25</td>\n",
       "      <td>F</td>\n",
       "      <td>1.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clea DuVall</td>\n",
       "      <td>23.0</td>\n",
       "      <td>/m/02vbb3r</td>\n",
       "      <td>/m/0bgchp9</td>\n",
       "      <td>/m/01y9xg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450664</th>\n",
       "      <td>913762</td>\n",
       "      <td>/m/03pcrp</td>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>Elensh</td>\n",
       "      <td>1970-05</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dorothy Elias-Fahn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0kr406c</td>\n",
       "      <td>/m/0kr406h</td>\n",
       "      <td>/m/0b_vcv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450665</th>\n",
       "      <td>913762</td>\n",
       "      <td>/m/03pcrp</td>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>Hibiki</td>\n",
       "      <td>1965-04-12</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jonathan Fahn</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0kr405_</td>\n",
       "      <td>/m/0kr4090</td>\n",
       "      <td>/m/0bx7_j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450666</th>\n",
       "      <td>28308153</td>\n",
       "      <td>/m/0cp05t9</td>\n",
       "      <td>1957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1941-11-18</td>\n",
       "      <td>M</td>\n",
       "      <td>1.730</td>\n",
       "      <td>/m/02w7gg</td>\n",
       "      <td>David Hemmings</td>\n",
       "      <td>15.0</td>\n",
       "      <td>/m/0g8ngmc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/022g44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450667</th>\n",
       "      <td>28308153</td>\n",
       "      <td>/m/0cp05t9</td>\n",
       "      <td>1957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roberta Paterson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0g8ngmj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0g8ngmm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450668</th>\n",
       "      <td>28308153</td>\n",
       "      <td>/m/0cp05t9</td>\n",
       "      <td>1957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>John Rogers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0g8ngmw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0btz19d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450669 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         wiki_ID     free_ID     release                   char_name  \\\n",
       "0         975900   /m/03vyhn  2001-08-24                    Akooshay   \n",
       "1         975900   /m/03vyhn  2001-08-24  Lieutenant Melanie Ballard   \n",
       "2         975900   /m/03vyhn  2001-08-24         Desolation Williams   \n",
       "3         975900   /m/03vyhn  2001-08-24          Sgt Jericho Butler   \n",
       "4         975900   /m/03vyhn  2001-08-24             Bashira Kincaid   \n",
       "...          ...         ...         ...                         ...   \n",
       "450664    913762   /m/03pcrp  1992-05-21                      Elensh   \n",
       "450665    913762   /m/03pcrp  1992-05-21                      Hibiki   \n",
       "450666  28308153  /m/0cp05t9        1957                         NaN   \n",
       "450667  28308153  /m/0cp05t9        1957                         NaN   \n",
       "450668  28308153  /m/0cp05t9        1957                         NaN   \n",
       "\n",
       "               DOB gender  height   ethnicity            act_name  \\\n",
       "0       1958-08-26      F   1.620         NaN      Wanda De Jesus   \n",
       "1       1974-08-15      F   1.780  /m/044038p  Natasha Henstridge   \n",
       "2       1969-06-15      M   1.727     /m/0x67            Ice Cube   \n",
       "3       1967-09-12      M   1.750         NaN       Jason Statham   \n",
       "4       1977-09-25      F   1.650         NaN         Clea DuVall   \n",
       "...            ...    ...     ...         ...                 ...   \n",
       "450664     1970-05      F     NaN         NaN  Dorothy Elias-Fahn   \n",
       "450665  1965-04-12      M     NaN         NaN       Jonathan Fahn   \n",
       "450666  1941-11-18      M   1.730   /m/02w7gg      David Hemmings   \n",
       "450667         NaN    NaN     NaN         NaN    Roberta Paterson   \n",
       "450668         NaN    NaN     NaN         NaN         John Rogers   \n",
       "\n",
       "        age_at_release free_char_map1 free_char_map2 free_char_map3  \n",
       "0                 42.0     /m/0bgchxw     /m/0bgcj3x     /m/03wcfv7  \n",
       "1                 27.0      /m/0jys3m     /m/0bgchn4      /m/0346l4  \n",
       "2                 32.0      /m/0jys3g     /m/0bgchn_     /m/01vw26l  \n",
       "3                 33.0     /m/02vchl6     /m/0bgchnq      /m/034hyc  \n",
       "4                 23.0     /m/02vbb3r     /m/0bgchp9      /m/01y9xg  \n",
       "...                ...            ...            ...            ...  \n",
       "450664             NaN     /m/0kr406c     /m/0kr406h      /m/0b_vcv  \n",
       "450665            27.0     /m/0kr405_     /m/0kr4090      /m/0bx7_j  \n",
       "450666            15.0     /m/0g8ngmc            NaN      /m/022g44  \n",
       "450667             NaN     /m/0g8ngmj            NaN     /m/0g8ngmm  \n",
       "450668             NaN     /m/0g8ngmw            NaN     /m/0btz19d  \n",
       "\n",
       "[450669 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import character metadata\n",
    "character_df = pd.read_csv(cmu_folder + 'character.metadata.tsv', sep='\\t', header=None)\n",
    "\n",
    "# Add column names deduced from README\n",
    "character_df.columns = ['wiki_ID', 'free_ID', 'release', 'char_name', 'DOB', 'gender', 'height', 'ethnicity', 'act_name', 'age_at_release', 'free_char_map1', 'free_char_map2', 'free_char_map3']\n",
    "\n",
    "display(character_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Movie MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>free_ID</th>\n",
       "      <th>mov_name</th>\n",
       "      <th>release</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>languages</th>\n",
       "      <th>countries</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3196793</td>\n",
       "      <td>/m/08yl5d</td>\n",
       "      <td>Getting Away with Murder: The JonBenÃ©t Ramsey ...</td>\n",
       "      <td>2000-02-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28463795</td>\n",
       "      <td>/m/0crgdbh</td>\n",
       "      <td>Brun bitter</td>\n",
       "      <td>1988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>{\"/m/05f_3\": \"Norwegian Language\"}</td>\n",
       "      <td>{\"/m/05b4w\": \"Norway\"}</td>\n",
       "      <td>{\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9363483</td>\n",
       "      <td>/m/0285_cd</td>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/07ssc\": \"United Kingdom\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261236</td>\n",
       "      <td>/m/01mrr1</td>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>1983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>{\"/m/04306rv\": \"German Language\"}</td>\n",
       "      <td>{\"/m/0345h\": \"Germany\"}</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81736</th>\n",
       "      <td>35228177</td>\n",
       "      <td>/m/0j7hxnt</td>\n",
       "      <td>Mermaids: The Body Found</td>\n",
       "      <td>2011-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81737</th>\n",
       "      <td>34980460</td>\n",
       "      <td>/m/0g4pl34</td>\n",
       "      <td>Knuckle</td>\n",
       "      <td>2011-01-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/03rt9\": \"Ireland\", \"/m/07ssc\": \"United Ki...</td>\n",
       "      <td>{\"/m/03bxz7\": \"Biographical film\", \"/m/07s9rl0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81738</th>\n",
       "      <td>9971909</td>\n",
       "      <td>/m/02pygw1</td>\n",
       "      <td>Another Nice Mess</td>\n",
       "      <td>1972-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/06nbt\": \"Satire\", \"/m/01z4y\": \"Comedy\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81739</th>\n",
       "      <td>913762</td>\n",
       "      <td>/m/03pcrp</td>\n",
       "      <td>The Super Dimension Fortress Macross II: Lover...</td>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>{\"/m/03_9r\": \"Japanese Language\"}</td>\n",
       "      <td>{\"/m/03_3d\": \"Japan\"}</td>\n",
       "      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/0gw5n2f\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81740</th>\n",
       "      <td>12476867</td>\n",
       "      <td>/m/02w7zz8</td>\n",
       "      <td>Spliced</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/0d060g\": \"Canada\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/03npn\": \"Horror\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81741 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        wiki_ID     free_ID  \\\n",
       "0        975900   /m/03vyhn   \n",
       "1       3196793   /m/08yl5d   \n",
       "2      28463795  /m/0crgdbh   \n",
       "3       9363483  /m/0285_cd   \n",
       "4        261236   /m/01mrr1   \n",
       "...         ...         ...   \n",
       "81736  35228177  /m/0j7hxnt   \n",
       "81737  34980460  /m/0g4pl34   \n",
       "81738   9971909  /m/02pygw1   \n",
       "81739    913762   /m/03pcrp   \n",
       "81740  12476867  /m/02w7zz8   \n",
       "\n",
       "                                                mov_name     release  \\\n",
       "0                                         Ghosts of Mars  2001-08-24   \n",
       "1      Getting Away with Murder: The JonBenÃ©t Ramsey ...  2000-02-16   \n",
       "2                                            Brun bitter        1988   \n",
       "3                                       White Of The Eye        1987   \n",
       "4                                      A Woman in Flames        1983   \n",
       "...                                                  ...         ...   \n",
       "81736                           Mermaids: The Body Found  2011-03-19   \n",
       "81737                                            Knuckle  2011-01-21   \n",
       "81738                                  Another Nice Mess  1972-09-22   \n",
       "81739  The Super Dimension Fortress Macross II: Lover...  1992-05-21   \n",
       "81740                                            Spliced        2002   \n",
       "\n",
       "          revenue  runtime                           languages  \\\n",
       "0      14010832.0     98.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "1             NaN     95.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "2             NaN     83.0  {\"/m/05f_3\": \"Norwegian Language\"}   \n",
       "3             NaN    110.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "4             NaN    106.0   {\"/m/04306rv\": \"German Language\"}   \n",
       "...           ...      ...                                 ...   \n",
       "81736         NaN    120.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "81737         NaN     96.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "81738         NaN     66.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "81739         NaN    150.0   {\"/m/03_9r\": \"Japanese Language\"}   \n",
       "81740         NaN     86.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "\n",
       "                                               countries  \\\n",
       "0              {\"/m/09c7w0\": \"United States of America\"}   \n",
       "1              {\"/m/09c7w0\": \"United States of America\"}   \n",
       "2                                 {\"/m/05b4w\": \"Norway\"}   \n",
       "3                         {\"/m/07ssc\": \"United Kingdom\"}   \n",
       "4                                {\"/m/0345h\": \"Germany\"}   \n",
       "...                                                  ...   \n",
       "81736          {\"/m/09c7w0\": \"United States of America\"}   \n",
       "81737  {\"/m/03rt9\": \"Ireland\", \"/m/07ssc\": \"United Ki...   \n",
       "81738          {\"/m/09c7w0\": \"United States of America\"}   \n",
       "81739                              {\"/m/03_3d\": \"Japan\"}   \n",
       "81740                            {\"/m/0d060g\": \"Canada\"}   \n",
       "\n",
       "                                                  genres  \n",
       "0      {\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...  \n",
       "1      {\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...  \n",
       "2      {\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...  \n",
       "3      {\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...  \n",
       "4                                {\"/m/07s9rl0\": \"Drama\"}  \n",
       "...                                                  ...  \n",
       "81736                            {\"/m/07s9rl0\": \"Drama\"}  \n",
       "81737  {\"/m/03bxz7\": \"Biographical film\", \"/m/07s9rl0...  \n",
       "81738       {\"/m/06nbt\": \"Satire\", \"/m/01z4y\": \"Comedy\"}  \n",
       "81739  {\"/m/06n90\": \"Science Fiction\", \"/m/0gw5n2f\": ...  \n",
       "81740  {\"/m/01jfsb\": \"Thriller\", \"/m/03npn\": \"Horror\"...  \n",
       "\n",
       "[81741 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the wiki_ID unique ? True\n"
     ]
    }
   ],
   "source": [
    "# Import movie metadata\n",
    "movie_df = pd.read_csv(cmu_folder + 'movie.metadata.tsv', sep='\\t', header=None)\n",
    "\n",
    "# Add column names deduced from README\n",
    "movie_df.columns = ['wiki_ID', 'free_ID', 'mov_name', 'release', 'revenue', 'runtime', 'languages', 'countries', 'genres']\n",
    "display(movie_df)\n",
    "print(f\"Is the wiki_ID unique ? {movie_df.wiki_ID.is_unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wiki_ID        int64\n",
       "free_ID       object\n",
       "mov_name      object\n",
       "release       object\n",
       "revenue      float64\n",
       "runtime      float64\n",
       "languages     object\n",
       "countries     object\n",
       "genres        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the index of the row with the smallest value in 'Column1'\n",
    "# min_index = movie_df['release'].idxmin()\n",
    "\n",
    "# # Get the entire row using the index\n",
    "# min_row = movie_df.loc[min_index]\n",
    "# print(f\"oldest movies in CMU dataset : {min_row}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets check the percentage of missing  values in the revenue attribut of the movie dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values in column 'revenue': 89.72%\n"
     ]
    }
   ],
   "source": [
    "nb_revenue_missing = movie_df['revenue'].isna().sum()\n",
    "total_movies = len(movie_df)\n",
    "perc_missing = (nb_revenue_missing / total_movies)*100\n",
    "print(f\"Percentage of missing values in column 'revenue': {perc_missing:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets get a list of character name in the movie dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The character dataframe has not a unique index. It is due to the several Nan values present in the same movie. To tackles this we can drop the rows that have a NaN as name and see if it solve the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_filtered = character_df.copy(deep=True)\n",
    "\n",
    "# drop the rows with a NaN as the character name\n",
    "character_filtered = character_filtered.dropna(subset=['char_name'])\n",
    "# drop the rows with the same character name\n",
    "character_filtered = character_filtered.drop_duplicates(subset=['wiki_ID','char_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki_ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>[S-Mart Clerk, Fake shemp, Ash Williams, Evil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>[J.F. Sebastian, Rick Deckard, Roy Batty, Rach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>[Gabby Johnson, Taggart, Rev. Johnson, Mongo, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>[Don Vallens, Dorothy Vallens, Jeffrey Beaumon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>[Barry Lyndon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37196243</th>\n",
       "      <td>[Carlina White, Ann Pettway, Joy White, Carl W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37322106</th>\n",
       "      <td>[Major Samar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37373877</th>\n",
       "      <td>[Beth Patterson, Jennifer Jones]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37478048</th>\n",
       "      <td>[Ajay]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37501922</th>\n",
       "      <td>[John Hunter, Craig Murphy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32571 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  char_name\n",
       "wiki_ID                                                    \n",
       "3217      [S-Mart Clerk, Fake shemp, Ash Williams, Evil ...\n",
       "3746      [J.F. Sebastian, Rick Deckard, Roy Batty, Rach...\n",
       "3837      [Gabby Johnson, Taggart, Rev. Johnson, Mongo, ...\n",
       "3947      [Don Vallens, Dorothy Vallens, Jeffrey Beaumon...\n",
       "4227                                         [Barry Lyndon]\n",
       "...                                                     ...\n",
       "37196243  [Carlina White, Ann Pettway, Joy White, Carl W...\n",
       "37322106                                      [Major Samar]\n",
       "37373877                   [Beth Patterson, Jennifer Jones]\n",
       "37478048                                             [Ajay]\n",
       "37501922                        [John Hunter, Craig Murphy]\n",
       "\n",
       "[32571 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DataFrame with only one entry containing all character names for a given film\n",
    "character_per_movie_df = character_filtered.groupby('wiki_ID').apply(lambda x: pd.Series({\n",
    "        'char_name': x['char_name'].values\n",
    "    }))\n",
    "display(character_per_movie_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thomd\\AppData\\Local\\Temp\\ipykernel_26540\\443696169.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_movie_names['split_names'] = df_movie_names['char_name'].apply(split_names)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_name</th>\n",
       "      <th>split_names</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>[S-Mart Clerk, Fake shemp, Ash Williams, Evil ...</td>\n",
       "      <td>[S-Mart, Clerk, Fake, shemp, Ash, Williams, Ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>[J.F. Sebastian, Rick Deckard, Roy Batty, Rach...</td>\n",
       "      <td>[J.F., Sebastian, Rick, Deckard, Roy, Batty, R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>[Gabby Johnson, Taggart, Rev. Johnson, Mongo, ...</td>\n",
       "      <td>[Gabby, Johnson, Taggart, Rev., Johnson, Mongo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>[Don Vallens, Dorothy Vallens, Jeffrey Beaumon...</td>\n",
       "      <td>[Don, Vallens, Dorothy, Vallens, Jeffrey, Beau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>[Barry Lyndon]</td>\n",
       "      <td>[Barry, Lyndon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37196243</th>\n",
       "      <td>[Carlina White, Ann Pettway, Joy White, Carl W...</td>\n",
       "      <td>[Carlina, White, Ann, Pettway, Joy, White, Car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37322106</th>\n",
       "      <td>[Major Samar]</td>\n",
       "      <td>[Major, Samar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37373877</th>\n",
       "      <td>[Beth Patterson, Jennifer Jones]</td>\n",
       "      <td>[Beth, Patterson, Jennifer, Jones]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37478048</th>\n",
       "      <td>[Ajay]</td>\n",
       "      <td>[Ajay]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37501922</th>\n",
       "      <td>[John Hunter, Craig Murphy]</td>\n",
       "      <td>[John, Hunter, Craig, Murphy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32571 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  char_name  \\\n",
       "wiki_ID                                                       \n",
       "3217      [S-Mart Clerk, Fake shemp, Ash Williams, Evil ...   \n",
       "3746      [J.F. Sebastian, Rick Deckard, Roy Batty, Rach...   \n",
       "3837      [Gabby Johnson, Taggart, Rev. Johnson, Mongo, ...   \n",
       "3947      [Don Vallens, Dorothy Vallens, Jeffrey Beaumon...   \n",
       "4227                                         [Barry Lyndon]   \n",
       "...                                                     ...   \n",
       "37196243  [Carlina White, Ann Pettway, Joy White, Carl W...   \n",
       "37322106                                      [Major Samar]   \n",
       "37373877                   [Beth Patterson, Jennifer Jones]   \n",
       "37478048                                             [Ajay]   \n",
       "37501922                        [John Hunter, Craig Murphy]   \n",
       "\n",
       "                                                split_names  \n",
       "wiki_ID                                                      \n",
       "3217      [S-Mart, Clerk, Fake, shemp, Ash, Williams, Ev...  \n",
       "3746      [J.F., Sebastian, Rick, Deckard, Roy, Batty, R...  \n",
       "3837      [Gabby, Johnson, Taggart, Rev., Johnson, Mongo...  \n",
       "3947      [Don, Vallens, Dorothy, Vallens, Jeffrey, Beau...  \n",
       "4227                                        [Barry, Lyndon]  \n",
       "...                                                     ...  \n",
       "37196243  [Carlina, White, Ann, Pettway, Joy, White, Car...  \n",
       "37322106                                     [Major, Samar]  \n",
       "37373877                 [Beth, Patterson, Jennifer, Jones]  \n",
       "37478048                                             [Ajay]  \n",
       "37501922                      [John, Hunter, Craig, Murphy]  \n",
       "\n",
       "[32571 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_movie_names = character_per_movie_df[0:]\n",
    "\n",
    "def split_names(names_list):\n",
    "    result = []\n",
    "    for name in names_list:\n",
    "        split_name = name.split()\n",
    "        result.extend(split_name)\n",
    "    return result\n",
    "\n",
    "df_movie_names['split_names'] = df_movie_names['char_name'].apply(split_names)\n",
    "\n",
    "display(df_movie_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given name dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>number</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mary</td>\n",
       "      <td>F</td>\n",
       "      <td>7065</td>\n",
       "      <td>1880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anna</td>\n",
       "      <td>F</td>\n",
       "      <td>2604</td>\n",
       "      <td>1880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emma</td>\n",
       "      <td>F</td>\n",
       "      <td>2003</td>\n",
       "      <td>1880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>F</td>\n",
       "      <td>1939</td>\n",
       "      <td>1880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Minnie</td>\n",
       "      <td>F</td>\n",
       "      <td>1746</td>\n",
       "      <td>1880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name gender  number  year\n",
       "0       Mary      F    7065  1880\n",
       "1       Anna      F    2604  1880\n",
       "2       Emma      F    2003  1880\n",
       "3  Elizabeth      F    1939  1880\n",
       "4     Minnie      F    1746  1880"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import name dataset\n",
    "import os\n",
    "\n",
    "# Define the path to your dataset folder\n",
    "folder_path = 'raw_data/baby_names_national/'\n",
    "\n",
    "# Create an empty list to store individual DataFrames\n",
    "data_frames = []\n",
    "\n",
    "# Iterate through each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.startswith('yob') and filename.endswith('.txt'):\n",
    "        # Extract the year from the filename\n",
    "        year = int(filename[3:-4])\n",
    "\n",
    "        # Read the data from the file into a DataFrame\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path, header=None, names=['name', 'gender', 'number'])\n",
    "\n",
    "        # Add the 'year' column to the DataFrame\n",
    "        df['year'] = year\n",
    "\n",
    "        # Append the current DataFrame to the list\n",
    "        data_frames.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list into one DataFrame\n",
    "combined_data = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Set the 'name' column as the index\n",
    "# combined_data.set_index('name', inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#Character names analysis\n",
    "\n",
    "df_movie_names.head()\n",
    "\n",
    "df_movie_names['split_names']\n",
    "\n",
    "print(type(df_movie_names['split_names'].iloc[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S-Mart', 'Clerk', 'Fake', 'shemp', 'Ash', 'Williams', 'Evil', 'Ash', 'Cowardly', 'Warrior', 'Linda', 'Sheila', 'Possessed', 'Witch', 'Duke', 'Henry', 'the', 'Red', 'Second', 'Supportive', 'Villager', 'Wiseman', 'Gold', 'Tooth', 'Blacksmith', 'Lord', 'Arthur']\n",
      "{'Gold', 'Ash', 'Red', 'Linda', 'Henry', 'Warrior', 'Arthur', 'Sheila', 'Lord', 'Duke', 'Williams'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Faire une series des nom unique des enfants \n",
    "unique_entries = combined_data['name'].unique()\n",
    "\n",
    "# Convert the unique entries to a list\n",
    "unique_entries_list = list(unique_entries)\n",
    "\n",
    "#   display(unique_entries_list)\n",
    "\n",
    "print(df_movie_names['split_names'].iloc[0])\n",
    "\n",
    "intersection_set = set(df_movie_names['split_names'].iloc[0]) & set(unique_entries_list)\n",
    "print(intersection_set)\n",
    "\n",
    "bool(intersection_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_movie_names.split_names)\n",
    "\n",
    "Intersection_names = []\n",
    "\n",
    "#for i in range(10) : \n",
    "\n",
    "#    inter = set(df_movie_names['split_names'].iloc[i]) & set(unique_entries_list)\n",
    "\n",
    "#    Intersection_names = [Intersection_names,bool(inter)]\n",
    "\n",
    "Intersection_names = []\n",
    "\n",
    "for i in range(10000):\n",
    "    inter = set(df_movie_names['split_names'].iloc[i]) & set(unique_entries_list)\n",
    "    Intersection_names.append(bool(inter))\n",
    "\n",
    "Intersection_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(Intersection_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = character_per_movie_df[:10]\n",
    "\n",
    "# def split_names(names_list):\n",
    "#     split_names = [name.split() if ' ' in name else [name] for name in names_list]\n",
    "#     return split_names\n",
    "\n",
    "# df['split_names'] = df['char_name'].apply(split_names)\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = character_per_movie_df[:10]\n",
    "\n",
    "# def split_names(names_list):\n",
    "#     result = []\n",
    "#     for name in names_list:\n",
    "#         if ' ' in name:\n",
    "#             print(f\"the name {name} has a space in it\")\n",
    "#             split_name = name.split()\n",
    "#         else:\n",
    "#             print(f\"the name {name} doesn't have a space in it\")\n",
    "#             split_name = [name]\n",
    "#         result.append(split_name)\n",
    "#     return result\n",
    "\n",
    "# df['split_names'] = df['char_name'].apply(split_names)\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>free_ID</th>\n",
       "      <th>release</th>\n",
       "      <th>DOB</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>act_name</th>\n",
       "      <th>age_at_release</th>\n",
       "      <th>free_char_map1</th>\n",
       "      <th>free_char_map2</th>\n",
       "      <th>free_char_map3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>char_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">975900</th>\n",
       "      <th>Akooshay</th>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "      <td>42.0</td>\n",
       "      <td>/m/0bgchxw</td>\n",
       "      <td>/m/0bgcj3x</td>\n",
       "      <td>/m/03wcfv7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lieutenant Melanie Ballard</th>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.780</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0jys3m</td>\n",
       "      <td>/m/0bgchn4</td>\n",
       "      <td>/m/0346l4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Desolation Williams</th>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>1969-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>1.727</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>Ice Cube</td>\n",
       "      <td>32.0</td>\n",
       "      <td>/m/0jys3g</td>\n",
       "      <td>/m/0bgchn_</td>\n",
       "      <td>/m/01vw26l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sgt Jericho Butler</th>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>33.0</td>\n",
       "      <td>/m/02vchl6</td>\n",
       "      <td>/m/0bgchnq</td>\n",
       "      <td>/m/034hyc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bashira Kincaid</th>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>1977-09-25</td>\n",
       "      <td>F</td>\n",
       "      <td>1.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clea DuVall</td>\n",
       "      <td>23.0</td>\n",
       "      <td>/m/02vbb3r</td>\n",
       "      <td>/m/0bgchp9</td>\n",
       "      <td>/m/01y9xg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">913762</th>\n",
       "      <th>Maj. Nexx</th>\n",
       "      <td>/m/03pcrp</td>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>1960-04-28</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steven Blum</td>\n",
       "      <td>32.0</td>\n",
       "      <td>/m/0kr40d9</td>\n",
       "      <td>/m/0kr40df</td>\n",
       "      <td>/m/044_7j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lord Feff</th>\n",
       "      <td>/m/03pcrp</td>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>1960-04-28</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steven Blum</td>\n",
       "      <td>32.0</td>\n",
       "      <td>/m/0kr408g</td>\n",
       "      <td>/m/0kr408l</td>\n",
       "      <td>/m/044_7j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UN Spacy Commander</th>\n",
       "      <td>/m/03pcrp</td>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>1954</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sonny Byrkett</td>\n",
       "      <td>38.0</td>\n",
       "      <td>/m/0kr407w</td>\n",
       "      <td>/m/0kr407_</td>\n",
       "      <td>/m/0gn4bz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Silvie Gena</th>\n",
       "      <td>/m/03pcrp</td>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>1958</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Susan Byrkett</td>\n",
       "      <td>34.0</td>\n",
       "      <td>/m/0kr40b9</td>\n",
       "      <td>/m/0kr40bf</td>\n",
       "      <td>/m/0gn4nd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elensh</th>\n",
       "      <td>/m/03pcrp</td>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>1970-05</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dorothy Elias-Fahn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0kr406c</td>\n",
       "      <td>/m/0kr406h</td>\n",
       "      <td>/m/0b_vcv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189341 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      free_ID     release         DOB gender  \\\n",
       "wiki_ID char_name                                                              \n",
       "975900  Akooshay                    /m/03vyhn  2001-08-24  1958-08-26      F   \n",
       "        Lieutenant Melanie Ballard  /m/03vyhn  2001-08-24  1974-08-15      F   \n",
       "        Desolation Williams         /m/03vyhn  2001-08-24  1969-06-15      M   \n",
       "        Sgt Jericho Butler          /m/03vyhn  2001-08-24  1967-09-12      M   \n",
       "        Bashira Kincaid             /m/03vyhn  2001-08-24  1977-09-25      F   \n",
       "...                                       ...         ...         ...    ...   \n",
       "913762  Maj. Nexx                   /m/03pcrp  1992-05-21  1960-04-28      M   \n",
       "        Lord Feff                   /m/03pcrp  1992-05-21  1960-04-28      M   \n",
       "        UN Spacy Commander          /m/03pcrp  1992-05-21        1954      M   \n",
       "        Silvie Gena                 /m/03pcrp  1992-05-21        1958      F   \n",
       "        Elensh                      /m/03pcrp  1992-05-21     1970-05      F   \n",
       "\n",
       "                                    height   ethnicity            act_name  \\\n",
       "wiki_ID char_name                                                            \n",
       "975900  Akooshay                     1.620         NaN      Wanda De Jesus   \n",
       "        Lieutenant Melanie Ballard   1.780  /m/044038p  Natasha Henstridge   \n",
       "        Desolation Williams          1.727     /m/0x67            Ice Cube   \n",
       "        Sgt Jericho Butler           1.750         NaN       Jason Statham   \n",
       "        Bashira Kincaid              1.650         NaN         Clea DuVall   \n",
       "...                                    ...         ...                 ...   \n",
       "913762  Maj. Nexx                      NaN         NaN         Steven Blum   \n",
       "        Lord Feff                      NaN         NaN         Steven Blum   \n",
       "        UN Spacy Commander             NaN         NaN       Sonny Byrkett   \n",
       "        Silvie Gena                    NaN         NaN       Susan Byrkett   \n",
       "        Elensh                         NaN         NaN  Dorothy Elias-Fahn   \n",
       "\n",
       "                                    age_at_release free_char_map1  \\\n",
       "wiki_ID char_name                                                   \n",
       "975900  Akooshay                              42.0     /m/0bgchxw   \n",
       "        Lieutenant Melanie Ballard            27.0      /m/0jys3m   \n",
       "        Desolation Williams                   32.0      /m/0jys3g   \n",
       "        Sgt Jericho Butler                    33.0     /m/02vchl6   \n",
       "        Bashira Kincaid                       23.0     /m/02vbb3r   \n",
       "...                                            ...            ...   \n",
       "913762  Maj. Nexx                             32.0     /m/0kr40d9   \n",
       "        Lord Feff                             32.0     /m/0kr408g   \n",
       "        UN Spacy Commander                    38.0     /m/0kr407w   \n",
       "        Silvie Gena                           34.0     /m/0kr40b9   \n",
       "        Elensh                                 NaN     /m/0kr406c   \n",
       "\n",
       "                                   free_char_map2 free_char_map3  \n",
       "wiki_ID char_name                                                 \n",
       "975900  Akooshay                       /m/0bgcj3x     /m/03wcfv7  \n",
       "        Lieutenant Melanie Ballard     /m/0bgchn4      /m/0346l4  \n",
       "        Desolation Williams            /m/0bgchn_     /m/01vw26l  \n",
       "        Sgt Jericho Butler             /m/0bgchnq      /m/034hyc  \n",
       "        Bashira Kincaid                /m/0bgchp9      /m/01y9xg  \n",
       "...                                           ...            ...  \n",
       "913762  Maj. Nexx                      /m/0kr40df      /m/044_7j  \n",
       "        Lord Feff                      /m/0kr408l      /m/044_7j  \n",
       "        UN Spacy Commander             /m/0kr407_      /m/0gn4bz  \n",
       "        Silvie Gena                    /m/0kr40bf      /m/0gn4nd  \n",
       "        Elensh                         /m/0kr406h      /m/0b_vcv  \n",
       "\n",
       "[189341 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the indexing unique ? True\n"
     ]
    }
   ],
   "source": [
    "character_filtered = character_filtered.set_index(['wiki_ID','char_name'])\n",
    "display(character_filtered)\n",
    "\n",
    "# Verify the indexes are unique\n",
    "print(f\"Is the indexing unique ? {character_filtered.index.is_unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# character_filetered.query('wiki_ID == 975900')\n",
    "# # T'es trop frais Maxou le s de la veine, le fratÃ©, le khouya\n",
    "#  (+1)\n",
    "\n",
    "# character_filetered.loc[975900]\n",
    "# character_filetered.loc[975900, 'Akooshay']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
