{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) comment on catégoriser le taux d'influence: t-stat\n",
    "2) is movie significant ? -> p-value\n",
    "3) same release year for several movies -> keep the one that is the most rated (number of ratings)\n",
    "4) keep categories of 5 : top 5, most 5 popular movies which are not significant, bottom 5\n",
    "5) remove all movies that have less than 100 ratings (to be determined maybe we discard too many movies or too litte...)\n",
    "6) remove all characters that have an order below the median (or mean) of the number of character in the movie.\n",
    "7) Careful : the number of movies with significant impact on baby names may drop a lot due to the point 5 and 6\n",
    "8) the point 5 and 6 must be done also for the global study and not only for the website interactive heading (TO BE DISCUSSED!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>order</th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "      <th>t_stat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>char_words</th>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29502739</th>\n",
       "      <th>Kyser</th>\n",
       "      <th>F</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8398222</th>\n",
       "      <th>Stonewall</th>\n",
       "      <th>M</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            order  p_value  slope_change  t_stat\n",
       "wiki_ID  char_words gender                                      \n",
       "29502739 Kyser      F         1.0      NaN           NaN     NaN\n",
       "8398222  Stonewall  M         0.0      NaN           NaN     NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mov_name</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>revenue</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>poster_url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28635851</th>\n",
       "      <td>Deadly Hero</td>\n",
       "      <td>1976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8244890</th>\n",
       "      <td>King Cobra</td>\n",
       "      <td>1999</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2560</td>\n",
       "      <td>3.2</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mov_name  year  month  revenue  numVotes  averageRating  \\\n",
       "wiki_ID                                                                \n",
       "28635851  Deadly Hero  1976    NaN      NaN       383            5.8   \n",
       "8244890    King Cobra  1999    4.0      NaN      2560            3.2   \n",
       "\n",
       "                                                 poster_url  \n",
       "wiki_ID                                                      \n",
       "28635851                                                NaN  \n",
       "8244890   https://images-na.ssl-images-amazon.com/images...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder_processed_data_path = './processed_data/'\n",
    "\n",
    "# import the name by movie\n",
    "name_by_movie_df = pd.read_csv(os.path.join(folder_processed_data_path, 'name_by_movie_ordered_pvalue_10_5_df.csv'))\n",
    "name_by_movie_df.set_index(['wiki_ID', 'char_words', 'gender'], inplace=True)\n",
    "display(name_by_movie_df.sample(2))\n",
    "\n",
    "# import the movie dataframe\n",
    "movie_df = pd.read_csv(os.path.join(folder_processed_data_path, 'movie_df.csv'))\n",
    "movie_df.set_index(['wiki_ID'], inplace=True)\n",
    "display(movie_df.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given name by user\n",
    "chosen_name = 'John'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute `movie_impact` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's compute the 5 years with the most change in the babies for the chosen name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>char_words</th>\n",
       "      <th>gender</th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53023</th>\n",
       "      <td>3190223</td>\n",
       "      <td>Mingus</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93636</th>\n",
       "      <td>10932698</td>\n",
       "      <td>Man</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        wiki_ID char_words gender  p_value  slope_change\n",
       "53023   3190223     Mingus      M      NaN           NaN\n",
       "93636  10932698        Man      M      NaN           NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove useless columns\n",
    "name_by_movie_web = name_by_movie_df.reset_index().copy(deep=True)\n",
    "name_by_movie_web.drop(columns=['order', 't_stat'], inplace=True)\n",
    "display(name_by_movie_web.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length : 172906 -> 167984\n",
      "Is the indexing of name_by_movie_web unique? True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_words</th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Shamus</th>\n",
       "      <th>16190310</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crew</th>\n",
       "      <th>4450552</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     p_value  slope_change\n",
       "char_words wiki_ID                        \n",
       "Shamus     16190310      NaN           NaN\n",
       "Crew       4450552       NaN           NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# drop gender column\n",
    "len_before = len(name_by_movie_web)\n",
    "\n",
    "name_by_movie_web.reset_index(inplace=True, drop=True)\n",
    "name_by_movie_web.drop_duplicates(subset=['wiki_ID', 'char_words'], keep='first', inplace=True)\n",
    "name_by_movie_web.drop(columns=['gender'], inplace=True)\n",
    "name_by_movie_web.set_index(['char_words', 'wiki_ID'], inplace=True)\n",
    "\n",
    "len_after = len(name_by_movie_web)\n",
    "print(f\"length : {len_before} -> {len_after}\")\n",
    "print(f\"Is the indexing of name_by_movie_web unique? {name_by_movie_web.index.is_unique}\")\n",
    "display(name_by_movie_web.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN values\n",
    "name_by_movie_web.dropna(subset=['p_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "      <th>year</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_words</th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Allegra</th>\n",
       "      <th>4644031</th>\n",
       "      <td>0.098078</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>1998</td>\n",
       "      <td>3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abner</th>\n",
       "      <th>1203421</th>\n",
       "      <td>0.592030</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>1985</td>\n",
       "      <td>2468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     p_value  slope_change  year  numVotes\n",
       "char_words wiki_ID                                        \n",
       "Allegra    4644031  0.098078      0.000747  1998      3125\n",
       "Abner      1203421  0.592030     -0.000096  1985      2468"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add the year of release of the movie to the name_by_movie_web dataframe\n",
    "movie_id_and_year_df = movie_df.reset_index()[['wiki_ID', 'year', 'numVotes']].copy(deep=True)\n",
    "name_by_movie_and_year = name_by_movie_web.reset_index().merge(movie_id_and_year_df, on='wiki_ID', how='left').copy(deep=True) # merge the release year into the name_by_movie_web dataframe\n",
    "name_by_movie_and_year.set_index(['char_words', 'wiki_ID'], inplace=True)\n",
    "display(name_by_movie_and_year.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, status, movie_id]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the movie_impact dataframe\n",
    "columns = ['name', 'status', 'movie_id']\n",
    "movie_impact_df = pd.DataFrame(columns=columns)\n",
    "display(movie_impact_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "      <th>year</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13395744</th>\n",
       "      <td>0.988304</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>1998</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886835</th>\n",
       "      <td>0.988304</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>1998</td>\n",
       "      <td>2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16749397</th>\n",
       "      <td>0.988304</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>1998</td>\n",
       "      <td>1811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28414080</th>\n",
       "      <td>0.988304</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>1998</td>\n",
       "      <td>1529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667958</th>\n",
       "      <td>0.988304</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>1998</td>\n",
       "      <td>39983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22332305</th>\n",
       "      <td>0.072481</td>\n",
       "      <td>0.094670</td>\n",
       "      <td>1969</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266695</th>\n",
       "      <td>0.201968</td>\n",
       "      <td>0.100165</td>\n",
       "      <td>1918</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433285</th>\n",
       "      <td>0.047836</td>\n",
       "      <td>0.105511</td>\n",
       "      <td>1968</td>\n",
       "      <td>74026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422489</th>\n",
       "      <td>0.047836</td>\n",
       "      <td>0.105511</td>\n",
       "      <td>1968</td>\n",
       "      <td>27558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18903874</th>\n",
       "      <td>0.047836</td>\n",
       "      <td>0.105511</td>\n",
       "      <td>1968</td>\n",
       "      <td>4614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           p_value  slope_change  year  numVotes\n",
       "wiki_ID                                         \n",
       "13395744  0.988304      0.000088  1998       377\n",
       "2886835   0.988304      0.000088  1998      2574\n",
       "16749397  0.988304      0.000088  1998      1811\n",
       "28414080  0.988304      0.000088  1998      1529\n",
       "2667958   0.988304      0.000088  1998     39983\n",
       "...            ...           ...   ...       ...\n",
       "22332305  0.072481      0.094670  1969       228\n",
       "4266695   0.201968      0.100165  1918       326\n",
       "433285    0.047836      0.105511  1968     74026\n",
       "2422489   0.047836      0.105511  1968     27558\n",
       "18903874  0.047836      0.105511  1968      4614\n",
       "\n",
       "[470 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chosen_name_movies_df = name_by_movie_and_year.loc[chosen_name, :].copy(deep=True)\n",
    "chosen_name_movies_df.sort_values(by=['slope_change'], inplace=True)\n",
    "chosen_name_movies_df.query('slope_change > 0', inplace=True)\n",
    "display(chosen_name_movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the loop to do the computation for top1 to top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>t</td>\n",
       "      <td>433285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John</td>\n",
       "      <td>t</td>\n",
       "      <td>2422489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John</td>\n",
       "      <td>t</td>\n",
       "      <td>18903874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John</td>\n",
       "      <td>t</td>\n",
       "      <td>4266695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John</td>\n",
       "      <td>t</td>\n",
       "      <td>17995856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>John</td>\n",
       "      <td>t</td>\n",
       "      <td>149791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>John</td>\n",
       "      <td>t</td>\n",
       "      <td>2265234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>John</td>\n",
       "      <td>t</td>\n",
       "      <td>982199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>John</td>\n",
       "      <td>t</td>\n",
       "      <td>187636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>John</td>\n",
       "      <td>t</td>\n",
       "      <td>7105919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>John</td>\n",
       "      <td>t</td>\n",
       "      <td>1623263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>John</td>\n",
       "      <td>t</td>\n",
       "      <td>24267121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>John</td>\n",
       "      <td>t</td>\n",
       "      <td>10394661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name status  movie_id\n",
       "0   John      t    433285\n",
       "1   John      t   2422489\n",
       "2   John      t  18903874\n",
       "3   John      t   4266695\n",
       "4   John      t  17995856\n",
       "5   John      t    149791\n",
       "6   John      t   2265234\n",
       "7   John      t    982199\n",
       "8   John      t    187636\n",
       "9   John      t   7105919\n",
       "10  John      t   1623263\n",
       "11  John      t  24267121\n",
       "12  John      t  10394661"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(5): # from top1 to top5\n",
    "    # get the movies release the year with the highest positive variation\n",
    "    top_i_year = chosen_name_movies_df.iloc[-1].year.astype(int)\n",
    "    top_i_year_chosen_name_movies = chosen_name_movies_df.query(f'year == {top_i_year}').copy(deep=True)\n",
    "\n",
    "    # keep only the three most popular movies\n",
    "    top_i_year_chosen_name_movies.sort_values(by=['numVotes'], ascending=False, inplace=True)\n",
    "    top_i_3_chosen_name_movies = top_i_year_chosen_name_movies.iloc[:3].copy(deep=True)\n",
    "\n",
    "    # add the the three popular movies to the movie_impact_df\n",
    "    for index, row in top_i_3_chosen_name_movies.iterrows():\n",
    "        movie_impact_df.loc[len(movie_impact_df)] = {'name': chosen_name, 'status': 't', 'movie_id': index}\n",
    "\n",
    "    # remove the found movies from the chosen_name_movies_df to avoid picking them again for next iterations\n",
    "    chosen_name_movies_df.drop(top_i_year_chosen_name_movies.index, inplace=True)\n",
    "\n",
    "    # remove also the movies release in the frame [-5 years, +5 years] of the top1_year\n",
    "    chosen_name_movies_df.query(f'year < {top_i_year - 5} or year > {top_i_year + 5}', inplace=True)\n",
    "\n",
    "display(movie_impact_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_processed_data_path = './processed_data/'\n",
    "\n",
    "# import the name_by_movie dataframe\n",
    "name_by_movie_df = pd.read_csv(os.path.join(folder_processed_data_path, 'name_by_movie_ordered_df.csv'))\n",
    "name_by_movie_df.set_index(['wiki_ID', 'char_words', 'gender'], inplace=True)\n",
    "display(name_by_movie_df.sample(2))\n",
    "\n",
    "# import the movie dataframe\n",
    "movie_df = pd.read_csv(os.path.join(folder_processed_data_path, 'movie_df.csv'))\n",
    "movie_df.set_index(['wiki_ID'], inplace=True)\n",
    "display(movie_df.sample(2))\n",
    "\n",
    "# import the baby names dataframe\n",
    "baby_name_df = pd.read_csv(os.path.join(folder_processed_data_path, 'baby_name_df.csv'))\n",
    "baby_name_df.set_index(['name', 'year'], inplace=True)\n",
    "display(baby_name_df.sample(2))\n",
    "\n",
    "# create dataframe containing the release year of each movie\n",
    "release_year_df = movie_df[['year', 'numVotes']].copy(deep=True)\n",
    "display(release_year_df.sample(2))\n",
    "\n",
    "# import the name_by_movie with the slope difference\n",
    "name_by_movie_slope_diff_df = pd.read_csv(os.path.join(folder_processed_data_path, 'name_by_movie_ordered_pvalue_10_5_df.csv'))\n",
    "name_by_movie_slope_diff_df.set_index(['wiki_ID', 'char_words', 'gender'], inplace=True)\n",
    "display(name_by_movie_slope_diff_df.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing for the website\n",
    "In this notebook, we filter the `name_by_movie` dataframe in order to remove the movie character too little known to have had an impact on the baby names. We will assess the popularity of the charcter based on the number of IMDB ratings of the movie and whether its role was important by using the `order` attribute.\n",
    "\n",
    "In addition, an issue related to the limitation of the data is assessed here. The problem is that for two movies released the same year that has the same name for one of their character, we can't tell which of them had an impact on the name given to babies. To assess this problem, we will keep only the most popular movie based on the number of IMDB ratings.\n",
    "\n",
    "### Filtering of `name_by_movie` : number of ratings\n",
    "\n",
    "First, let's remove the character names of movies with less than 100 IMDB ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_by_movie_df.reset_index(inplace=True)\n",
    "movie_df.reset_index(inplace=True)\n",
    "\n",
    "name_by_movie_df_merged = name_by_movie_df.merge(release_year_df, left_on='wiki_ID', right_on='wiki_ID', how = 'left').copy(deep=True)\n",
    "print(f\"length of the initial dataframe : {len(name_by_movie_df)}\")\n",
    "print(f\"length of the merged dataframe : {len(name_by_movie_df_merged)}\")\n",
    "display(name_by_movie_df_merged.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_by_movie_df_merged_filter_nbratings = name_by_movie_df_merged[name_by_movie_df_merged['numVotes'] >= 1000].copy(deep=True)\n",
    "print(f\"length of the initial dataframe : {len(name_by_movie_df)}\")\n",
    "print(f\"length of the filtered dataframe : {len(name_by_movie_df_merged_filter_nbratings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering of `name_by_movie`  : importance of the role\n",
    "\n",
    "Now, lets remove the character names with an minor role in the movie. We will keep only the characters with a order higher or equal to the median of the set of order in the movie. First, let's compute the number of order for each movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is it normal that not all the movies in movies_df have at least one character in name_by_movie_df ? TODO\n",
    "# display(movie_df[movie_df['wiki_ID'] == 844398])\n",
    "# display(name_by_movie_df[name_by_movie_df['wiki_ID'] == 844398])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_by_movie_merged_groupby = name_by_movie_df_merged_filter_nbratings.groupby(['wiki_ID'])\n",
    "name_by_movie_merged_nunique = name_by_movie_merged_groupby['order'].nunique()\n",
    "\n",
    "# check for a specific movie\n",
    "test_movie_id = 617063\n",
    "\n",
    "for movie_id, group in name_by_movie_merged_groupby:\n",
    "    if(movie_id == (test_movie_id,)):\n",
    "        print('movie_id', movie_id)\n",
    "        print('group', group)\n",
    "\n",
    "print(f\"number of unique order = {name_by_movie_merged_nunique[test_movie_id]}\")\n",
    "name_by_movie_merged_nunique = name_by_movie_merged_nunique.to_frame()\n",
    "name_by_movie_merged_nunique.rename(columns={\"order\": \"nb_order\"}, inplace=True)\n",
    "display(name_by_movie_merged_nunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_by_movie_merged_with_nunique = name_by_movie_df_merged_filter_nbratings.merge(name_by_movie_merged_nunique, on='wiki_ID', how='left')\n",
    "display(name_by_movie_merged_with_nunique.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering\n",
    "name_by_movie_merged_important_role = name_by_movie_merged_with_nunique[name_by_movie_merged_with_nunique['order'] <= name_by_movie_merged_with_nunique['nb_order']].copy(deep=True)\n",
    "name_by_movie_merged_important_role.drop(columns=['order', 'nb_order'], inplace=True)\n",
    "print(f\"length of the initial dataframe : {len(name_by_movie_df)}\")\n",
    "print(f\"length of the filtered dataframe : {len(name_by_movie_merged_important_role)}\")\n",
    "display(name_by_movie_merged_important_role.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering  `name_by_movie` : keep three most famous character of the year only\n",
    "In a given year, several movies may have been released with the same name for one of their character. This is problematic because it is impossible to know which of the movie had an impact on the baby naming of the given name (if it had any). To solve this problem, we keep three most famous movies (based on the number of rating) for each year and name in the dataset. \n",
    "\n",
    "First, we need to remove the gender attribute which is annoying because some of the characters are twice in the dataset once for each genders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop gender column\n",
    "len_before = len(name_by_movie_merged_important_role)\n",
    "name_by_movie_merged_important_role.drop_duplicates(subset=['wiki_ID', 'char_words'], keep='first', inplace=True)\n",
    "name_by_movie_merged_important_role.drop(columns=['gender'], inplace=True)\n",
    "len_after = len(name_by_movie_merged_important_role)\n",
    "print(f\"length before : {len_before}\")\n",
    "print(f\"length after : {len_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can filter the `name_by_movie` dataframe in order to keep only the three most popular movies for each year and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_by_movie_merged_three_characters_only = name_by_movie_merged_important_role.sort_values(by='numVotes', ascending=False).groupby(['year', 'char_words']).head(3).reset_index(drop=True)\n",
    "\n",
    "display(name_by_movie_merged_three_characters_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make a first test to see if the filtering is correct for a specific case: the name Daniel, in 2001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check before\n",
    "test_word = 'Daniel'\n",
    "test_year = 2001\n",
    "test_df = name_by_movie_merged_important_role[name_by_movie_merged_important_role['char_words'] == test_word]\n",
    "test_df = test_df[test_df['year'] == test_year]\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check after\n",
    "test_df = name_by_movie_merged_three_characters_only[name_by_movie_merged_three_characters_only['char_words'] == test_word]\n",
    "test_df = test_df[test_df['year'] == test_year]\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"length of the initial dataframe : {len(name_by_movie_df)}\")\n",
    "print(f\"length of the filtered dataframe : {len(name_by_movie_merged_three_characters_only)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the custom `web_name_by_movie_df`\n",
    "Finally, we create the dataframe that will be used in the website. To do so, we add information about the movie on the `name_by_movie` dataframe created until now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(name_by_movie_merged_three_characters_only.sample(2))\n",
    "# display(movie_df)\n",
    "\n",
    "# Add movie info to the dataframe\n",
    "temp_merge_df = movie_df[['wiki_ID', 'mov_name', 'averageRating', 'poster_url']].copy(deep=True)\n",
    "web_name_by_movie_df = name_by_movie_merged_three_characters_only.merge(temp_merge_df, on='wiki_ID', how='left').copy(deep=True)\n",
    "\n",
    "# Reorder the columns\n",
    "desired_columns_order = ['char_words', 'wiki_ID', 'mov_name', 'year', 'averageRating', 'numVotes', 'poster_url']\n",
    "web_name_by_movie_df = web_name_by_movie_df[desired_columns_order].copy(deep=True)\n",
    "web_name_by_movie_df.set_index(['char_words', 'wiki_ID'], inplace=True)\n",
    "\n",
    "# Check if the indexing is unique\n",
    "print(f\"Is the indexing of web_name_by_movie_df unique ? {web_name_by_movie_df.index.is_unique}\")\n",
    "display(web_name_by_movie_df.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific check\n",
    "web_name_by_movie_df.loc['Elizabeth'][web_name_by_movie_df.loc['Elizabeth']['year'] == 1940]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering of `baby_name_df`\n",
    "The baby_name_df is too large to be loaded on the website. We will drop the column `number` and remove the names with too little years where there is data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(baby_name_df.head(2))\n",
    "web_baby_name_df = baby_name_df[['percentage']].copy(deep=True)\n",
    "display(web_baby_name_df.head(2))\n",
    "web_baby_name_count = web_baby_name_df.groupby(['name']).count()\n",
    "web_baby_name_count.rename(columns={\"percentage\": \"count\"}, inplace=True)\n",
    "display(web_baby_name_count.head(2))\n",
    "plt.hist(web_baby_name_count['count'], bins=100)\n",
    "plt.show()\n",
    "\n",
    "# merging\n",
    "web_baby_name_df.reset_index(inplace=True)\n",
    "web_baby_name_count.reset_index(inplace=True)\n",
    "display(web_baby_name_df.head(2))\n",
    "display(web_baby_name_count.head(2))\n",
    "web_name_by_movie_df_merged = web_baby_name_df.merge(web_baby_name_count, on='name', how='left').copy(deep=True)\n",
    "display(web_name_by_movie_df_merged.head(2))\n",
    "\n",
    "# filtering\n",
    "print(f\"size of the dataframe before filtering : {len(baby_name_df)}\")\n",
    "print(f\"size of the dataframe before filtering : {len(web_name_by_movie_df_merged)}\")\n",
    "web_baby_name_df = web_name_by_movie_df_merged[web_name_by_movie_df_merged['count'] >= 60].copy(deep=True)\n",
    "web_baby_name_df.drop(columns=['count'], inplace=True)\n",
    "web_baby_name_df.set_index(['name', 'year'], inplace=True)\n",
    "display(web_baby_name_df.head(2))\n",
    "print(f\"size of the dataframe after filtering : {len(web_baby_name_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's filter the dataframe web_baby_name_df to anticipate the ploting\n",
    "web_baby_name_df.sort_values(by=['year'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the TOP5/5NULLFAMOUS/BOTTOM5\n",
    "We need also a dataframe containing for each name in the `baby_name` dataset, 10 years where a variation of the baby names are significant (5 with the largest positive variation and 5 with the largest negative variation) as well as 5 popular movies where the variation is not significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(name_by_movie_slope_diff_df.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the gender because we won't consider it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop gender column\n",
    "len_before = len(name_by_movie_slope_diff_df)\n",
    "name_by_movie_slope_diff_without_gender_df = name_by_movie_slope_diff_df.copy(deep=True)\n",
    "name_by_movie_slope_diff_without_gender_df.reset_index(inplace=True)\n",
    "name_by_movie_slope_diff_without_gender_df.drop_duplicates(subset=['wiki_ID', 'char_words'], keep='first', inplace=True)\n",
    "name_by_movie_slope_diff_without_gender_df.drop(columns=['gender'], inplace=True)\n",
    "len_after = len(name_by_movie_slope_diff_without_gender_df)\n",
    "print(f\"length before : {len_before}\")\n",
    "print(f\"length after : {len_after}\")\n",
    "display(name_by_movie_slope_diff_without_gender_df.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless columns\n",
    "name_by_movie_with_slope_only = name_by_movie_slope_diff_without_gender_df.drop(columns=['order', 'p_value', 't_stat']).copy(deep=True)\n",
    "display(name_by_movie_with_slope_only.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's tackle the computing of the 5 TOP and 5 BOTTOM years with the most variation per names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_and_year_df = movie_df[['wiki_ID', 'year']].copy(deep=True)\n",
    "display(movie_id_and_year_df.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the release year into the name_by_movie_with_slope_only dataframe\n",
    "name_by_movie_with_slope_and_year = name_by_movie_with_slope_only.merge(movie_id_and_year_df, on='wiki_ID', how='left').copy(deep=True)\n",
    "display(name_by_movie_with_slope_and_year.sample(2))\n",
    "\n",
    "# check for a specific name and year\n",
    "name_by_movie_with_slope_and_year.set_index(['char_words', 'year'], inplace=True)\n",
    "display(name_by_movie_with_slope_and_year.loc['Elizabeth', 2004]) # ok, everything is fine\n",
    "name_by_movie_with_slope_and_year.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(name_by_movie_with_slope_and_year.head(2))\n",
    "name_by_year_with_slop_change = name_by_movie_with_slope_and_year.drop_duplicates(subset=['char_words', 'year'], keep='first').copy(deep=True)\n",
    "name_by_year_with_slop_change.drop(columns=['wiki_ID'], inplace=True)\n",
    "name_by_year_with_slop_change.dropna(subset='slope_change', inplace=True)\n",
    "display(name_by_year_with_slop_change.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top and bottom 5 years for each name\n",
    "top_5_years = name_by_year_with_slop_change.groupby('char_words').apply(lambda x: x.nlargest(5, 'slope_change')).reset_index(drop=True).copy(deep=True)\n",
    "bottom_5_years = name_by_year_with_slop_change.groupby('char_words').apply(lambda x: x.nsmallest(5, 'slope_change')).reset_index(drop=True).copy(deep=True)\n",
    "\n",
    "# Add a column indicating whether it is a top or bottom year\n",
    "top_5_years['top_or_bottom'] = 'top'\n",
    "bottom_5_years['top_or_bottom'] = 'bottom'\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "web_top_bottom_df = pd.concat([top_5_years, bottom_5_years], ignore_index=True).copy(deep=True)\n",
    "\n",
    "# Drop the column used for sorting and set the index columns\n",
    "web_top_bottom_df.set_index(['char_words', 'top_or_bottom'], inplace=True)\n",
    "\n",
    "display(web_top_bottom_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an issue when the are less than 5 years with a positive slope and when there are less than 5 years with a negative slope. The next cell solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(web_top_bottom_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(web_top_bottom_df.loc['Maxime',:]) ## There should be only positive value in for the top years and only negative values for the bottom years\n",
    "\n",
    "# To solve this problem :\n",
    "web_top_bottom_df_no_index = web_top_bottom_df.reset_index().copy(deep=True)\n",
    "web_top_bottom_filtered_df = web_top_bottom_df_no_index[~((web_top_bottom_df_no_index['slope_change'] < 0) & (web_top_bottom_df_no_index['top_or_bottom'] == 'top')) & ~((web_top_bottom_df_no_index['slope_change'] > 0) & (web_top_bottom_df_no_index['top_or_bottom'] == 'bottom'))].copy(deep=True)\n",
    "web_top_bottom_filtered_df.set_index(['char_words', 'top_or_bottom'], inplace=True)\n",
    "\n",
    "display(web_top_bottom_filtered_df.loc['Maxime',:]) ## There should be only positive value in for the top years and only negative values for the bottom years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_top_bottom_df = web_top_bottom_filtered_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check TOP 5 and BOTTOM 5 computation with a specific name\n",
    "name_by_year_with_slop_change.reset_index(inplace=True)\n",
    "name_by_year_with_slop_change.set_index(['char_words', 'year'], inplace=True)\n",
    "display(name_by_year_with_slop_change)\n",
    "display(name_by_year_with_slop_change.loc['Elizabeth', :])\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "# Create a scatter plot using Plotly Express\n",
    "fig = px.scatter(name_by_year_with_slop_change.loc['Elizabeth', :].reset_index(), x='year', y='slope_change', title='Interactive Scatter Plot', labels={'X': 'X-axis', 'Y': 'Y-axis'})\n",
    "\n",
    "# Add cursor tooltip\n",
    "fig.update_layout(hovermode='closest')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "display(web_top_bottom_df.loc['Elizabeth', :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check passed, we can drop the column slope_change\n",
    "web_top_bottom_df.drop(columns=['slope_change'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each name in the `web_name_by_movie` dataframe, we gather all the movies that have this name for one of its character and that are not significant. Then we take the first 5 of this list and add it into a new dataframe called `5_famous_movies_but_unsignificant_by_name`\n",
    "\n",
    "We reuse the dataframe `name_by_movie_slope_diff_without_gender_df` computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(name_by_movie_slope_diff_without_gender_df.head())\n",
    "print(f\"Length before : {len(name_by_movie_slope_diff_without_gender_df)}\")\n",
    "\n",
    "# first we can remove all the rows where the p_value is a NaN\n",
    "name_by_movie_slope_diff_without_gender_filtered = name_by_movie_slope_diff_without_gender_df.copy(deep=True)\n",
    "name_by_movie_slope_diff_without_gender_filtered.dropna(subset=['p_value'], inplace=True)\n",
    "# we can remove the columsn we don't need\n",
    "name_by_movie_slope_diff_without_gender_filtered.drop(columns=['order', 'slope_change', 't_stat'], inplace=True)\n",
    "display(name_by_movie_slope_diff_without_gender_filtered.head())\n",
    "print(f\"Length after : {len(name_by_movie_slope_diff_without_gender_filtered)}\")\n",
    "\n",
    "print(f\"Length before : {len(name_by_movie_slope_diff_without_gender_df)}\")\n",
    "# keep only non-significent rows\n",
    "name_by_movie_non_significent = name_by_movie_slope_diff_without_gender_filtered[name_by_movie_slope_diff_without_gender_filtered['p_value'] >= 0.1].copy(deep=True)\n",
    "name_by_movie_non_significent.drop(columns=['p_value'], inplace=True)\n",
    "display(name_by_movie_non_significent.head())\n",
    "print(f\"Length after : {len(name_by_movie_non_significent)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the attribute 'numVotes' from the movie_df dataframe with a merge\n",
    "temp_merge_df = movie_df[['wiki_ID', 'numVotes']].copy(deep=True)\n",
    "display(temp_merge_df.head())\n",
    "name_by_movie_non_significent_with_numvotes = name_by_movie_non_significent.merge(temp_merge_df, on='wiki_ID', how='left').copy(deep=True)\n",
    "display(name_by_movie_non_significent_with_numvotes.head())\n",
    "print(f\"length of name_by_movie_non_significent_with_numvotes : {len(name_by_movie_non_significent_with_numvotes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the DataFrame by 'name' and 'scores' in descending order\n",
    "# df_sorted = name_by_movie_non_significent_with_numvotes.sort_values(by=['char_words', 'numVotes'], ascending=[True, False])\n",
    "name_by_movie_non_significent_with_numvotes_sorted = name_by_movie_non_significent_with_numvotes.sort_values(by='numVotes', ascending=False).copy(deep=True)\n",
    "display(name_by_movie_non_significent_with_numvotes_sorted.head())\n",
    "\n",
    "# Extracting the top 5 rows for each 'name'\n",
    "web_top_famous_but_insi = name_by_movie_non_significent_with_numvotes_sorted.groupby('char_words').head(5).copy(deep=True)\n",
    "web_top_famous_but_insi.set_index(['char_words'], inplace=True)\n",
    "web_top_famous_but_insi.drop(columns=['numVotes'], inplace=True)\n",
    "display(web_top_famous_but_insi.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_website_data_folder = './processed_data/website/'\n",
    "\n",
    "display(web_name_by_movie_df.reset_index().head())\n",
    "# Export DataFrame to a CSV file in the processed data folder\n",
    "web_name_by_movie_df.reset_index().to_csv(os.path.join(processed_website_data_folder, 'web_name_by_movie_df.csv'), index=False)\n",
    "\n",
    "display(web_baby_name_df.reset_index().head())\n",
    "# Export DataFrame to a CSV file in the processed data folder\n",
    "web_baby_name_df.reset_index().to_csv(os.path.join(processed_website_data_folder, 'web_baby_name_df.csv'), index=False)\n",
    "\n",
    "display(web_top_bottom_df.reset_index().head())\n",
    "# Export DataFrame to a CSV file in the processed data folder\n",
    "web_top_bottom_df.reset_index().to_csv(os.path.join(processed_website_data_folder, 'web_top_bottom_df.csv'), index=False)\n",
    "\n",
    "display(web_top_famous_but_insi.reset_index().head())\n",
    "# Export DataFrame to a CSV file in the processed data folder\n",
    "web_top_famous_but_insi.reset_index().to_csv(os.path.join(processed_website_data_folder, 'web_top_famous_but_insi.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be set by the user\n",
    "chosen_name = 'Elizabeth'\n",
    "\n",
    "web_baby_name_df.reset_index(inplace=True)\n",
    "web_baby_name_df.set_index(['name'], inplace=True)\n",
    "\n",
    "x_values = web_baby_name_df.loc[chosen_name]['year'].values\n",
    "y_values = web_baby_name_df.loc[chosen_name]['percentage'].values\n",
    "\n",
    "# Ploting\n",
    "plt.plot(x_values, y_values)\n",
    "plt.xlabel('Years')\n",
    "plt.ylabel('Percentage of total births')\n",
    "plt.title(f'Name \"{chosen_name}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 5 years from the web data\n",
    "top_5_years = web_top_bottom_df.loc[chosen_name, 'top'].values[:,0]\n",
    "print(f\"top_5_years = {top_5_years}\")\n",
    "data_top_5_years = web_name_by_movie_df[(web_name_by_movie_df['char_words'] == chosen_name) & (web_name_by_movie_df['year'].isin(top_5_years))].copy(deep=True)\n",
    "display(data_top_5_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the bottom 5 years from the web data\n",
    "bottom_5_years = web_top_bottom_df.loc[chosen_name, 'bottom'].values[:,0]\n",
    "print(f\"bottom_5_years = {bottom_5_years}\")\n",
    "data_bottom_5_years = web_name_by_movie_df[(web_name_by_movie_df['char_words'] == chosen_name) & (web_name_by_movie_df['year'].isin(bottom_5_years))].copy(deep=True)\n",
    "display(data_bottom_5_years)\n",
    "\n",
    "# # only three movies for the chosen name 'Thomas' ? instead of 3x5=15 ? check the top 5 years seperately\n",
    "# display(web_name_by_movie_df[(web_name_by_movie_df['char_words'] == chosen_name) & (web_name_by_movie_df['year'] == bottom_5_years[0])])\n",
    "# display(web_name_by_movie_df[(web_name_by_movie_df['char_words'] == chosen_name) & (web_name_by_movie_df['year'] == bottom_5_years[1])])\n",
    "# display(web_name_by_movie_df[(web_name_by_movie_df['char_words'] == chosen_name) & (web_name_by_movie_df['year'] == bottom_5_years[2])])\n",
    "# display(web_name_by_movie_df[(web_name_by_movie_df['char_words'] == chosen_name) & (web_name_by_movie_df['year'] == bottom_5_years[3])])\n",
    "# display(web_name_by_movie_df[(web_name_by_movie_df['char_words'] == chosen_name) & (web_name_by_movie_df['year'] == bottom_5_years[4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 5 famous but insignificant movies from the web data\n",
    "id_5_famous_movies_but_insignificant = web_top_famous_but_insi.loc[chosen_name].values[:,0]\n",
    "print(f\"id_5_famous_movies_but_insignificant = {id_5_famous_movies_but_insignificant}\")\n",
    "\n",
    "web_name_by_movie_df.reset_index(inplace=True)\n",
    "data_5_famous_movies_but_insignificant = web_name_by_movie_df[(web_name_by_movie_df['char_words'] == chosen_name) & (web_name_by_movie_df['wiki_ID'].isin(id_5_famous_movies_but_insignificant))]\n",
    "display(data_5_famous_movies_but_insignificant)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
