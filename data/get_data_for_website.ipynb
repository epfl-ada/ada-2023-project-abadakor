{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for interactive plot\n",
    "In this notebook, three csv files are generated for the website interactive plot.\n",
    "- **movie_impact.csv** : contains the movies to add as scatter points on the baby_name curve for positive, negative and insignificant variations. <br>\n",
    "        Columns: `['name', 'status', 'group_year', 'movie_id']` <br>\n",
    "        `'status'` contains either `'t'`, `'b'`, `'i'` for positive, negative and insignificant variation respectively <br>\n",
    "        `'group_year'` correspond to the year where the movie must be displayed\n",
    "\n",
    "- **name_per_year.csv** : contains the baby names data for each name and year. The data is in fraction of the total newborns of the year (in percent).<br>\n",
    "Columns: `['name', 'year', 'percentage']`\n",
    "\n",
    "- **movies.csv** : contains the movie informations and objects needed to construct the links to the poster and the IMDB wesite. <br>\n",
    "Columns: `['movie_id', 'mov_name', 'year', 'vote', 'rating', 'poster_url' 'imdb_id]`\n",
    "\n",
    "All of them are simplified version of the dataframe computed in [preprocessing.ipynb](./preprocessing.ipynb), in order to simplify the plot generation on the website and to avoid slowing down the website with too much data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_processed_data_path = './processed_data/'\n",
    "processed_website_data_folder = './processed_data/website/'\n",
    "tmp_data_folder = './tmp_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the dataframe computed in preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the name by movie\n",
    "name_by_movie_df = pd.read_csv(os.path.join(folder_processed_data_path, 'name_by_movie_ordered_pvalue_10_5_df.csv'))\n",
    "name_by_movie_df.set_index(['wiki_ID', 'char_words', 'gender'], inplace=True)\n",
    "display(name_by_movie_df.sample(2))\n",
    "\n",
    "# import the movie dataframe\n",
    "movie_df = pd.read_csv(os.path.join(folder_processed_data_path, 'movie_df.csv'))\n",
    "movie_df.set_index(['wiki_ID'], inplace=True)\n",
    "display(movie_df.sample(2))\n",
    "\n",
    "# import the name_by_movie dataframe\n",
    "baby_name_df = pd.read_csv(os.path.join(tmp_data_folder, 'zero_padding_baby_name_df.csv'))\n",
    "baby_name_df.set_index(['name', 'year'], inplace=True)\n",
    "display(baby_name_df.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute `movie_impact` dataframe\n",
    "\n",
    "The dataframe `movie_impact` is a subset of the dataframe `name_by_movie` computed in [preprocessing.ipynb](./preprocessing.ipynb).\n",
    "\n",
    "### Filtering of `name_by_movie`  : importance of the role\n",
    "\n",
    "Lets remove the character names with an minor role in the movie. We will keep only the characters with an order higher or equal to the median of the set of order in the movie. First, let's compute the number of order for each movies and merge it the `name_by_movie` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the order count of each movie\n",
    "name_by_movie_groupby_id = name_by_movie_df.groupby(['wiki_ID'])\n",
    "order_counts = name_by_movie_groupby_id['order'].count()\n",
    "\n",
    "# convert from serie to dataframe and rename the columns\n",
    "order_counts_df = order_counts.to_frame()\n",
    "order_counts_df.rename(columns={\"order\": \"nb_order\"}, inplace=True)\n",
    "display(order_counts_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the order count with name_by_movie_df\n",
    "name_by_movie_order_counts = name_by_movie_df.reset_index().merge(order_counts_df, on='wiki_ID', how='left')\n",
    "display(name_by_movie_order_counts.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a special case with tommy character in Titanic (1997)\n",
    "name_by_movie_order_counts[name_by_movie_order_counts['wiki_ID'] == 52371]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to keep only half of the characters with the lowest order\n",
    "name_by_movie_merged_important_role = name_by_movie_order_counts[name_by_movie_order_counts['order'] <= (name_by_movie_order_counts['nb_order']/2)].copy(deep=True)\n",
    "\n",
    "print(f\"length of the dataframe : {len(name_by_movie_df)} -> {len(name_by_movie_merged_important_role)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check case with tommy charcater in titanic\n",
    "name_by_movie_merged_important_role[name_by_movie_merged_important_role['wiki_ID'] == 52371]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this dataframe as name_by_movie_df\n",
    "name_by_movie_df = name_by_movie_merged_important_role.copy(deep=True)\n",
    "print(f\"Length of the name_by_movie_df : {len(name_by_movie_df)}\")\n",
    "print(f\"Is the indexing of name_by_movie_web unique? {name_by_movie_df.index.is_unique}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing `name_by_movie`\n",
    "In this section, we remove useless columns and NaN values, add the movie release year for each character and set the name in lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove useless 't_stat' column\n",
    "name_by_movie_web = name_by_movie_df.reset_index().copy(deep=True)\n",
    "name_by_movie_web.drop(columns=['index', 't_stat', 'order', 'nb_order'], inplace=True)\n",
    "display(name_by_movie_web.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop gender column\n",
    "len_before = len(name_by_movie_web)\n",
    "\n",
    "name_by_movie_web.reset_index(inplace=True, drop=True)\n",
    "name_by_movie_web.drop_duplicates(subset=['wiki_ID', 'char_words'], keep='first', inplace=True)\n",
    "name_by_movie_web.drop(columns=['gender'], inplace=True)\n",
    "name_by_movie_web.set_index(['char_words', 'wiki_ID'], inplace=True)\n",
    "\n",
    "len_after = len(name_by_movie_web)\n",
    "print(f\"length of the dataframe : {len_before} -> {len_after}\")\n",
    "print(f\"Is the indexing of name_by_movie_web unique? {name_by_movie_web.index.is_unique}\")\n",
    "display(name_by_movie_web.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with NaN values in 'p_value' column\n",
    "len_before = len(name_by_movie_web)\n",
    "name_by_movie_web.dropna(subset=['p_value'], inplace=True)\n",
    "len_after = len(name_by_movie_web)\n",
    "print(f\"length : {len_before} -> {len_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add needed info about movie for deducing the TOP/BOTTOM/INSIGN movies\n",
    "needed_movie_info = movie_df.reset_index()[['wiki_ID', 'year', 'averageRating', 'numVotes']].copy(deep=True)\n",
    "\n",
    "len_before_merge = len(name_by_movie_web)\n",
    "name_by_movie_with_info = name_by_movie_web.reset_index().merge(needed_movie_info, on='wiki_ID', how='left').copy(deep=True) # merge the release year into the name_by_movie_web dataframe\n",
    "len_after_merge = len(name_by_movie_with_info)\n",
    "print(f\"length : {len_before_merge} -> {len_after_merge}\")\n",
    "\n",
    "name_by_movie_with_info.set_index(['char_words', 'wiki_ID'], inplace=True)\n",
    "display(name_by_movie_with_info.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the char_words in lowercase\n",
    "name_by_movie_with_info.reset_index(inplace=True)\n",
    "name_by_movie_with_info['char_words'] = name_by_movie_with_info['char_words'].str.lower()\n",
    "name_by_movie_with_info.set_index(['char_words', 'wiki_ID'], inplace=True)\n",
    "print(f\"Length of name_by_movie_with_info : {len(name_by_movie_with_info)}\")\n",
    "display(name_by_movie_with_info.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the movie_impact dataframe\n",
    "columns = ['name', 'status', 'group_year', 'movie_id']\n",
    "movie_impact_df = pd.DataFrame(columns=columns)\n",
    "display(movie_impact_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three functions to compute TOP/BOTTOM/INSIGN\n",
    "These three functions are used to compute the `movie_impact_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_movies(name, chosen_name_movies_top_df, chosen_name_movies_df, movie_impact_df):\n",
    "    for i in range(5): # from top1 to top5\n",
    "        if(not chosen_name_movies_top_df.empty):\n",
    "            # get the year with the highest positive variation\n",
    "            top_i_year = chosen_name_movies_top_df.iloc[-1].year.astype(int)\n",
    "\n",
    "            # get the movies released close to the year with the highest positive variation [top_i_year-3, top_i_year+3]\n",
    "            top_i_year_chosen_name_movies = chosen_name_movies_df.query(f'year >= {top_i_year - 3} and year <= {top_i_year + 3}').copy(deep=True)\n",
    "\n",
    "            # keep only the three most popular movies\n",
    "            top_i_year_chosen_name_movies.sort_values(by=['numVotes'], ascending=False, inplace=True)\n",
    "            top_i_3_chosen_name_movies = top_i_year_chosen_name_movies.iloc[:3].copy(deep=True)\n",
    "\n",
    "            # add the the three popular movies to the movie_impact_df\n",
    "            for index, row in top_i_3_chosen_name_movies.iterrows():\n",
    "                movie_impact_df.loc[len(movie_impact_df)] = {'name': name, 'status': 't', 'group_year': top_i_year, 'movie_id': index}\n",
    "\n",
    "            # remove also the movies release in the frame [-5 years, +5 years] of the top1_year\n",
    "            chosen_name_movies_top_df.query(f'year < {top_i_year - 5} or year > {top_i_year + 5}', inplace=True)\n",
    "\n",
    "            # remove the found movies from the chosen_name_movies_df to avoid picking them again for next iterations\n",
    "            chosen_name_movies_df.drop(top_i_3_chosen_name_movies.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bottom_movies(name, chosen_name_movies_bottom_df, chosen_name_movies_df, movie_impact_df):\n",
    "    for i in range(5): # from bottom1 to bottom5\n",
    "        if(not chosen_name_movies_bottom_df.empty):\n",
    "            # get the year with the highest negative variation\n",
    "            bottom_i_year = chosen_name_movies_bottom_df.iloc[-1].year.astype(int)\n",
    "\n",
    "            # get the movies released close to the year with the highest negative variation [bottom_i_year-3, bottom_i_year+3]\n",
    "            bottom_i_year_chosen_name_movies = chosen_name_movies_df.query(f'year >= {bottom_i_year - 3} and year <= {bottom_i_year + 3}').copy(deep=True)\n",
    "\n",
    "            # keep only the three most popular movies\n",
    "            bottom_i_year_chosen_name_movies.sort_values(by=['numVotes'], ascending=False, inplace=True)\n",
    "            bottom_i_3_chosen_name_movies = bottom_i_year_chosen_name_movies.iloc[:3].copy(deep=True)\n",
    "\n",
    "            # add the the three popular movies to the movie_impact_df\n",
    "            for index, row in bottom_i_3_chosen_name_movies.iterrows():\n",
    "                movie_impact_df.loc[len(movie_impact_df)] = {'name': name, 'status': 'b', 'group_year': bottom_i_year, 'movie_id': index}\n",
    "\n",
    "            # remove also the movies release in the frame [-5 years, +5 years] of the bottom_i_year\n",
    "            chosen_name_movies_bottom_df.query(f'year < {bottom_i_year - 5} or year > {bottom_i_year + 5}', inplace=True)\n",
    "\n",
    "            # remove the found movies from the chosen_name_movies_df to avoid picking them again for next iterations\n",
    "            chosen_name_movies_df.drop(bottom_i_3_chosen_name_movies.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_insign_movies(name, chosen_name_movies_insign_df, movie_impact_df):\n",
    "    for i in range(5): # from insign1 to insign5\n",
    "        if(not chosen_name_movies_insign_df.empty):\n",
    "            # get the movies release the year with the highest rating and number of votes\n",
    "            insign_i_year = chosen_name_movies_insign_df.iloc[-1].year.astype(int)\n",
    "            insign_i_year_chosen_name_movies = chosen_name_movies_insign_df.query(f'year == {insign_i_year}').copy(deep=True)\n",
    "\n",
    "            # add the most popular movie to the movie_impact_df\n",
    "            movie_impact_df.loc[len(movie_impact_df)] = {'name': name, 'status': 'i', 'group_year': insign_i_year, 'movie_id': insign_i_year_chosen_name_movies.index[0]}\n",
    "\n",
    "            # remove the found movies from the chosen_name_movies_top_df to avoid picking them again for next iterations\n",
    "            chosen_name_movies_insign_df.drop(insign_i_year_chosen_name_movies.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Special case for a single name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given name by user\n",
    "chosen_name = 'elizabeth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the movie containing the chosen name\n",
    "chosen_name_movies_df = name_by_movie_with_info.loc[chosen_name, :].copy(deep=True)\n",
    "display(chosen_name_movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by slope_change to have the movies ranked by how big the variation is in the movie release year\n",
    "chosen_name_movies_df.sort_values(by=['slope_change'], inplace=True)\n",
    "\n",
    "# keep only the candidate movies for the TOP 5 movies with positive impact\n",
    "chosen_name_movies_top_df = chosen_name_movies_df.query('(slope_change > 0) and (p_value < 0.1)').copy(deep=True)\n",
    "display(chosen_name_movies_top_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute TOP 5 and add it to the movie_impact_df\n",
    "compute_top_movies(chosen_name, chosen_name_movies_top_df, chosen_name_movies_df, movie_impact_df)\n",
    "display(movie_impact_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the candidate movies for the BOTTOM 5 movies with negative impact\n",
    "chosen_name_movies_bottom_df = chosen_name_movies_df.query('(slope_change <= 0) and (p_value < 0.1)').copy(deep=True)\n",
    "# sort by slope_change in the opposite direction to have the highest negative variation at the end\n",
    "chosen_name_movies_bottom_df.sort_values(by=['slope_change'], ascending=True, inplace=True)\n",
    "display(chosen_name_movies_bottom_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute BOTTOM 5 and add it to the movie_impact_df\n",
    "compute_bottom_movies(chosen_name, chosen_name_movies_bottom_df, chosen_name_movies_df, movie_impact_df)\n",
    "display(movie_impact_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the candidate movies for the top 5 most famous movies with no significant impact\n",
    "chosen_name_movies_insign_df = chosen_name_movies_df.query('p_value > 0.1').copy(deep=True)\n",
    "\n",
    "# rank them by popularity\n",
    "chosen_name_movies_insign_df.sort_values(by=['averageRating', 'numVotes'], inplace=True)\n",
    "display(chosen_name_movies_insign_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute INSIGN 5 and add it to the movie_impact_df\n",
    "compute_insign_movies(chosen_name, chosen_name_movies_insign_df, movie_impact_df)\n",
    "display(movie_impact_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there movie duplicates in the movie_impact_df\n",
    "print(f\"number of duplicates in movie_impact_df : {movie_impact_df.duplicated(subset=['movie_id']).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalize for all the names to generate `movie_impact_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the names in the name_by_movie_with_info dataframe\n",
    "names = name_by_movie_with_info.index.get_level_values(0).unique().tolist()\n",
    "print(names)\n",
    "print(f\"Number of names : {len(names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 0\n",
    "for name in names:\n",
    "    print(f\"Number of name treated: {iter}\", end='\\r', flush=True)\n",
    "    # get the movie containing the chosen name\n",
    "    chosen_name_movies_df = name_by_movie_with_info.loc[name, :].copy(deep=True)\n",
    "\n",
    "    # sort the movies by slope_change, get movies with significant p_value and positive slope_change and compute the top 5\n",
    "    chosen_name_movies_df.sort_values(by=['slope_change'], inplace=True)\n",
    "    chosen_name_movies_top_df = chosen_name_movies_df.query('(slope_change > 0) and (p_value < 0.1)').copy(deep=True)\n",
    "    compute_top_movies(name, chosen_name_movies_top_df, chosen_name_movies_df, movie_impact_df)\n",
    "\n",
    "    # sort the movies by slope_change, get movies with significant p_value and negative slope_change and compute the bottom 5\n",
    "    chosen_name_movies_bottom_df = chosen_name_movies_df.query('(slope_change <= 0) and (p_value < 0.1)').copy(deep=True)\n",
    "    chosen_name_movies_bottom_df.sort_values(by=['slope_change'], ascending=False, inplace=True)\n",
    "    compute_bottom_movies(name, chosen_name_movies_bottom_df, chosen_name_movies_df, movie_impact_df)\n",
    "\n",
    "    # get the remaining movies and filter to keep only the insignificant ones and compute the insign 5\n",
    "    chosen_name_movies_insign_df = chosen_name_movies_df.query('p_value > 0.1').copy(deep=True)\n",
    "    chosen_name_movies_insign_df.sort_values(by=['numVotes'], inplace=True)\n",
    "    compute_insign_movies(name, chosen_name_movies_insign_df, movie_impact_df)\n",
    "    \n",
    "    iter = iter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the result\n",
    "display(movie_impact_df.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Import `movie_impact` dataframe to avoid timeconsuming computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the movie_impact_df to avoid the time-consuming computation of movie_impact_df\n",
    "imported_movie_impact_df = pd.read_csv(os.path.join(processed_website_data_folder, 'movie_impacts.csv'))\n",
    "imported_movie_impact_df.set_index(['name', 'status'], inplace=True)\n",
    "display(imported_movie_impact_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values in the name column\n",
    "contains_nan = imported_movie_impact_df.reset_index()['name'].isna().any()\n",
    "\n",
    "if contains_nan:\n",
    "    print(\"The `name` column contains NaN values.\")\n",
    "else:\n",
    "    print(\"The `name` column does not contain NaN values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason, the name column contains NaN values. Let's remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN values in the name column\n",
    "print(f\"Length of imported_movie_impact_df before dropping NaN values : {len(imported_movie_impact_df)}\")\n",
    "imported_movie_impact_df.reset_index(inplace=True)\n",
    "imported_movie_impact_df.dropna(subset=['name'], inplace=True)\n",
    "imported_movie_impact_df.set_index(['name', 'status'], inplace=True)\n",
    "print(f\"Length of imported_movie_impact_df after dropping NaN values : {len(imported_movie_impact_df)}\")\n",
    "\n",
    "display(imported_movie_impact_df)\n",
    "movie_impact_df = imported_movie_impact_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values in the name column\n",
    "contains_nan = imported_movie_impact_df.reset_index()['name'].isna().any()\n",
    "\n",
    "if contains_nan:\n",
    "    print(\"The `name` column contains NaN values.\")\n",
    "else:\n",
    "    print(\"The `name` column does not contain NaN values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute `name_per_year` dataframe\n",
    "\n",
    "The dataframe `name_per_year` is a subset of the dataframe `name_by_movie` computed in [preprocessing.ipynb](./preprocessing.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove number column\n",
    "name_per_year = baby_name_df.copy(deep=True)\n",
    "name_per_year.drop(columns='number', inplace=True)\n",
    "display(name_per_year.sample(2))\n",
    "print(f\"Is the indexing of name_per_year unique? {name_per_year.index.is_unique}\")\n",
    "print(f\"Length of the name_per_year_df : {len(name_per_year)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round the percentage values to reduce the size of the future csv file for the web\n",
    "name_per_year['percentage'] = name_per_year['percentage'].round(6)\n",
    "\n",
    "# set the names in lowercases\n",
    "name_per_year.reset_index(inplace=True)\n",
    "name_per_year['name'] = name_per_year['name'].str.lower()\n",
    "name_per_year.set_index(['name', 'year'], inplace=True)\n",
    "\n",
    "display(name_per_year.sample(2))\n",
    "print(f\"Length of the name_per_year_df : {len(name_per_year)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the name_per_year_df to keep only the names in the movie_impact_df\n",
    "name_per_year_filtered = name_per_year.loc[movie_impact_df.reset_index()['name'].unique().tolist(), :].copy(deep=True)\n",
    "name_per_year = name_per_year_filtered.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sort the dataframe name_per_year to anticipate the ploting\n",
    "name_per_year.sort_values(by=['name', 'year'], inplace=True)\n",
    "display(name_per_year.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the number of names in the three dataframes in order to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute how many unique names are there in the dataframes to compare\n",
    "names_in_name_per_year = name_per_year.reset_index()['name'].unique().tolist()\n",
    "print(f\"Number of unique names in name_per_year = {len(names_in_name_per_year)}\")\n",
    "names_in_movie_impact = movie_impact_df.reset_index()['name'].unique().tolist()\n",
    "print(f\"Number of unique names in movie_impact_df = {len(names_in_movie_impact)}\")\n",
    "names_in_name_by_movie_with_info = name_by_movie_with_info.reset_index()['char_words'].unique().tolist()\n",
    "print(f\"Number of unique names in name_by_movie_with_info = {len(names_in_name_by_movie_with_info)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify names in name_by_movie not present in name_per_year\n",
    "values_only_in_name_by_movie = name_by_movie_with_info.reset_index()[~name_by_movie_with_info.reset_index()['char_words'].isin(name_per_year.reset_index()['name'])]['char_words'].unique()\n",
    "\n",
    "print(f\"Number of unique names in name_by_movie_with_info  = {len(name_by_movie_with_info.reset_index()['char_words'].unique())}\")\n",
    "\n",
    "# Display the result\n",
    "print(\"Values in name_by_movie_with_info but not present in name_per_year:\")\n",
    "print(values_only_in_name_by_movie)\n",
    "print(f\"Number of names missing  = {len(values_only_in_name_by_movie)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All good :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute `movies` dataframe\n",
    "This dataset contains the information relative to the movie given its `wiki_ID`. It is a subset of the dataframe `movie_df` computed in [preprocessing.ipynb](./preprocessing.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the movies in the movie_df that are in the movie_impact_df\n",
    "simplified_movie_df = movie_df.loc[movie_impact_df['movie_id'].unique().tolist(), :].copy(deep=True)\n",
    "\n",
    "print(f\"Number of movies in movie_impact_df : {len(movie_impact_df['movie_id'].unique())}\")\n",
    "print(f\"Number of movies kept in movie_df: {len(simplified_movie_df)}\")\n",
    "\n",
    "# remove useless columns\n",
    "simplified_movie_df.drop(columns=['month', 'revenue'], inplace=True)\n",
    "simplified_movie_df.rename(columns={'averageRating': 'rating', 'numVotes': 'votes', 'IMDB_ID': 'imdb_id'}, inplace=True)\n",
    "\n",
    "display(simplified_movie_df.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the three datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export movie_impact.csv\n",
    "display(movie_impact_df.reset_index().sample(2))\n",
    "movie_impact_df.reset_index().to_csv(os.path.join(processed_website_data_folder, 'movie_impacts.csv'), index=False)\n",
    "\n",
    "# Export name_per_year.csv\n",
    "display(name_per_year.reset_index().sample(2))\n",
    "name_per_year.reset_index().to_csv(os.path.join(processed_website_data_folder, 'name_per_year.csv'), index=False)\n",
    "\n",
    "# Export movie.csv\n",
    "display(simplified_movie_df.reset_index().sample(2))\n",
    "simplified_movie_df.reset_index().to_csv(os.path.join(processed_website_data_folder, 'movies.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
