{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) comment on catÃ©goriser le taux d'influence: t-stat\n",
    "2) is movie significant ? -> p-value\n",
    "3) same release year for several movies -> keep the one that is the most rated (number of ratings)\n",
    "4) keep categories of 5 : top 5, most 5 popular movies which are not significant, bottom 5\n",
    "5) remove all movies that have less than 100 ratings (to be determined maybe we discard too many movies or too litte...)\n",
    "6) remove all characters that have an order below the median (or mean) of the number of character in the movie.\n",
    "7) Careful : the number of movies with significant impact on baby names may drop a lot due to the point 5 and 6\n",
    "8) the point 5 and 6 must be done also for the global study and not only for the website interactive heading (TO BE DISCUSSED!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_processed_data_path = './processed_data/'\n",
    "processed_website_data_folder = './processed_data/website/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>order</th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "      <th>t_stat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>char_words</th>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14935392</th>\n",
       "      <th>Deuce</th>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522855</th>\n",
       "      <th>Haskell</th>\n",
       "      <th>M</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.894676</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>0.135485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            order   p_value  slope_change    t_stat\n",
       "wiki_ID  char_words gender                                         \n",
       "14935392 Deuce      NaN       NaN       NaN           NaN       NaN\n",
       "1522855  Haskell    M        11.0  0.894676     -0.000014  0.135485"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mov_name</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>revenue</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>poster_url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28745625</th>\n",
       "      <td>Batasari</td>\n",
       "      <td>1961</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>5.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095464</th>\n",
       "      <td>Mirch Masala</td>\n",
       "      <td>1985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1523</td>\n",
       "      <td>7.7</td>\n",
       "      <td>/j7vOnZuTnr420zdw3LDIq7froce.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mov_name  year  month  revenue  numVotes  averageRating  \\\n",
       "wiki_ID                                                                 \n",
       "28745625      Batasari  1961    7.0      NaN        19            5.9   \n",
       "2095464   Mirch Masala  1985    NaN      NaN      1523            7.7   \n",
       "\n",
       "                                poster_url  \n",
       "wiki_ID                                     \n",
       "28745625                               NaN  \n",
       "2095464   /j7vOnZuTnr420zdw3LDIq7froce.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import the name by movie\n",
    "name_by_movie_df = pd.read_csv(os.path.join(folder_processed_data_path, 'name_by_movie_ordered_pvalue_10_5_df.csv'))\n",
    "name_by_movie_df.set_index(['wiki_ID', 'char_words', 'gender'], inplace=True)\n",
    "display(name_by_movie_df.sample(2))\n",
    "\n",
    "# import the movie dataframe\n",
    "movie_df = pd.read_csv(os.path.join(folder_processed_data_path, 'movie_df.csv'))\n",
    "movie_df.set_index(['wiki_ID'], inplace=True)\n",
    "display(movie_df.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute `movie_impact` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given name by user\n",
    "chosen_name = 'trinity'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's compute the 5 years with the most change in the babies for the chosen name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>char_words</th>\n",
       "      <th>gender</th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61689</th>\n",
       "      <td>4242732</td>\n",
       "      <td>Harvey</td>\n",
       "      <td>M</td>\n",
       "      <td>0.88454</td>\n",
       "      <td>-0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157329</th>\n",
       "      <td>29309335</td>\n",
       "      <td>Kavi</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         wiki_ID char_words gender  p_value  slope_change\n",
       "61689    4242732     Harvey      M  0.88454     -0.000082\n",
       "157329  29309335       Kavi      M      NaN           NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove useless columns\n",
    "name_by_movie_web = name_by_movie_df.reset_index().copy(deep=True)\n",
    "name_by_movie_web.drop(columns=['order', 't_stat'], inplace=True)\n",
    "display(name_by_movie_web.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length : 172906 -> 167984\n",
      "Is the indexing of name_by_movie_web unique? True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_words</th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Harper</th>\n",
       "      <th>23463534</th>\n",
       "      <td>0.997227</td>\n",
       "      <td>-8.334226e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brink</th>\n",
       "      <th>6446044</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      p_value  slope_change\n",
       "char_words wiki_ID                         \n",
       "Harper     23463534  0.997227 -8.334226e-07\n",
       "Brink      6446044        NaN           NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# drop gender column\n",
    "len_before = len(name_by_movie_web)\n",
    "\n",
    "name_by_movie_web.reset_index(inplace=True, drop=True)\n",
    "name_by_movie_web.drop_duplicates(subset=['wiki_ID', 'char_words'], keep='first', inplace=True)\n",
    "name_by_movie_web.drop(columns=['gender'], inplace=True)\n",
    "name_by_movie_web.set_index(['char_words', 'wiki_ID'], inplace=True)\n",
    "\n",
    "len_after = len(name_by_movie_web)\n",
    "print(f\"length : {len_before} -> {len_after}\")\n",
    "print(f\"Is the indexing of name_by_movie_web unique? {name_by_movie_web.index.is_unique}\")\n",
    "display(name_by_movie_web.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length : 167984 -> 116464\n"
     ]
    }
   ],
   "source": [
    "# drop NaN values\n",
    "len_before = len(name_by_movie_web)\n",
    "name_by_movie_web.dropna(subset=['p_value'], inplace=True)\n",
    "len_after = len(name_by_movie_web)\n",
    "print(f\"length : {len_before} -> {len_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length : 116464 -> 116464\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "      <th>year</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_words</th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Clifford</th>\n",
       "      <th>952902</th>\n",
       "      <td>0.108558</td>\n",
       "      <td>-0.001012</td>\n",
       "      <td>2000</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spencer</th>\n",
       "      <th>3599765</th>\n",
       "      <td>0.471155</td>\n",
       "      <td>-0.000429</td>\n",
       "      <td>1956</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     p_value  slope_change  year  averageRating  numVotes\n",
       "char_words wiki_ID                                                       \n",
       "Clifford   952902   0.108558     -0.001012  2000            6.7      3831\n",
       "Spencer    3599765  0.471155     -0.000429  1956            6.9      5767"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add the year of release of the movie to the name_by_movie_web dataframe\n",
    "\n",
    "needed_movie_info = movie_df.reset_index()[['wiki_ID', 'year', 'averageRating', 'numVotes']].copy(deep=True)\n",
    "\n",
    "len_before_merge = len(name_by_movie_web)\n",
    "name_by_movie_with_info = name_by_movie_web.reset_index().merge(needed_movie_info, on='wiki_ID', how='left').copy(deep=True) # merge the release year into the name_by_movie_web dataframe\n",
    "len_after_merge = len(name_by_movie_with_info)\n",
    "print(f\"length : {len_before_merge} -> {len_after_merge}\")\n",
    "\n",
    "name_by_movie_with_info.set_index(['char_words', 'wiki_ID'], inplace=True)\n",
    "display(name_by_movie_with_info.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of name_by_movie_with_info : 116464\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "      <th>year</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_words</th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sam</th>\n",
       "      <th>21678052</th>\n",
       "      <td>0.390860</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>2010</td>\n",
       "      <td>5.1</td>\n",
       "      <td>256116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>william</th>\n",
       "      <th>3662683</th>\n",
       "      <td>0.673892</td>\n",
       "      <td>-0.003222</td>\n",
       "      <td>2006</td>\n",
       "      <td>5.5</td>\n",
       "      <td>25100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      p_value  slope_change  year  averageRating  numVotes\n",
       "char_words wiki_ID                                                        \n",
       "sam        21678052  0.390860      0.000379  2010            5.1    256116\n",
       "william    3662683   0.673892     -0.003222  2006            5.5     25100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set the char_names in lowercase\n",
    "name_by_movie_with_info.reset_index(inplace=True)\n",
    "name_by_movie_with_info['char_words'] = name_by_movie_with_info['char_words'].str.lower()\n",
    "name_by_movie_with_info.set_index(['char_words', 'wiki_ID'], inplace=True)\n",
    "print(f\"Length of name_by_movie_with_info : {len(name_by_movie_with_info)}\")\n",
    "display(name_by_movie_with_info.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, status, movie_id]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the movie_impact dataframe\n",
    "columns = ['name', 'status', 'movie_id']\n",
    "movie_impact_df = pd.DataFrame(columns=columns)\n",
    "display(movie_impact_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to compute TOP/BOTTOM/INSIGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_movies(name, chosen_name_movies_top_df, movie_impact_df):\n",
    "    for i in range(5): # from top1 to top5\n",
    "        if(not chosen_name_movies_top_df.empty):\n",
    "            # get the movies release the year with the highest positive variation\n",
    "            top_i_year = chosen_name_movies_top_df.iloc[-1].year.astype(int)\n",
    "            top_i_year_chosen_name_movies = chosen_name_movies_top_df.query(f'year == {top_i_year}').copy(deep=True)\n",
    "\n",
    "            # keep only the three most popular movies\n",
    "            top_i_year_chosen_name_movies.sort_values(by=['numVotes'], ascending=False, inplace=True)\n",
    "            top_i_3_chosen_name_movies = top_i_year_chosen_name_movies.iloc[:3].copy(deep=True)\n",
    "\n",
    "            # add the the three popular movies to the movie_impact_df\n",
    "            for index, row in top_i_3_chosen_name_movies.iterrows():\n",
    "                movie_impact_df.loc[len(movie_impact_df)] = {'name': name, 'status': 't', 'movie_id': index}\n",
    "\n",
    "            # remove the found movies from the chosen_name_movies_top_df to avoid picking them again for next iterations\n",
    "            chosen_name_movies_top_df.drop(top_i_year_chosen_name_movies.index, inplace=True)\n",
    "\n",
    "            # remove also the movies release in the frame [-5 years, +5 years] of the top1_year\n",
    "            chosen_name_movies_top_df.query(f'year < {top_i_year - 5} or year > {top_i_year + 5}', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bottom_movies(name, chosen_name_movies_bottom_df, movie_impact_df):\n",
    "    for i in range(5): # from bottom1 to bottom5\n",
    "        if(not chosen_name_movies_bottom_df.empty):\n",
    "            # get the movies release the year with the highest negative variation\n",
    "            bottom_i_year = chosen_name_movies_bottom_df.iloc[-1].year.astype(int)\n",
    "            bottom_i_year_chosen_name_movies = chosen_name_movies_bottom_df.query(f'year == {bottom_i_year}').copy(deep=True)\n",
    "\n",
    "            # keep only the three most popular movies\n",
    "            bottom_i_year_chosen_name_movies.sort_values(by=['numVotes'], ascending=False, inplace=True)\n",
    "            bottom_i_3_chosen_name_movies = bottom_i_year_chosen_name_movies.iloc[:3].copy(deep=True)\n",
    "\n",
    "            # add the the three popular movies to the movie_impact_df\n",
    "            for index, row in bottom_i_3_chosen_name_movies.iterrows():\n",
    "                movie_impact_df.loc[len(movie_impact_df)] = {'name': name, 'status': 'b', 'movie_id': index}\n",
    "\n",
    "            # remove the found movies from the chosen_name_movies_bottom_df to avoid picking them again for next iterations\n",
    "            chosen_name_movies_bottom_df.drop(bottom_i_year_chosen_name_movies.index, inplace=True)\n",
    "\n",
    "            # remove also the movies release in the frame [-5 years, +5 years] of the bottom_i_year\n",
    "            chosen_name_movies_bottom_df.query(f'year < {bottom_i_year - 5} or year > {bottom_i_year + 5}', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_insign_movies(name, chosen_name_movies_insign_df, movie_impact_df):\n",
    "    for i in range(5): # from insign1 to insign5\n",
    "        if(not chosen_name_movies_insign_df.empty):\n",
    "            # get the movies release the year with the highest rating and number of votes\n",
    "            insign_i_year = chosen_name_movies_insign_df.iloc[-1].year.astype(int)\n",
    "            insign_i_year_chosen_name_movies = chosen_name_movies_insign_df.query(f'year == {insign_i_year}').copy(deep=True)\n",
    "\n",
    "            # keep only the three most popular movies\n",
    "            insign_i_3_chosen_name_movies = insign_i_year_chosen_name_movies.iloc[:3].copy(deep=True)\n",
    "\n",
    "            # add the the three popular movies to the movie_impact_df\n",
    "            for index, row in insign_i_3_chosen_name_movies.iterrows():\n",
    "                movie_impact_df.loc[len(movie_impact_df)] = {'name': name, 'status': 'i', 'movie_id': index}\n",
    "\n",
    "            # remove the found movies from the chosen_name_movies_top_df to avoid picking them again for next iterations\n",
    "            chosen_name_movies_insign_df.drop(insign_i_year_chosen_name_movies.index, inplace=True)\n",
    "\n",
    "            # remove also the movies release in the frame [-5 years, +5 years] of the top1_year\n",
    "            chosen_name_movies_insign_df.query(f'year < {insign_i_year - 5} or year > {insign_i_year + 5}', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special case for a single name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the movie containing the chosen name\n",
    "chosen_name_movies_df = name_by_movie_with_info.loc[chosen_name, :].copy(deep=True)\n",
    "display(chosen_name_movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_name_movies_df.sort_values(by=['slope_change'], inplace=True)\n",
    "chosen_name_movies_top_df = chosen_name_movies_df.query('(slope_change > 0) and (p_value < 0.1)').copy(deep=True)\n",
    "display(chosen_name_movies_top_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the loop to do the computation for top1 to top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_top_movies(chosen_name, chosen_name_movies_top_df, movie_impact_df)\n",
    "\n",
    "display(movie_impact_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_name_movies_bottom_df = chosen_name_movies_df.query('(slope_change <= 0) and (p_value < 0.1)').copy(deep=True)\n",
    "chosen_name_movies_bottom_df.sort_values(by=['slope_change'], ascending=False, inplace=True)\n",
    "display(chosen_name_movies_bottom_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_bottom_movies(chosen_name, chosen_name_movies_bottom_df, movie_impact_df)\n",
    "\n",
    "display(movie_impact_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_chosen_name_movies_df = pd.concat([chosen_name_movies_top_df, chosen_name_movies_bottom_df])\n",
    "chosen_name_movies_insign_df = remaining_chosen_name_movies_df.query('p_value > 0.1').copy(deep=True)\n",
    "chosen_name_movies_insign_df.sort_values(by=['averageRating', 'numVotes'], inplace=True)\n",
    "display(chosen_name_movies_insign_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_insign_movies(chosen_name, chosen_name_movies_insign_df, movie_impact_df)\n",
    "display(movie_impact_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there movie duplicates in the movie_impact_df\n",
    "print(f\"number of duplicates in movie_impact_df : {movie_impact_df.duplicated(subset=['movie_id']).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalize for all the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['linda', 'henry', 'duke', 'williams', 'sheila', 'arthur', 'eldon', 'lewis', 'leon', 'hannibal', 'rick', 'rachael', 'tyrell', 'roy', 'bryant', 'sebastian', 'lamarr', 'van', 'bart', 'lyle', 'buddy', 'johnson', 'von', 'sam', 'howard', 'harriett', 'lili', 'jim', 'don', 'dorothy', 'hunter', 'frank', 'jeffrey', 'raymond', 'ben', 'paul', 'barbara', 'sandy', 'mike', 'lyndon', 'barry', 'kimberly', 'murray', 'nicole', 'andy', 'benny', 'gary', 'cassandra', 'joyce', 'jennifer', 'merrick', 'edward', 'campbell', 'william', 'king', 'princess', 'robert', 'stephen', 'wallace', 'stewart', 'bruce', 'malcolm', 'prince', 'isabelle', 'james', 'alexander', 'gordon', 'vicki', 'carl', 'bob', 'harvey', 'alfred', 'cooper', 'morgan', 'miles', 'robin', 'harriet', 'lady', 'max', 'charles', 'haven', 'ivy', 'wilson', 'grayson', 'nora', 'julie', 'madison', 'burton', 'chase', 'eric', 'roosevelt', 'jerry', 'thompson', 'leland', 'mary', 'anderson', 'herbert', 'young', 'susan', 'foster', 'walter', 'bertha', 'carter', 'theodore', 'monroe', 'emily', 'norton', 'lien', 'jun', 'may', 'jade', 'master', 'de', 'sir', 'bo', 'yu', 'jennie', 'sybil', 'harold', 'lindsay', 'jackson', 'aubrey', 'andrew', 'jefferson', 'thomas', 'kate', 'miller', 'elliott', 'dietrich', 'lionel', 'jack', 'scott', 'general', 'major', 'randolph', 'benjamin', 'franz', 'nadine', 'johann', 'phillip', 'markus', 'monique', 'cheryl', 'shelly', 'brain', 'taylor', 'maggie', 'romero', 'marion', 'lou', 'curran', 'harris', 'rosa', 'alice', 'helena', 'bill', 'amanda', 'victor', 'nick', 'lisa', 'gayle', 'lee', 'lin', 'tania', 'ed', 'jake', 'joe', 'henrietta', 'bobby', 'annie', 'manny', 'laura', 'rodrigo', 'fiona', 'angus', 'tom', 'scarlett', 'david', 'bernard', 'lydia', 'matthew', 'gerald', 'carrie', 'gareth', 'george', 'ryan', 'elliot', 'jane', 'ross', 'gray', 'neil', 'murphy', 'leonard', 'davis', 'earl', 'jay', 'lawrence', 'nita', 'little', 'kane', 'stevenson', 'queen', 'antonio', 'miki', 'erika', 'emmy', 'kenji', 'steve', 'martin', 'fred', 'katelyn', 'tommy', 'kyle', 'gwen', 'dane', 'brandon', 'guy', 'kwan', 'jason', 'heather', 'betty', 'courtney', 'chandler', 'rodney', 'ram', 'dennis', 'kelly', 'dean', 'pauline', 'martha', 'kurt', 'peter', 'keith', 'veronica', 'dawson', 'gregory', 'stan', 'mandy', 'brian', 'jesus', 'matthias', 'harry', 'giovanni', 'joey', 'johnny', 'charlie', 'michael', 'tony', 'jimmy', 'oscar', 'diane', 'teresa', 'mario', 'tim', 'patsy', 'matthews', 'leslie', 'kathy', 'hart', 'karen', 'tobin', 'gracie', 'mei', 'louise', 'gene', 'nicki', 'camilla', 'adam', 'coco', 'rita', 'vincenzo', 'kenny', 'cynthia', 'lorraine', 'roque', 'neal', 'mabel', 'emil', 'sonny', 'dwight', 'mallory', 'wayne', 'grace', 'gale', 'mickey', 'london', 'roger', 'delmar', 'dan', 'junior', 'homer', 'penny', 'nelson', 'vernon', 'teague', 'everett', 'pete', 'yuri', 'augusta', 'russell', 'julia', 'jordan', 'billy', 'luis', 'jorge', 'alan', 'sara', 'shirley', 'walker', 'philippe', 'paris', 'maurice', 'pierre', 'german', 'san', 'kaya', 'ralph', 'janet', 'brad', 'rocky', 'eddie', 'webster', 'marlene', 'bud', 'kevin', 'archie', 'napoleon', 'rodriguez', 'otto', 'parnell', 'leila', 'kirk', 'beverly', 'alyssa', 'la', 'deanna', 'reginald', 'sean', 'lily', 'sloane', 'preston', 'carol', 'clark', 'marcus', 'stoney', 'terrell', 'montgomery', 'adrian', 'john', 'wade', 'parker', 'fallon', 'francis', 'daniel', 'stanley', 'richard', 'henderson', 'frederick', 'irwin', 'timothy', 'willie', 'west', 'catherine', 'pam', 'sally', 'franklin', 'brandt', 'marty', 'knox', 'jeffery', 'maude', 'donald', 'special', 'carla', 'mason', 'ernest', 'baxter', 'paxton', 'patrick', 'elaine', 'smith', 'robinson', 'claire', 'reed', 'allison', 'betsy', 'iris', 'travis', 'precious', 'clarice', 'ruth', 'crawford', 'barney', 'trinity', 'judy', 'helen', 'barbra', 'ventura', 'ginger', 'matt', 'reese', 'hal', 'connor', 'nancy', 'sarah', 'buck', 'jill', 'hamilton', 'jose', 'casey', 'cole', 'kathryn', 'dave', 'jody', 'jude', 'darren', 'vincent', 'collins', 'kyra', 'grey', 'anna', 'lynn', 'brooks', 'diamond', 'ellis', 'floyd', 'hadley', 'boyd', 'ernie', 'palmer', 'blair', 'norris', 'garry', 'geri', 'massimo', 'tracy', 'francine', 'salvatore', 'basil', 'edison', 'miracle', 'westley', 'valerie', 'montoya', 'sharon', 'elizabeth', 'brenda', 'danny', 'alvin', 'rose', 'crystal', 'darla', 'bernardo', 'chris', 'petra', 'hilario', 'britt', 'maria', 'stevens', 'pablo', 'alison', 'ransom', 'eve', 'austin', 'denise', 'eugene', 'elijah', 'price', 'audrey', 'joseph', 'tyler', 'gunther', 'ted', 'carson', 'larson', 'anthony', 'ronald', 'fitzgerald', 'emmett', 'olga', 'anders', 'karin', 'marianne', 'ira', 'jess', 'marie', 'julian', 'wellington', 'louis', 'cindy', 'aide', 'watson', 'conley', 'pat', 'mack', 'katherine', 'malvin', 'javier', 'manolo', 'rosario', 'ayala', 'francisco', 'ray', 'carlos', 'caroline', 'seth', 'montel', 'vanessa', 'eduardo', 'arturo', 'collier', 'juan', 'sanchez', 'oswald', 'long', 'shaw', 'liz', 'clay', 'marina', 'garrison', 'susie', 'al', 'andrews', 'warren', 'ivon', 'ann', 'ruby', 'norman', 'malky', 'jenny', 'presley', 'buford', 'forrest', 'wesley', 'elvis', 'margo', 'green', 'phil', 'mitchell', 'ginny', 'angel', 'holly', 'phyllis', 'york', 'cass', 'niles', 'milly', 'nina', 'jan', 'cassidy', 'darian', 'gina', 'rowland', 'morris', 'josh', 'rachel', 'mercedes', 'august', 'hisham', 'adele', 'lillian', 'arnold', 'lane', 'spence', 'holden', 'berlin', 'ken', 'skylar', 'steffi', 'angelo', 'sal', 'milton', 'alma', 'annette', 'judson', 'burke', 'dana', 'willow', 'myrtle', 'daisy', 'mac', 'terry', 'edie', 'doyle', 'charley', 'glover', 'katie', 'marla', 'natalie', 'willis', 'boy', 'freeman', 'hugo', 'josef', 'lamar', 'irene', 'jerome', 'caesar', 'anton', 'stella', 'goldie', 'sherman', 'berry', 'marvin', 'mikhail', 'dmitri', 'pavel', 'alexei', 'marshal', 'maxim', 'ali', 'bentley', 'nate', 'charlene', 'hugh', 'hanna', 'lauren', 'marciano', 'justine', 'fran', 'angela', 'carolyn', 'lester', 'hayes', 'berkley', 'ricky', 'dupree', 'christy', 'emile', 'zola', 'nino', 'georgette', 'lucien', 'suzanne', 'hipolito', 'dominique', 'madeleine', 'eva', 'rhonda', 'kitty', 'moses', 'troy', 'lexie', 'willy', 'jolene', 'rosita', 'rosanna', 'lynne', 'billie', 'bettina', 'noland', 'lev', 'maynard', 'graham', 'ramon', 'becca', 'virginia', 'elden', 'peterson', 'chuck', 'nicolai', 'wendy', 'ellie', 'felix', 'weston', 'mark', 'anne', 'percy', 'emma', 'shirl', 'gilbert', 'sol', 'tab', 'donovan', 'lindsey', 'hiram', 'virgil', 'lola', 'hortense', 'alexis', 'rico', 'marc', 'clarence', 'randy', 'rex', 'krishna', 'hillary', 'lara', 'lord', 'bryce', 'alex', 'luc', 'juliette', 'olivia', 'lilly', 'leia', 'luke', 'mace', 'lars', 'owen', 'dexter', 'natalia', 'jean', 'aleksandr', 'leo', 'sid', 'rusty', 'marjorie', 'calvert', 'molly', 'jacob', 'brock', 'patricia', 'constance', 'albert', 'miguel', 'alicia', 'julius', 'steven', 'marilyn', 'philip', 'jasmine', 'truman', 'quincy', 'willard', 'hannah', 'woody', 'julianna', 'rebecca', 'colleen', 'lynette', 'gianni', 'shelby', 'aaron', 'edmund', 'sofia', 'sera', 'terri', 'debbie', 'brody', 'jones', 'simon', 'jimmie', 'jules', 'bonnie', 'page', 'raquel', 'mamie', 'winston', 'honey', 'brett', 'mia', 'fabienne', 'butch', 'lance', 'stephanie', 'doreen', 'connie', 'gus', 'patrice', 'cleo', 'akeem', 'imani', 'darryl', 'quinn', 'robby', 'tiffany', 'melina', 'lori', 'douglas', 'baron', 'tion', 'anakin', 'cody', 'adolph', 'verna', 'tad', 'dale', 'frankie', 'reagan', 'bernie', 'beth', 'killian', 'katrina', 'garrett', 'jonathan', 'glenn', 'china', 'shan', 'yvonne', 'blaine', 'kenneth', 'kim', 'gretchen', 'thurman', 'donnie', 'lilian', 'samantha', 'eugenie', 'eleanor', 'gaines', 'melvin', 'marco', 'darien', 'ollie', 'larry', 'bishop', 'bailey', 'bert', 'violet', 'abel', 'melissa', 'margy', 'gideon', 'dorcas', 'liza', 'caleb', 'oran', 'shawn', 'eloise', 'sidney', 'harley', 'missouri', 'judge', 'blake', 'toby', 'mimi', 'clyde', 'hank', 'washington', 'charlotte', 'gabriel', 'oliver', 'nathan', 'clarissa', 'agatha', 'jeremy', 'arabella', 'nolan', 'marietta', 'abraham', 'suzette', 'dora', 'betsey', 'gladys', 'cornelius', 'bennett', 'vance', 'belle', 'armand', 'dixie', 'lucy', 'randall', 'judith', 'hattie', 'luther', 'powell', 'kay', 'manuela', 'esteban', 'marian', 'etta', 'thea', 'barton', 'benson', 'mable', 'alec', 'hubert', 'harrison', 'mae', 'curley', 'lennie', 'dallas', 'riley', 'coleman', 'erie', 'loretta', 'margaret', 'dinah', 'keller', 'male', 'noah', 'aidan', 'samara', 'henriette', 'zita', 'marcia', 'tanya', 'adair', 'monica', 'todd', 'becky', 'agnes', 'lenny', 'janice', 'enzo', 'johana', 'christiana', 'germaine', 'roland', 'ector', 'thatcher', 'jocelyn', 'philippa', 'marcel', 'herman', 'mila', 'oskar', 'emilie', 'amon', 'rufus', 'baker', 'margie', 'dallin', 'hans', 'porter', 'georgie', 'avery', 'armin', 'karl', 'amy', 'jackie', 'alden', 'meredith', 'rob', 'lacey', 'duane', 'scarlet', 'nico', 'delores', 'tracey', 'storm', 'adams', 'tate', 'gino', 'rica', 'jennings', 'carlton', 'taft', 'hassan', 'grant', 'millie', 'orin', 'latrell', 'sasha', 'holland', 'harding', 'urban', 'angelique', 'samuel', 'louisa', 'wilbur', 'ida', 'hollis', 'evelyn', 'duffy', 'sophie', 'christina', 'kirby', 'ron', 'sophia', 'isaac', 'laurie', 'curt', 'rich', 'kit', 'jakie', 'blanche', 'velma', 'ivan', 'jamal', 'salim', 'khaled', 'aziz', 'spencer', 'annabelle', 'gennaro', 'ian', 'juanito', 'lex', 'kami', 'thornton', 'beryl', 'royal', 'dolly', 'prentice', 'hilary', 'tillie', 'vladimir', 'alia', 'duncan', 'chani', 'jessica', 'kirsty', 'merrill', 'jafar', 'genie', 'sultan', 'gerard', 'gabrielle', 'minnie', 'lehman', 'fritz', 'elmer', 'aloysius', 'jonas', 'butler', 'clara', 'kendall', 'tina', 'raheem', 'love', 'clifton', 'vito', 'greg', 'joanne', 'wyatt', 'enrique', 'harper', 'jaime', 'monte', 'lupe', 'roderick', 'zona', 'arden', 'aura', 'kent', 'chester', 'venus', 'cleopatra', 'frieda', 'hercules', 'roscoe', 'magdalene', 'christ', 'rocco', 'ola', 'geary', 'starr', 'pierce', 'colby', 'mildred', 'will', 'louie', 'hartwell', 'sanders', 'mollie', 'beck', 'victory', 'zeb', 'jeb', 'cleve', 'jethro', 'stuart', 'linus', 'prescott', 'ramsey', 'theodora', 'archibald', 'spiro', 'layton', 'vaughn', 'christine', 'gardner', 'ellen', 'priscilla', 'lassie', 'jacy', 'marlow', 'lois', 'waldo', 'bessie', 'hardy', 'valentine', 'jeremiah', 'yale', 'alonzo', 'esther', 'lon', 'colonel', 'lucille', 'ballard', 'truett', 'trudy', 'norval', 'modesta', 'jolly', 'brown', 'granville', 'ike', 'clementine', 'angelica', 'godfrey', 'carlo', 'cornelia', 'ethel', 'johnnie', 'lina', 'isobel', 'reggie', 'kemp', 'delbert', 'linnea', 'opal', 'joan', 'pearl', 'gay', 'dwayne', 'sue', 'otis', 'katy', 'carmine', 'chip', 'birdie', 'willa', 'walt', 'sterling', 'jeff', 'kathie', 'meta', 'fletcher', 'terrill', 'jamie', 'georges', 'le', 'raphael', 'marquise', 'santino', 'lena', 'baby', 'raoul', 'dolores', 'allen', 'cookie', 'buzz', 'cliff', 'garth', 'gil', 'bradley', 'irving', 'ethan', 'mose', 'clayton', 'dina', 'vic', 'marcy', 'rollie', 'grafton', 'shane', 'desmond', 'norma', 'artie', 'gillis', 'lilia', 'derek', 'jo', 'jacqui', 'april', 'marshall', 'dorsey', 'rod', 'gavin', 'midge', 'bunny', 'dutch', 'freddie', 'marlowe', 'craig', 'josie', 'margot', 'anita', 'dixon', 'berta', 'lupita', 'ronnie', 'leopold', 'morton', 'evans', 'antoine', 'therese', 'jeanne', 'bernadette', 'bridget', 'golden', 'hilton', 'sigmund', 'deborah', 'stacy', 'elyse', 'davy', 'christian', 'winifred', 'brady', 'benedict', 'polly', 'viet', 'dudley', 'doris', 'gertrude', 'ophelia', 'abner', 'burdette', 'consuela', 'che', 'mina', 'dick', 'barth', 'paula', 'rudolf', 'eli', 'trey', 'lizzie', 'tasha', 'rochelle', 'teddy', 'ace', 'vince', 'denny', 'vern', 'milo', 'viola', 'ned', 'florence', 'simone', 'ferris', 'jeanie', 'cameron', 'gillian', 'timon', 'abbie', 'frances', 'antonia', 'kylie', 'mikey', 'archer', 'ibn', 'ahmed', 'mel', 'bella', 'kai', 'freddy', 'fernandez', 'humphrey', 'adeline', 'flo', 'rosemary', 'irma', 'eileen', 'lloyd', 'romaine', 'cullen', 'nell', 'ella', 'ernst', 'rolfe', 'rudolph', 'haywood', 'levy', 'conrad', 'cain', 'marci', 'cecile', 'clifford', 'hope', 'zack', 'cristal', 'carey', 'samir', 'drew', 'joanna', 'alessandro', 'cesar', 'augusto', 'kristina', 'diego', 'mirtha', 'franco', 'theo', 'diana', 'tonya', 'alexandra', 'link', 'bethany', 'blossom', 'lucky', 'juliet', 'logan', 'macon', 'female', 'sandra', 'delano', 'rafe', 'alain', 'angie', 'tatiana', 'nicholas', 'anastasia', 'faith', 'jeanine', 'nigel', 'belinda', 'denis', 'bobbi', 'mick', 'tucker', 'xavier', 'minerva', 'darwin', 'payne', 'debby', 'turner', 'mitch', 'miriam', 'marcellus', 'horatio', 'reynaldo', 'marcella', 'tricia', 'dante', 'justice', 'brodie', 'brent', 'randal', 'chrissy', 'missy', 'jeannie', 'cash', 'sydney', 'adelle', 'lonnie', 'gentry', 'doug', 'laureen', 'garfield', 'kip', 'geoffrey', 'katharine', 'hana', 'marguerite', 'chad', 'faye', 'del', 'dolan', 'horace', 'tex', 'erich', 'saul', 'jeannette', 'erica', 'patti', 'suzy', 'cyril', 'leona', 'landon', 'reuben', 'rae', 'noble', 'griffin', 'apollo', 'freda', 'andreas', 'gail', 'elton', 'dionne', 'cher', 'amber', 'wendell', 'tai', 'ashton', 'madeline', 'vivian', 'dakota', 'thelma', 'harlan', 'darcy', 'park', 'gigi', 'erin', 'steele', 'jeannine', 'calvin', 'jarrett', 'sloan', 'ward', 'kendal', 'galvin', 'patty', 'aurora', 'rosie', 'rene', 'wally', 'edna', 'elias', 'tatum', 'soren', 'persephone', 'kali', 'jewel', 'clive', 'dawn', 'ronny', 'perry', 'susanna', 'clinton', 'oren', 'tess', 'gloria', 'dalton', 'noel', 'dee', 'terence', 'sadie', 'elgin', 'rolando', 'jensen', 'hagen', 'dominic', 'gaston', 'meyer', 'luciano', 'delilah', 'davey', 'trent', 'donna', 'slade', 'lucas', 'flora', 'ada', 'jad', 'clarke', 'evanna', 'solomon', 'blue', 'nevada', 'emilio', 'reno', 'buster', 'lovell', 'sy', 'esme', 'ferdinand', 'beatrice', 'elinor', 'fanny', 'christopher', 'scotty', 'tyson', 'laurel', 'jesse', 'suzie', 'ashley', 'sonia', 'muriel', 'sylvia', 'cecil', 'susannah', 'sheryl', 'cathy', 'krystyn', 'star', 'lana', 'bracken', 'duc', 'isabel', 'elena', 'guido', 'eliseo', 'rodolfo', 'lowell', 'liane', 'luca', 'elsie', 'lavinia', 'denton', 'rupert', 'warner', 'victoria', 'jenner', 'ely', 'emanuel', 'diva', 'judd', 'amalia', 'lanie', 'tomas', 'ezra', 'eduard', 'andie', 'sutton', 'emery', 'frazier', 'lincoln', 'selena', 'farrell', 'bascom', 'claude', 'rock', 'maximilian', 'brant', 'jameson', 'jonah', 'mi', 'mustafa', 'nova', 'harmon', 'zeke', 'edsel', 'stacey', 'roxanne', 'brandi', 'keisha', 'trina', 'reva', 'yvette', 'pandora', 'juanita', 'sharika', 'toi', 'georgia', 'gustav', 'damian', 'desire', 'miranda', 'troi', 'curtis', 'bambi', 'eden', 'kathleen', 'schuyler', 'son', 'nathaniel', 'rudy', 'roman', 'justin', 'martia', 'chang', 'nixon', 'kirsten', 'arletta', 'pepper', 'mattie', 'ulysses', 'marita', 'ruben', 'seamus', 'gregor', 'natacha', 'deirdre', 'pasquale', 'antonietta', 'hilda', 'johanna', 'chauncey', 'rand', 'kirkland', 'stanford', 'burt', 'megan', 'ajay', 'jared', 'devon', 'zan', 'sumner', 'sun', 'thalia', 'demetrius', 'hermes', 'cal', 'cedric', 'mathieu', 'drake', 'vicky', 'ava', 'sonya', 'tanner', 'renard', 'valentin', 'claudia', 'marius', 'newton', 'edgar', 'lucinda', 'cyrus', 'keaton', 'theresa', 'marlon', 'geneva', 'hayden', 'amos', 'janelle', 'kennedy', 'carmen', 'tuan', 'brennen', 'richie', 'pamela', 'boris', 'joi', 'wallis', 'elwood', 'sunny', 'andrea', 'danielle', 'cady', 'leigh', 'peggy', 'celia', 'pearce', 'paulette', 'darlene', 'sully', 'russ', 'rowena', 'monty', 'marsha', 'melinda', 'vaughan', 'althea', 'arlo', 'jewell', 'jessie', 'dewey', 'chance', 'markie', 'rogers', 'evan', 'glen', 'lamont', 'daryl', 'davina', 'della', 'myron', 'rubin', 'hazel', 'emmet', 'omer', 'edith', 'willem', 'sade', 'renee', 'marquis', 'abbe', 'latina', 'hoyt', 'muhammad', 'cassius', 'timmy', 'jasper', 'ingrid', 'booker', 'augustus', 'glenda', 'shilo', 'donnell', 'selina', 'amelia', 'lila', 'collie', 'carole', 'thadeus', 'alexa', 'takashi', 'mai', 'bertram', 'bartlett', 'blythe', 'werner', 'quinton', 'hawk', 'brandy', 'howell', 'conway', 'bayley', 'stone', 'brennan', 'damien', 'fairy', 'hudson', 'myra', 'rosalie', 'skipper', 'sunshine', 'raleigh', 'mohamed', 'martinez', 'bradford', 'giovanna', 'mauro', 'tyrone', 'donny', 'keeley', 'wilfred', 'adriana', 'cruz', 'amir', 'maxwell', 'wilma', 'pebbles', 'demetra', 'cortez', 'devlin', 'gregorio', 'judas', 'magdalen', 'nicodemus', 'julio', 'ana', 'silvia', 'cecilia', 'luisa', 'alejandro', 'eugenia', 'manuel', 'lucero', 'flint', 'sullivan', 'gertie', 'roxie', 'bowen', 'bree', 'caitlin', 'orville', 'bianca', 'june', 'mona', 'flynn', 'nickie', 'michele', 'romy', 'julien', 'romeo', 'laurence', 'sampson', 'paolo', 'laurent', 'dayton', 'candace', 'tully', 'barrett', 'janine', 'angelina', 'cutter', 'morrison', 'clemmie', 'hayward', 'doran', 'rory', 'eddy', 'danni', 'serge', 'gerry', 'daniella', 'luigi', 'seymour', 'mackenzie', 'carlyn', 'annalee', 'wren', 'christie', 'perez', 'sabra', 'dillon', 'cera', 'chan', 'martel', 'andre', 'lulu', 'ming', 'nicolo', 'nicolas', 'marley', 'ursula', 'henri', 'sylvie', 'layla', 'ty', 'tod', 'rivers', 'christa', 'chaney', 'toni', 'ramona', 'webb', 'garland', 'mathew', 'phillips', 'chas', 'clair', 'dusty', 'ari', 'candy', 'wanda', 'celeste', 'clint', 'roberta', 'saundra', 'reilly', 'charleston', 'zebulon', 'ludwig', 'robbie', 'blain', 'lawson', 'richmond', 'melanie', 'montana', 'tabatha', 'dorothea', 'thurston', 'vivien', 'simeon', 'meryl', 'terrance', 'baldwin', 'brooke', 'noelle', 'brittany', 'michelle', 'egan', 'bruno', 'chandra', 'rianne', 'joshua', 'trish', 'elisabeth', 'russel', 'grover', 'shannon', 'wendel', 'jed', 'brendan', 'ally', 'baylor', 'francois', 'percival', 'mitchel', 'secret', 'andrei', 'robie', 'sheldon', 'jacques', 'coral', 'marlin', 'val', 'shelley', 'holt', 'renata', 'colin', 'crispin', 'kelli', 'nicky', 'gwyneth', 'chet', 'nadia', 'krystal', 'cadence', 'felicity', 'ivana', 'scottie', 'gilda', 'livia', 'guillermo', 'thaddeus', 'celine', 'zoe', 'chaz', 'heath', 'santos', 'lula', 'dell', 'tran', 'edwin', 'nguyen', 'hector', 'norm', 'hampton', 'meena', 'neville', 'mavis', 'barret', 'coy', 'terrence', 'bronson', 'elsa', 'erik', 'pascal', 'dieter', 'lorna', 'irish', 'dylan', 'houston', 'selma', 'janie', 'tammy', 'greta', 'frida', 'vera', 'antony', 'emmanuel', 'libby', 'gill', 'marnie', 'bernice', 'hezekiah', 'hester', 'phoebe', 'omar', 'alberto', 'elvira', 'chi', 'natalya', 'irina', 'xenia', 'raj', 'simran', 'preeti', 'marcela', 'helene', 'abby', 'julianne', 'joanie', 'magda', 'delany', 'decker', 'vinny', 'edwina', 'jin', 'eris', 'kale', 'cheyenne', 'mariana', 'declan', 'dimitri', 'jarvis', 'cherry', 'pedro', 'peg', 'jock', 'fabio', 'sherry', 'tarrance', 'tommie', 'lambert', 'jubilee', 'mystique', 'gia', 'wilhelmina', 'cy', 'vy', 'hanson', 'aron', 'dianne', 'pryce', 'ricki', 'maxie', 'delia', 'nettie', 'dottie', 'misty', 'anabel', 'raja', 'wilfrid', 'nellie', 'merle', 'kiri', 'nader', 'allegra', 'viviane', 'milan', 'nash', 'tenia', 'felipe', 'elle', 'sofie', 'beatrix', 'alana', 'ariel', 'chico', 'sinclair', 'stanton', 'elvin', 'siri', 'abdul', 'esmeralda', 'dustin', 'allan', 'meg', 'hiroki', 'matilda', 'maury', 'hansel', 'bartholomew', 'kala', 'chadwick', 'asa', 'ritchie', 'kiara', 'huston', 'marybeth', 'gabe', 'carlotta', 'portia', 'florine', 'samson', 'valjean', 'bilal', 'lora', 'wells', 'yang', 'millard', 'alva', 'carver', 'inga', 'kira', 'sky', 'nana', 'breeze', 'sammy', 'candice', 'deidre', 'channing', 'giselle', 'anamaria', 'maya', 'cora', 'charity', 'humberto', 'orlando', 'tia', 'blaire', 'charlton', 'lino', 'giuseppe', 'barbie', 'marino', 'quincey', 'rylan', 'manning', 'claudius', 'michel', 'alpha', 'nada', 'corwin', 'finn', 'rance', 'harlen', 'abigail', 'lafayette', 'adelaide', 'tremain', 'wolf', 'mandel', 'arlene', 'jon', 'chapman', 'tito', 'brie', 'maxine', 'tami', 'vickie', 'wes', 'regina', 'len', 'art', 'merlin', 'imad', 'angelic', 'katya', 'kasper', 'alisa', 'skip', 'greer', 'braxton', 'gerrit', 'corinne', 'rayna', 'sanford', 'brice', 'electra', 'vilma', 'brigitte', 'mauricio', 'rocio', 'mohammed', 'kenan', 'aurelia', 'nehemiah', 'leanne', 'lucia', 'sacha', 'erwin', 'nikita', 'graeme', 'bronwyn', 'callen', 'rudi', 'douglass', 'maverick', 'zane', 'bret', 'earlene', 'rajah', 'ismail', 'tarik', 'nala', 'avram', 'gracey', 'teri', 'piero', 'ralston', 'nicolette', 'kingsley', 'ma', 'boone', 'arleen', 'chastity', 'candi', 'christiane', 'rainer', 'ariane', 'laverne', 'priya', 'santa', 'demon', 'tin', 'tej', 'roberto', 'dirk', 'levon', 'lacy', 'joscelyn', 'kaylee', 'gregg', 'kristen', 'marin', 'cage', 'viktor', 'yelena', 'xander', 'liana', 'isabella', 'lorelei', 'steward', 'luna', 'lorenzo', 'constantine', 'destiny', 'nikki', 'jacqueline', 'usman', 'aman', 'neha', 'deepak', 'chesney', 'cort', 'ruthie', 'josephine', 'denver', 'estrella', 'felton', 'sapphire', 'nestor', 'mindy', 'esperanza', 'rosalind', 'francesca', 'jagger', 'stevie', 'darling', 'krista', 'lonny', 'shaun', 'savina', 'empress', 'linden', 'lorrie', 'sheridan', 'aileen', 'corey', 'moira', 'serena', 'enid', 'callahan', 'jamieson', 'reena', 'fulton', 'triton', 'morgana', 'melody', 'rolf', 'dario', 'kimmy', 'christin', 'felice', 'ilse', 'marta', 'nyah', 'ambrose', 'selene', 'lucian', 'damone', 'maribel', 'gabriella', 'kayleigh', 'kagan', 'heidi', 'blane', 'iona', 'eleazar', 'quentin', 'emory', 'phillipe', 'etienne', 'rena', 'tawny', 'devi', 'cohen', 'maximillian', 'jenna', 'devine', 'annabeth', 'gypsy', 'mister', 'ford', 'tiago', 'berenice', 'thiago', 'sandro', 'yasmin', 'soraya', 'shyla', 'oakley', 'hansen', 'norbert', 'frederic', 'huy', 'yocheved', 'brianna', 'jamey', 'mateo', 'cristina', 'astrid', 'evie', 'joy', 'evette', 'tan', 'penelope', 'kaye', 'deacon', 'blade', 'jenson', 'racquel', 'marcello', 'irvin', 'lettie', 'gunner', 'india', 'elio', 'rowan', 'calum', 'yves', 'pace', 'janely', 'jana', 'annemarie', 'noreen', 'prentiss', 'asad', 'nyssa', 'fox', 'lucius', 'tramell', 'garner', 'keane', 'felicia', 'mitzi', 'passion', 'nathanial', 'gwendolyn', 'matisse', 'ezekiel', 'sang', 'han', 'fatima', 'kiki', 'roel', 'fausto', 'olivier', 'maxime', 'nathalie', 'santo', 'keoki', 'natasha', 'mara', 'naomi', 'sabrina', 'jodi', 'shavonne', 'mathias', 'jayne', 'lenore', 'serra', 'river', 'tam', 'vikram', 'byron', 'matilde', 'guadalupe', 'filippo', 'remington', 'abdullah', 'remy', 'davidson', 'dwan', 'rexford', 'adolphus', 'rainey', 'giles', 'fabian', 'allie', 'yusef', 'aurelio', 'hobie', 'wagner', 'cassie', 'bobbie', 'gibson', 'eleanore', 'jefferey', 'kandy', 'barclay', 'misha', 'ignacio', 'chong', 'silvana', 'joel', 'derrick', 'michaela', 'hung', 'reynolds', 'vijay', 'kamal', 'fredrick', 'les', 'sparkle', 'haley', 'jaye', 'calder', 'chloe', 'staci', 'kenard', 'igor', 'zachary', 'phoenix', 'earle', 'alfredo', 'paola', 'sabine', 'michell', 'jezebel', 'elspeth', 'kiva', 'athena', 'raven', 'nikolas', 'marcie', 'riccardo', 'larkin', 'maple', 'elmo', 'marvel', 'elmira', 'elma', 'cherie', 'ibrahim', 'clarisse', 'maureen', 'kari', 'kamran', 'kara', 'rueben', 'thayer', 'whitney', 'cisco', 'regan', 'graydon', 'thor', 'zach', 'trevor', 'jamison', 'colton', 'pooja', 'anjali', 'rahul', 'rohan', 'kimberley', 'ronna', 'sherri', 'stefan', 'dierdre', 'carolina', 'rosina', 'kellie', 'abhay', 'rohit', 'cedar', 'owens', 'darci', 'ester', 'camden', 'catarina', 'drayton', 'lindy', 'nelly', 'curry', 'holli', 'reba', 'hallie', 'tori', 'jolie', 'bridger', 'eliot', 'franky', 'nisha', 'khan', 'sanjay', 'carmella', 'carroll', 'alena', 'carlson', 'wyman', 'jacoby', 'kerry', 'karan', 'usher', 'octavius', 'debra', 'creed', 'rosalee', 'sonja', 'casper', 'gussie', 'gannon', 'elder', 'rider', 'vlad', 'cantrell', 'renaldo', 'cordell', 'loren', 'keno', 'ernesto', 'wolfgang', 'wilhelm', 'raine', 'aldo', 'tamara', 'wynter', 'paige', 'kermit', 'laine', 'kelson', 'angeline', 'tani', 'liyah', 'emerald', 'shari', 'jeanette', 'lilliana', 'jimi', 'silver', 'walton', 'mari', 'jalil', 'caela', 'blaze', 'rowdy', 'jai', 'tristan', 'armando', 'titus', 'huey', 'durrell', 'alley', 'rolanda', 'domingo', 'maia', 'phineas', 'emmeline', 'draco', 'sawyer', 'isak', 'jobe', 'hailey', 'josiah', 'chavez', 'dessie', 'phelan', 'carlyle', 'enrico', 'zinnia', 'frantz', 'rajan', 'blanca', 'nashawn', 'nuria', 'axel', 'darby', 'lida', 'eldridge', 'hakim', 'caine', 'pernell', 'chauncy', 'forest', 'ena', 'emiliano', 'josefa', 'juana', 'audra', 'cyndi', 'loni', 'colt', 'olive', 'silvano', 'kareem', 'atlanta', 'lexi', 'tobias', 'seven', 'charly', 'zander', 'aline', 'rhoda', 'randi', 'janey', 'enos', 'cheng', 'monet', 'taryn', 'malik', 'deja', 'dominick', 'brogan', 'khari', 'nikolai', 'daphne', 'yuki', 'sylvester', 'marko', 'dugan', 'leticia', 'aisha', 'cale', 'jr', 'rafael', 'luiz', 'early', 'salem', 'royce', 'cory', 'avi', 'inez', 'charmaine', 'chancellor', 'tino', 'guinevere', 'lancelot', 'abe', 'garnett', 'santiago', 'rina', 'alise', 'gemma', 'jorgen', 'cosmo', 'kia', 'parrish', 'ravi', 'leroy', 'addison', 'yetta', 'shanti', 'caprice', 'ramiro', 'susana', 'gustavo', 'octavio', 'leonardo', 'julieta', 'valeria', 'jacobo', 'lyla', 'charisse', 'hale', 'reina', 'roxy', 'shay', 'tabitha', 'mariella', 'millicent', 'ji', 'latifa', 'gretta', 'marlee', 'kana', 'glory', 'lace', 'jeri', 'benton', 'wei', 'mayer', 'isis', 'torrance', 'kasey', 'karla', 'krystyna', 'sinead', 'carly', 'asher', 'ileana', 'franklyn', 'bryan', 'woodrow', 'kristi', 'alonso', 'ramey', 'asia', 'vivienne', 'bess', 'midori', 'alfonso', 'mortimer', 'bennie', 'patience', 'filomena', 'nicholai', 'maris', 'talia', 'wiley', 'tripp', 'kramer', 'nadya', 'adrienne', 'summer', 'eleni', 'taran', 'sameer', 'aryan', 'kiran', 'sanjana', 'megha', 'gustave', 'matty', 'darnell', 'brantley', 'waynette', 'yumi', 'ryo', 'klaus', 'rona', 'dorinda', 'amar', 'shyam', 'karisma', 'bashir', 'tara', 'tracie', 'poppy', 'lavender', 'finnigan', 'cormac', 'blaise', 'nicola', 'gage', 'irena', 'farrah', 'ren', 'yancy', 'gabby', 'copeland', 'martina', 'edmond', 'vida', 'katina', 'lew', 'ema', 'trisha', 'wayland', 'atlee', 'abbey', 'arline', 'hersh', 'levin', 'jenifer', 'cesare', 'eleanora', 'tillman', 'nola', 'piper', 'lexy', 'osiris', 'griffith', 'lainey', 'fisher', 'kansas', 'antwone', 'quenton', 'damon', 'sven', 'hari', 'anand', 'margret', 'abi', 'zahra', 'tonda', 'ryder', 'estelle', 'denisha', 'lukas', 'eben', 'dempsey', 'gena', 'madelyne', 'eliza', 'roya', 'villa', 'francoise', 'arlen', 'merritt', 'lyman', 'myles', 'elise', 'genevieve', 'lazarus', 'deloris', 'ramone', 'emerson', 'sona', 'daria', 'dion', 'grady', 'surya', 'luba', 'mathis', 'dimitrios', 'dryden', 'mendel', 'solange', 'darin', 'jakob', 'job', 'torrey', 'niels', 'philomena', 'callie', 'pa', 'dyson', 'courtland', 'aliya', 'ayesha', 'aditi', 'varun', 'ria', 'cannon', 'vittorio', 'channel', 'robertson', 'jocelyne', 'mirella', 'atticus', 'ammon', 'dani', 'lise', 'ignatius', 'dionna', 'chiara', 'darius', 'lam', 'corrine', 'haden', 'dominik', 'maguire', 'therman', 'aram', 'collette', 'lanier', 'axl', 'giancarlo', 'eamon', 'fortino', 'carolyne', 'winnie', 'katarina', 'gunnar', 'shepard', 'landis', 'savannah', 'bernadine', 'marissa', 'darcie', 'jericho', 'sherwood', 'reece', 'matai', 'tal', 'dejah', 'deep', 'gonzalo', 'ismael', 'patricio', 'treva', 'eri', 'phaedra', 'andrey', 'vishal', 'rani', 'conner', 'cutler', 'beckett', 'sabin', 'shelton', 'kong', 'aislinn', 'brok', 'an', 'galen', 'avid', 'odette', 'richardson', 'delila', 'severo', 'jani', 'anja', 'mika', 'saber', 'conan', 'calley', 'dino', 'shade', 'rain', 'briggs', 'sandi', 'kallen', 'reyes', 'cherish', 'zahara', 'neena', 'temple', 'telly', 'ocean', 'seward', 'sheri', 'juliano', 'rhett', 'laney', 'leonora', 'shayne', 'imogene', 'addie', 'trixie', 'karine', 'traci', 'perrin', 'shaila', 'francie', 'nan', 'chaim', 'esha', 'siddharth', 'katerina', 'ivory', 'cloe', 'cheri', 'delta', 'echo', 'corinna', 'paulina', 'ronaldo', 'ahmad', 'alistair', 'pietro', 'renzo', 'anson', 'dwain', 'chantal', 'mira', 'winthrop', 'antoinette', 'amit', 'wardell', 'kinsey', 'micki', 'augustin', 'camille', 'carmina', 'radhika', 'arjun', 'akira', 'lakshmi', 'marek', 'taj', 'wilder', 'pearson', 'sergio', 'tesla', 'kile', 'shaina', 'laramie', 'kristin', 'cathryn', 'idris', 'musa', 'lake', 'kelley', 'danica', 'dijon', 'dorian', 'reid', 'misaki', 'roslyn', 'kalina', 'lennox', 'georgina', 'bennet', 'jaya', 'aristotle', 'roxane', 'odin', 'desi', 'graciela', 'errol', 'cortland', 'cammi', 'kyla', 'rolland', 'jamaal', 'norah', 'crimson', 'paulo', 'bertie', 'una', 'alexia', 'eunice', 'malick', 'coty', 'janell', 'peyton', 'kiernan', 'maritza', 'mercy', 'cleon', 'albino', 'jarrod', 'quan', 'kimball', 'rafi', 'michelangelo', 'avis', 'leah', 'chesley', 'tristen', 'rustin', 'gifford', 'niko', 'sissy', 'allana', 'wynn', 'kincaid', 'neely', 'lani', 'georgianna', 'osvaldo', 'estela', 'lynda', 'miya', 'joab', 'tamar', 'violette', 'corbin', 'germain', 'elodie', 'mathilde', 'benji', 'akbar', 'lolita', 'garret', 'hennessy', 'timber', 'benita', 'dax', 'mariko', 'ames', 'glendon', 'bryon', 'yolanda', 'sumer', 'mariam', 'annabel', 'lazaro', 'olaf', 'carin', 'merry', 'linwood', 'drusilla', 'langston', 'alphonse', 'wylie', 'vita', 'lia', 'leonor', 'indiana', 'mordechai', 'tatyana', 'talley', 'wil', 'buffy', 'fenton', 'saleem', 'tariq', 'soledad', 'martine', 'cammy', 'rosalinda', 'luz', 'flor', 'tye', 'rome', 'marge', 'rey', 'juliana', 'kayley', 'ryker', 'colette', 'sameera', 'cinderella', 'roma', 'jedediah', 'jens', 'darik', 'judah', 'halley', 'murad', 'valentina', 'fay', 'nikhil', 'asha', 'puja', 'tong', 'herbie', 'katelin', 'italia', 'timoteo', 'pilar', 'hobart', 'carlissa', 'carsen', 'madolyn', 'annalise', 'arnell', 'coulter', 'lyra', 'serafina', 'marisa', 'lisbeth', 'velvet', 'queenie', 'ashby', 'chanel', 'katey', 'silas', 'aja', 'kamen', 'raul', 'robyn', 'kenyon', 'roby', 'anil', 'jonny', 'deaundre', 'chelsea', 'chazz', 'boyce', 'magdalena', 'alexi', 'dillyn', 'akash', 'shalini', 'angelika', 'deena', 'zak', 'sabian', 'kingston', 'satchel', 'leyla', 'elroy', 'slater', 'martino', 'braden', 'maren', 'hussein', 'kealy', 'geraldine', 'waylon', 'clancy', 'rosemarie', 'reeves', 'nasser', 'liam', 'jillian', 'arie', 'adrianne', 'biff', 'lottie', 'alton', 'rahim', 'seema', 'winter', 'riggs', 'tanis', 'nichols', 'dow', 'alix', 'rosy', 'parris', 'leonna', 'shoshana', 'krysta', 'abilene', 'starla', 'zora', 'marquez', 'christelle', 'vinson', 'joslyn', 'haskell', 'parish', 'creighton', 'rosetta', 'kristy', 'charisma', 'rickey', 'anthea', 'henrik', 'johan', 'teal', 'lakisha', 'malakai', 'arya', 'shah', 'pia', 'shea', 'kenton', 'sapna', 'andersen', 'brigit', 'fabrizio', 'clare', 'jae', 'roseanne', 'arsenio', 'lyric', 'carleton', 'stephan', 'unknown', 'geronimo', 'teena', 'zia', 'concetta', 'marylin', 'eula', 'zoey', 'darrin', 'america', 'thaddius', 'keene', 'bridgette', 'arizona', 'shruti', 'rika', 'skye', 'joaquin', 'scout', 'claudio', 'hill', 'lashawn', 'ennis', 'aarti', 'suraj', 'radha', 'aditya', 'evangeline', 'carlene', 'rosanne', 'talon', 'nils', 'cleveland', 'story', 'sunday', 'clovis', 'donavan', 'magnolia', 'ilona', 'hollie', 'lorry', 'clemente', 'deane', 'budd', 'tiger', 'marika', 'madge', 'coley', 'cary', 'rhea', 'mihir', 'memory', 'finnegan', 'thunder', 'tory', 'jonathon', 'ciro', 'consuelo', 'ender', 'hyrum', 'nara', 'emina', 'sakura', 'eros', 'avinash', 'saeed', 'akram', 'claudine', 'jessy', 'delaney', 'letha', 'gerson', 'rodriquez', 'benito', 'augustina', 'konrad', 'ina', 'darya', 'ilya', 'larisa', 'svetlana', 'cosette', 'mitra', 'gian', 'hogan', 'liesl', 'fleming', 'shereen', 'shaniqua', 'nasia', 'maura', 'yash', 'isha', 'sania', 'ronak', 'alisha', 'rajiv', 'amrita', 'lilli', 'charli', 'shy', 'ole', 'clement', 'dann', 'jodie', 'mansi', 'rehan', 'haider', 'hasan', 'ila', 'rogan', 'hamid', 'camilo', 'gisela', 'my', 'noemi', 'geoff', 'coralie', 'odell', 'kabir', 'manu', 'sheena', 'naima', 'shanta', 'sriram', 'niki', 'ilene', 'sarita', 'quaid', 'ishmael', 'nels', 'elly', 'shepherd', 'nazareth', 'jairus', 'langdon', 'tonny', 'tailor', 'tyrus', 'caspian', 'aslan', 'seldon', 'zelda', 'kathi', 'breck', 'lexington', 'lyssa', 'harmony', 'marleah', 'vinay', 'ishaan', 'janina', 'lipa', 'yehuda', 'swetha', 'saran', 'rishi', 'dev', 'eliott', 'sarina', 'ania', 'durand', 'cassady', 'pasha', 'melika', 'fischer', 'ashlyn', 'amparo', 'benigno', 'melba', 'dahlia', 'keri', 'gaylord', 'garcia', 'harland', 'iesha', 'olin', 'girard', 'aramis', 'cris', 'wisdom', 'kalman', 'hiawatha', 'lan', 'reyna', 'marisol', 'kamala', 'sharma', 'milena', 'vishnu', 'melora', 'reanna', 'patton', 'catharine', 'blakeley', 'bea', 'artis', 'malichi', 'railey', 'carlisle', 'horton', 'maddie', 'cade', 'tallulah', 'laszlo', 'komal', 'jerri', 'sahara', 'farris', 'davian', 'amonte', 'berk', 'kisha', 'wilton', 'kimiko', 'arun', 'rama', 'veronique', 'hai', 'maryann', 'kee', 'jarrell', 'hong', 'sunil', 'mayo', 'crysta', 'gautam', 'farah', 'delon', 'lenora', 'joachim', 'barrington', 'pascale', 'lesly', 'casimir', 'danish', 'latif', 'aaliya', 'josey', 'laila', 'silva', 'brook', 'orrin', 'ezekial', 'loc', 'wali', 'hussain', 'mansoor', 'rosaria', 'paloma', 'celestina', 'deangelo', 'morey', 'glyn', 'marcos', 'federico', 'vidal', 'khalil', 'saleh', 'talal', 'lexus', 'arnel', 'kash', 'samad', 'taras', 'lorie', 'ellison', 'evalyn', 'raychel', 'levi', 'ayah', 'deedee', 'delroy', 'jazz', 'mikaela', 'medford', 'keegan', 'duran', 'allyson', 'manfred', 'johny', 'markham', 'nat', 'tish', 'estella', 'terra', 'ricardo', 'regine', 'gabriela', 'janessa', 'niklas', 'carlie', 'violetta', 'bliss', 'maclean', 'lorne', 'tor', 'leonid', 'rayne', 'pallavi', 'francesco', 'carmela', 'lennon', 'ilana', 'alston', 'brooklyn', 'torrence', 'ambar', 'meir', 'issa', 'golda', 'ephraim', 'akari', 'saya', 'georgiana', 'giulia', 'olympia', 'colvin', 'able', 'alba', 'randa', 'fidel', 'nava', 'janis', 'gaspar', 'banks', 'chung', 'fern', 'soumya', 'mehak', 'kunal', 'cammie', 'syria', 'steffen', 'wright', 'iva', 'dashiell', 'robbin', 'brenner', 'tyla', 'gao', 'hagan', 'nasir', 'arash', 'race', 'madonna', 'vann', 'anwar', 'lilah', 'jacey', 'arlin', 'patrik', 'darrell', 'chanda', 'merrie', 'ramses', 'canon', 'freya', 'stafford', 'aviva', 'alessa', 'leonidas', 'theron', 'cornell', 'kary', 'ceasar', 'bing', 'lucretia', 'shawna', 'margherita', 'rasheed', 'salomon', 'bebe', 'beau', 'daly', 'puneet', 'ebenezer', 'brigid', 'montez', 'lorena', 'fergus', 'sonali', 'french', 'chapin', 'barron', 'akshay', 'vivek', 'neale', 'leena', 'imran', 'amin', 'skyler', 'griselda', 'irby', 'murrell', 'ash', 'junius', 'anneliese', 'christoph', 'jalal', 'shaheed', 'amjad', 'aparna', 'siobhan', 'sondra', 'didier', 'jenay', 'issac', 'thane', 'gaby', 'augustine', 'chantel', 'fawn', 'levar', 'solana', 'elora', 'garrick', 'mali', 'rivka', 'lexa', 'elisheva', 'noa', 'shimon', 'yaakov', 'malka', 'ganesh', 'tobey', 'lanny', 'kasim', 'nikos', 'tea', 'cipriano', 'elisa', 'laci', 'shadow', 'cecelia', 'alexandria', 'azrael', 'vanity', 'papa', 'felicitas', 'lalita', 'loan', 'mahmoud', 'conor', 'sheba', 'ka', 'whisper', 'hartley', 'tierney', 'danika', 'kaela', 'regis', 'purvis', 'parthenia', 'lovely', 'shivani', 'lucie', 'maida', 'kelby', 'dre', 'meghan', 'aldrin', 'lea', 'deke', 'kiyomi', 'kajal', 'sagar', 'bristol', 'daley', 'yasmeen', 'liliana', 'carlito', 'safiya', 'maggi', 'chantelle', 'divya', 'peaches', 'griffen', 'maybelle', 'pranav', 'mala', 'shawnee', 'shanna', 'dov', 'micah', 'malcom', 'lama', 'marlina', 'karthik', 'indra', 'meera', 'camryn', 'illeana', 'stavros', 'marti', 'sommer', 'iverson', 'mena', 'sergei', 'radley', 'carley', 'christen', 'osman', 'kerrigan', 'sarika', 'rohini', 'elli', 'vi', 'delphine', 'shahid', 'ryu', 'damani', 'herschel', 'fernando', 'haris', 'marija', 'jarius', 'melaina', 'rainy', 'slate', 'stryker', 'kayla', 'suha', 'ashraf', 'said', 'min', 'giorgio', 'swati', 'gorman', 'lang', 'hera', 'elsy', 'contessa', 'kain', 'rashid', 'omkar', 'nandini', 'eamonn', 'austen', 'majid', 'anya', 'teela', 'beulah', 'soleil', 'marine', 'orion', 'winona', 'sharda', 'sahil', 'malini', 'nafisa', 'tora', 'obadiah', 'arielle', 'nikolaus', 'ambrosia', 'orianna', 'arne', 'jamilla', 'kris', 'nahum', 'collin', 'renato', 'caterina', 'marques', 'marni', 'quinlan', 'joni', 'arif', 'flavia', 'dara', 'crosby', 'amadeus', 'hilliard', 'cassy', 'clio', 'reesa', 'ariana', 'naia', 'zev', 'keesha', 'radames', 'scotti', 'anuj', 'bronwen', 'rees', 'bee', 'tanvi', 'kyon', 'randle', 'darrel', 'donato', 'giacomo', 'egbert', 'sabre', 'jud', 'jordana', 'virgilio', 'jedidiah', 'kemper', 'velda', 'liberty', 'karma', 'carlin', 'sena', 'mal', 'effie', 'christophe', 'ara', 'jahan', 'layne', 'macy', 'nature', 'jacinta', 'ofelia', 'anmol', 'kerrie', 'kristoff', 'juvenal', 'ozzie', 'lilith', 'habib', 'keoni', 'cherokee', 'navin', 'jamel', 'taha', 'hazen', 'nadiyah', 'vada', 'simona', 'brynn', 'sela', 'shiva', 'nabil', 'seiji', 'emi', 'delfina', 'gamaliel', 'auburn', 'marianna', 'jordy', 'fermin', 'maudie', 'raylene', 'lainie', 'emmanuelle', 'cara', 'adina', 'claudette', 'chiffon', 'isiah', 'kwame', 'diya', 'kelsi', 'berkeley', 'jager', 'sonal', 'abagail', 'dayna', 'shana', 'autumn', 'maham', 'rana', 'lamia', 'henery', 'caden', 'tinsley', 'gavino', 'kerwin', 'aishwarya', 'dong', 'raina', 'xia', 'sharona', 'ainsley', 'shiloh', 'mills', 'eladio', 'gerda', 'kodi', 'sari', 'kaisa', 'britney', 'normand', 'case', 'tessa', 'cordelia', 'ying', 'adela', 'wilbert', 'isaiah', 'morrell', 'doc', 'tyne', 'saxon', 'aya', 'mackie', 'boston', 'daimon', 'ziad', 'bay', 'divina', 'oleg', 'melodie', 'karel', 'ambrosio', 'shauna', 'manley', 'keshav', 'merton', 'mendy', 'lemuel', 'medina', 'burns', 'sage', 'marcelle', 'callum', 'easton', 'lucio', 'leilani', 'dozier', 'jarod', 'windy', 'tessie', 'perla', 'toren', 'kalen', 'annabell', 'orval', 'adelina', 'patric', 'tomasz', 'zara', 'faron', 'jia', 'amrit', 'sharif', 'magnus', 'bette', 'shreya', 'leva', 'joleen', 'gaurav', 'jet', 'indira', 'daya', 'bradlee', 'lissa', 'brockton', 'kenya', 'lorenz', 'sabina', 'daniele', 'kaleigh', 'bonifacio', 'raghav', 'rishabh', 'rodgers', 'kiana', 'sharice', 'israel', 'henna', 'zachariah', 'alam', 'latrelle', 'archana', 'brinn', 'gable', 'valery', 'nannie', 'moishe', 'reema', 'jacinto', 'keenan', 'asif', 'kelsey', 'corin', 'phebe', 'milos', 'andrej', 'clem', 'charis', 'keira', 'margarette', 'devika', 'valdemar', 'crew', 'sandhya', 'burnett', 'attila', 'dody', 'pieter', 'swathi', 'zina', 'tremaine', 'brighton', 'carmel', 'myrna', 'yitzchok', 'pierson', 'saba', 'devin', 'demetri', 'johannes', 'krishan', 'abbas', 'kavita', 'zakaria', 'zahid', 'andi', 'thomasine', 'prem', 'henny', 'elie', 'santana', 'marlo', 'antonius', 'tejas', 'monai', 'kaycee', 'brendon', 'layna', 'carrigan', 'mohammad', 'brevin', 'gretel', 'sima', 'gaye', 'tommaso', 'arianna', 'egypt', 'thi', 'elysia', 'dia', 'vivianne', 'demi', 'sienna', 'sunni', 'salina', 'aimee', 'yosef', 'lavern', 'nessa', 'monika', 'kristie', 'darrius', 'whitley', 'veena', 'faizan', 'zain', 'neel', 'sherard', 'hayley', 'amina', 'berit', 'cleophus', 'ashish', 'kiesha', 'january', 'wilmer', 'madelaine', 'valentino', 'muhammed', 'armen', 'ewell', 'chyna', 'leander', 'azura', 'elina', 'sheela', 'alexandre', 'mustapha', 'corbett', 'annika', 'carlita', 'garvin', 'jacky', 'nisa', 'tarun', 'arnie', 'easter', 'alanna', 'desiree', 'ami', 'salome', 'rickie', 'kaitlan', 'keefer', 'melonie', 'faustino', 'reinaldo', 'gracy', 'uri', 'friedrich', 'margaretta', 'nida', 'sheikh', 'khalid', 'dian', 'kasi', 'lavar', 'tommye', 'tayshawn', 'mindi', 'rebeka', 'valeri', 'freida', 'kelvin', 'estevan', 'alejandra', 'arlena', 'tien', 'michal', 'agustina', 'rahman', 'audry', 'kalle', 'amethyst', 'sami', 'fabrice', 'skyla', 'leda', 'veda', 'kwesi', 'myisha', 'nirali', 'madhav', 'sunita', 'rajesh', 'britton', 'celina', 'tequila', 'lanna', 'sneha', 'alexey', 'helga', 'kern', 'macarthur', 'karina', 'jaimie', 'farley', 'stacia', 'mariah', 'narissa', 'luci', 'weldon', 'harlow', 'varsha', 'dewan', 'jamila', 'leann', 'saphire', 'sakina', 'langley', 'zachery', 'severin', 'harman', 'harald', 'montreal', 'imaan', 'dona', 'jarret', 'ellsworth', 'kei', 'ilsa', 'einar', 'imelda', 'magali', 'drey', 'uma', 'arianne', 'hershel', 'beatriz', 'alvaro', 'columbus', 'reymond', 'arvin', 'babe', 'sierra', 'juniper', 'tylar', 'nona', 'kennard', 'lory', 'klara', 'maire', 'madelyn', 'laird', 'teodoro', 'marcelo', 'waverly', 'yvan', 'korin', 'adolfo', 'danyelle', 'elissa', 'kenzie', 'byrd', 'rutherford', 'alverna', 'abie', 'alim', 'remi', 'kamiya', 'sora', 'piotr', 'melton', 'malerie', 'twyla', 'karinna', 'cam', 'naveen', 'emmit', 'starlene', 'donal', 'suzan', 'ezequiel', 'pascual', 'anika', 'adler', 'dena', 'raza', 'amira', 'abu', 'lawyer', 'coltrane', 'faiz', 'mirza', 'thad', 'emme', 'darshan', 'aysha', 'amada', 'vadim', 'adi', 'cameo', 'raeanne', 'aldrich', 'jamin', 'yasmina', 'bela', 'dalila', 'anastacio', 'vittoria', 'shira', 'margery', 'chana', 'tenley', 'messiah', 'mikal', 'azalea', 'jarett', 'corrigan', 'akhil', 'nidhi', 'lark', 'candida', 'omega', 'faris', 'maricella', 'infant', 'aran', 'glenna', 'jelena', 'meghana', 'broderick', 'shiv', 'malissa', 'tung', 'hala', 'brittney', 'ashwin', 'raistlin', 'karly', 'spirit', 'prudence', 'cissy', 'brigham', 'rossy', 'fong', 'genaro', 'tanisha', 'ansel', 'edson', 'fuad', 'verity', 'oswaldo', 'florian', 'erskine', 'fredric', 'clarabelle', 'cecily', 'rosio', 'raquelle', 'lian', 'laddie', 'tiana', 'riva', 'doria', 'lillie', 'lidia', 'rush', 'kerri', 'kipp', 'winslow', 'ai', 'concepcion', 'amelie', 'whitman', 'bauer', 'emmitt', 'susanne', 'carrol', 'janki', 'hellen', 'octavian', 'bonita', 'delton', 'tyrel', 'leeanne', 'tu', 'holley', 'jerrold', 'jansen', 'sandor', 'norwood', 'zarina', 'helaine', 'silvio', 'vinnie', 'lazar', 'samar', 'corina', 'socrates', 'khadija', 'mohit', 'saida', 'abram', 'jabari', 'louella', 'salman', 'shruthi', 'riya', 'fernand', 'sanam', 'letitia', 'caren', 'alora', 'macklin', 'cherise', 'meghna', 'durward', 'yan', 'priyanka', 'vina', 'ankita', 'joycelyn', 'lanisha', 'leela', 'gerardo', 'ronda', 'ibrahima', 'deva', 'farid', 'france', 'luan', 'octavia', 'aki', 'amaryllis', 'payton', 'nella', 'marya', 'alek', 'jonnie', 'demond', 'colbie', 'arin', 'leonore', 'marit', 'kalin', 'spring', 'september', 'heston', 'corky', 'jonothan', 'kagen', 'evert', 'kailash', 'connell', 'tru', 'lourdes', 'sigrid', 'aris', 'deni', 'trinidad', 'cristy', 'eulalia', 'evelyne', 'deion', 'aiden', 'waldemar', 'joana', 'nihal', 'reshma', 'adolf', 'samy', 'autry', 'maeve', 'mehmet', 'samira', 'fatma', 'sivan', 'sana', 'marijo', 'lyda', 'yuka', 'kiefer', 'jory', 'jaclyn', 'serina', 'rami', 'freedom', 'lala', 'kailey', 'leighton', 'jasmin', 'nichole', 'gwynne', 'ginette', 'ciaran', 'kainan', 'yusuf', 'sindy', 'teya', 'trinh', 'cally', 'zebedee', 'mahogany', 'doctor', 'linsey', 'hurley', 'megumi', 'nika', 'haylei', 'baltazar', 'marleen', 'cindi', 'malone', 'malek', 'kaia', 'inger', 'rafaella', 'homero', 'fabiola', 'breanna', 'yi', 'krish', 'corie', 'ori', 'maud', 'vincente', 'priti', 'barnard', 'vignesh', 'chalmers', 'tamika', 'loraine', 'cicily', 'jena', 'sohail', 'arian', 'kiley', 'dennys', 'daytona', 'duron', 'aida', 'tianna', 'dimitris', 'callan', 'rakesh', 'petros', 'arina', 'karyn', 'shania', 'manon', 'mariann', 'gracia', 'luciana', 'darlena', 'susy', 'suzana', 'roshni', 'dom', 'palma', 'sai', 'tavares', 'diona', 'kincade', 'shad', 'shera', 'jairo', 'lotus', 'petar', 'fatimah', 'glinda', 'soham', 'travers', 'yadira', 'dany', 'ramya', 'yohan', 'roselyn', 'sibyl', 'cathleen', 'mignon', 'suki', 'bodie', 'ahsan', 'gerhard', 'dimitrius', 'jesusa', 'fonda', 'arvind', 'adria', 'landry', 'achilles', 'lita', 'winfield', 'deepa', 'hanne', 'norberto', 'bubba', 'racine', 'kishan', 'marly', 'carola', 'dagny', 'taggart', 'tae', 'alyson', 'yoni', 'akasha', 'albin', 'mystery', 'avin', 'suhas', 'abhishek', 'richa', 'gayatri', 'melville', 'sharron', 'nam', 'shilpa', 'guthrie', 'kory', 'christos', 'deven', 'snow', 'jermaine', 'erick', 'carline', 'avni', 'nanette', 'noni', 'pao', 'savion', 'albertine', 'sheilah', 'tiara', 'cross', 'beverley', 'dodge', 'alvah', 'colson', 'salvador', 'lyon', 'dasha', 'janna', 'aleksei', 'dima', 'hamdi', 'verne', 'karim', 'caron', 'hira', 'ritika', 'ananya', 'vinh', 'gisella', 'moshe', 'rosalia', 'suzanna', 'quin', 'erasmo', 'huda', 'malika', 'anabelle', 'shellie', 'giulio', 'maha', 'moises', 'ruhi', 'margarita', 'salima', 'mallika', 'nerissa', 'bibi', 'joon', 'vernell', 'keya', 'corliss', 'tashi', 'sherrie', 'ebba', 'ranger', 'jeana', 'coleen', 'legend', 'alastair', 'adama', 'alessia', 'alina', 'porfirio', 'adaline', 'tana', 'davi', 'khali', 'wheeler', 'bassam', 'marwan', 'hani', 'llewellyn', 'inge', 'roni', 'mariette', 'sonam', 'ernestina', 'corrie', 'sarrah', 'christi', 'jabbar', 'youssef', 'naseem', 'lu', 'cordero', 'dewayne', 'cashmere', 'rogelio', 'dagmar', 'bedford', 'jebediah', 'kristine', 'chrissie', 'anahita', 'zahrah', 'kianna', 'micky', 'janette', 'rima', 'talmadge', 'jacki', 'flossie', 'marna', 'sha', 'ciara', 'hennessey', 'talib', 'dori', 'rekha', 'sandeep', 'habiba', 'adel', 'osborne', 'misa', 'verona', 'kendrick', 'lyn', 'jordon', 'sita', 'courtenay', 'saffron', 'cristobal', 'pinkie', 'chika', 'kenta', 'shivam', 'aaliyah', 'dovid', 'athan', 'stirling', 'hendrick', 'mordecai', 'durell', 'mathilda', 'manisha', 'pansy', 'karishma', 'toy', 'isa', 'lauryn', 'amara', 'salma', 'baley', 'yahya', 'risa', 'paisley', 'bonni', 'akane', 'gaia', 'florentino', 'anushka', 'brianne', 'mellisa', 'katia', 'basilio', 'daniela', 'kayne', 'mateus', 'matias', 'mert', 'zeynep', 'adnan', 'stockton', 'salwa', 'debora', 'moody', 'letty', 'mariya', 'erickson', 'hall', 'akemi', 'nadir', 'miri', 'anant', 'sigurd', 'payal', 'despina', 'michela', 'kasia', 'zoran', 'liv', 'elvia', 'melodye', 'joss', 'shadrach', 'lorissa', 'noam', 'eusebio', 'elisha', 'earnest', 'garnet', 'maisy', 'preet', 'hao', 'bao', 'marlena', 'ryne', 'shazia', 'tasneem', 'jennefer', 'mya', 'elysabeth', 'lavelle', 'everardo', 'reiss', 'zena', 'howie', 'artur', 'meridith', 'fareed', 'brielle', 'dory', 'abelardo', 'isidoro', 'ruperto', 'ahmet', 'nhi', 'venessa', 'silvestre', 'rebel', 'abir', 'dacey', 'philipp', 'katharina', 'tee', 'sama', 'zeth', 'sirena', 'clayborn', 'caitlyn', 'cesario', 'sachi', 'cari', 'krissy', 'supriya', 'andra', 'delfino', 'josefina', 'shmuel', 'haroon', 'adalberto', 'rochel', 'janita', 'atlas', 'starlet', 'daryll', 'baily', 'cori', 'loki', 'manav', 'juhi', 'larissa', 'seline', 'adit', 'jeet', 'mandi', 'yakov', 'mazie', 'miley', 'lisette', 'mabry', 'keren', 'kushal', 'kien', 'mar', 'keshon', 'raynard', 'louden', 'dhruv', 'bray', 'walid', 'carrick', 'noor', 'zaid', 'branden', 'ethlyn', 'kessler', 'saskia', 'shaye', 'rei', 'mckay', 'cayce', 'syrus', 'ericka', 'trenton', 'jerrod', 'lizzy', 'hays', 'joelle', 'tyrelle', 'davida', 'akela', 'kawika', 'charlee', 'daryle', 'jeanene', 'indigo', 'selby', 'margaux', 'jannelle', 'celene', 'alberta', 'tyree', 'yana', 'kristian', 'boe', 'adan', 'chandni', 'sergey', 'azul', 'rosella', 'roshan', 'sascha', 'denzel', 'zana', 'kavya', 'kaori', 'raffi', 'dimas', 'cartier', 'avril', 'zenobia', 'yaffa', 'newman', 'sister', 'priest', 'benoit', 'aubry', 'masha', 'iman', 'abdel', 'gilman', 'aisling', 'rosalyn', 'mireya', 'andreia', 'trace', 'barrie', 'cathrine', 'madden', 'elana', 'wilford', 'vega', 'ripley', 'radford', 'nadira', 'henley', 'johanne', 'bhargav', 'auguste', 'wiliam', 'shasta', 'demetrious', 'rayla', 'tiny', 'lucile', 'alla', 'lona', 'milad', 'jamil', 'rosaura', 'nicoletta', 'rivaldo', 'emilia', 'dominga', 'melvyn', 'guilherme', 'flavio', 'alexandros', 'chaya', 'zion', 'asael', 'hamza', 'dayne', 'bethel', 'epiphany', 'ivonne', 'kieran', 'destry', 'izabel', 'jaleel', 'hina', 'luka', 'juliane', 'zoya', 'trapper', 'hildegarde', 'bertrand', 'roswell', 'anisha', 'mohsin', 'naeem', 'goldy', 'sejal', 'nadja', 'gisele', 'sammie', 'mayan', 'yuvraj', 'simpson', 'briar', 'krzysztof', 'tonie', 'dorianne', 'rayford', 'anusha', 'nitin', 'torey', 'nazir', 'vikas', 'stacie', 'fernanda', 'malachi', 'iana', 'garet', 'akiko', 'zacharia', 'ellena', 'kani', 'aspen', 'erna', 'najma', 'shailey', 'yousef', 'aakash', 'adora', 'menno', 'sahir', 'scot', 'trudie', 'zainab', 'nasim', 'tarek', 'leandro', 'garin', 'newell', 'tevin', 'hubbard', 'sumie', 'toshio', 'briana', 'jase', 'angelis', 'hermann', 'aicha', 'livingston', 'harlee', 'solveig', 'adrien', 'jubal', 'katara', 'thao', 'marilena', 'keyshawn', 'calliope', 'saray', 'bergen', 'doron', 'ameena', 'katlyn', 'ozzy', 'edy', 'roxanna', 'mahir', 'avia', 'mercer', 'ramzy', 'mallorie', 'rifka', 'bogdan', 'kamil', 'cydney', 'stefanos', 'immanuel', 'ekaterina', 'colm', 'alysha', 'linn', 'jiya', 'boaz', 'zahava', 'aamir', 'irie', 'carina', 'rodger', 'sahra', 'ayaan', 'omid', 'burak', 'boubacar', 'tremayne', 'orson', 'prachi', 'zoila', 'gwenyth', 'adeeb', 'kolton', 'nima', 'crista', 'farhan', 'essie', 'hadrian', 'korey', 'takiya', 'shun', 'lolly', 'kaseem', 'jett', 'viraj', 'josette', 'karol', 'coby', 'monta', 'zella', 'hughes', 'elwin', 'moussa', 'tramaine', 'eman', 'parks', 'iyanna', 'fanta', 'malachy', 'sarabeth', 'jalan', 'sajid', 'ayla', 'kedar', 'artemis', 'ares', 'zeus', 'oliva', 'shi', 'manish', 'duan', 'maki', 'belal', 'tenzin', 'prophet', 'becker', 'veronika', 'truitt', 'minda', 'ricci', 'hedy', 'frederica', 'cate', 'aleta', 'mylene', 'judit', 'elbert', 'lorene', 'qasim', 'geno', 'tisha', 'elaina', 'ela', 'kamber', 'hardin', 'irfan', 'danton', 'margareta', 'martell', 'nitya', 'babette', 'senora', 'azra', 'lenin', 'leif', 'ever', 'aksel', 'drexel', 'lonie', 'svea', 'shamus', 'jemma', 'odie', 'adrianna', 'saira', 'henrique', 'isaak', 'quadir', 'marcelino', 'carmelo', 'holmes', 'suzi', 'kaitlin', 'sallie', 'subhan', 'ariadne', 'jaqueline', 'kaz', 'dodie', 'jersey', 'finley', 'ebrahim', 'kenyatta', 'kamila', 'anis', 'lamine', 'ayan', 'amal', 'kimi', 'lei', 'zakir', 'ishani', 'nandita', 'prithvi', 'disha', 'anjana', 'harleen', 'bryn', 'makena', 'carolanne', 'mahdi', 'layth', 'mervin', 'minor', 'gala', 'paulino', 'kaiser', 'vanya', 'shady', 'jemima', 'lucienne', 'yasser', 'myriam', 'rosette', 'zackery', 'talbert', 'floretta', 'aissa', 'theophilus', 'sulaiman', 'celso', 'katrin', 'mikkel', 'vangie', 'kennan', 'nikko', 'bevan', 'meenakshi', 'hutton', 'schneider', 'maryjane', 'safia', 'tao', 'alyah', 'margarete', 'yasin', 'tala', 'oz', 'stefanie', 'farren', 'daena', 'evonne', 'alois', 'arik', 'heyward', 'jenine', 'nyra', 'rebecka', 'johnie', 'rawan', 'jihad', 'lindley', 'haili', 'maja', 'sinan', 'billi', 'rio', 'yoselin', 'sharan', 'tre', 'stephano', 'menachem', 'celestino', 'titan', 'zuleyma', 'hamed', 'joao', 'fabiana', 'gianna', 'caius', 'da', 'edi', 'rubi', 'mackay', 'catriona', 'naaman', 'kristoffer', 'delmas', 'halbert', 'milburn', 'arliss', 'mele', 'basia', 'aamna', 'hakeem', 'lem', 'taja', 'rockwell', 'pattie', 'alta', 'amer', 'rachelle', 'rasha', 'peri', 'gita', 'arnulfo', 'keefe', 'faisal', 'adriano', 'damion', 'gaetana', 'lawanda', 'elektra', 'addy', 'roxana', 'carissa', 'malia', 'deric', 'aggie', 'niall', 'rudolfo', 'martyn', 'mikki', 'cicely', 'chasen', 'zeinab', 'joann', 'veta', 'naja', 'dream', 'violeta', 'yoko', 'stefano', 'hally', 'francisca', 'konstantinos', 'maksim', 'tamra', 'yuta', 'genoveva', 'rea', 'juli', 'kimber', 'sailor', 'nila', 'caitlynn', 'brinda', 'mariano', 'ines', 'dereck', 'algie', 'suri', 'venice', 'akil', 'navy', 'jeramiah', 'kirstin', 'faraz', 'kassie', 'rebeca', 'saif', 'kawan', 'rhiannon', 'hashim', 'nazar', 'ivey', 'devan', 'sarena', 'tomi', 'veer', 'natale', 'matteo', 'margit', 'maddox', 'aleksandra', 'ximena', 'isaias', 'ridley', 'cecilio', 'polina', 'aleksey', 'stratton', 'davide', 'lesley', 'roseanna', 'annetta', 'jada', 'clemens', 'maximus', 'aeron', 'alvie', 'bohdan', 'betti', 'matti', 'shareen', 'hanif', 'arlette', 'cornelio', 'pervis', 'maddy', 'waylen', 'jilian', 'tennyson', 'malin', 'polo', 'zahraa', 'loredana', 'sayra', 'yamila', 'horacio', 'tierra', 'eion', 'blakelee', 'heaven', 'carmelina', 'imogen', 'mica', 'gael', 'khaliq', 'heinz', 'grayden', 'ric', 'everette', 'satya', 'destin', 'gemini', 'corban', 'andromeda', 'solon', 'dermot', 'vicente', 'catalina', 'teofilo', 'nena', 'ziggy', 'emon', 'gershon', 'sachin', 'alf', 'florrie', 'castor', 'dillinger', 'selwyn', 'hernando', 'eneida', 'antoni', 'leonie', 'bretton', 'minna', 'buren', 'hermine', 'dalen', 'jannie', 'marielle', 'bram', 'tuesday', 'tian', 'asli', 'nevin', 'efrain', 'andree', 'jordi', 'amaya', 'peng', 'cardell', 'naina', 'beaux', 'kendra', 'janson', 'tonia', 'marcelina', 'hulda', 'adelaida', 'mayme', 'marlen', 'elia', 'miquel', 'stephane', 'madigan', 'miette', 'natanya', 'cayenne', 'knowledge', 'selin', 'esmerelda', 'yancey', 'catie', 'sable', 'rawley', 'nithya', 'carmelita', 'mikael', 'suhani', 'casimiro', 'ivette', 'tadd', 'boden', 'laurin', 'frederik', 'tolbert', 'lela', 'sohan', 'wyeth', 'kyleigh', 'rhys', 'hettie', 'phylis', 'orla', 'loris', 'gatlin', 'muna', 'nabeel', 'fadi', 'tanja', 'koda', 'sander', 'vani', 'camila', 'syed', 'santina', 'marletta', 'duff', 'jhonny', 'conchita', 'shanaya', 'jibril', 'genna', 'korah', 'sewell', 'clotilde', 'carman', 'maryanne', 'deniz', 'lysander', 'pavan', 'canyon', 'janani', 'farrel', 'bell', 'aziza', 'gwyn', 'arlington', 'treshawn', 'izaak', 'kareena', 'kyndra', 'montie', 'karmin', 'princeton', 'lawton', 'mont', 'wilburn', 'cinthya', 'colbert', 'fannie', 'noora', 'eder', 'madelon', 'melbourne', 'brayson', 'rolly', 'can', 'saralyn', 'joannie', 'lean', 'kaley', 'latham', 'ashely', 'luann', 'angi', 'yaseen', 'dennison', 'rollin', 'semaj', 'arushi', 'josemaria', 'jatin', 'syrena', 'jomar', 'ashleigh', 'bernhard', 'dalia', 'claudie', 'dagen', 'mireille', 'rosamaria', 'om', 'herb', 'tareq', 'hanan', 'jameelah', 'siddhartha', 'dj', 'saint', 'galina', 'elka', 'keiko', 'yola', 'wynne', 'tiberius', 'albany', 'rodrick', 'kaleo', 'ange', 'nereida', 'aries', 'blakely', 'emir', 'heinrich', 'dasan', 'matthieu', 'latisha', 'woodford', 'crissy', 'huber', 'aleksander', 'rommel', 'nia', 'shai', 'aoife', 'mesa', 'kirra', 'lachlan', 'shama', 'raya', 'porsche', 'masson', 'joby', 'amie', 'zadie', 'paradise', 'davie', 'kaitlyn', 'edoardo', 'koran', 'saleena', 'sho', 'zehra', 'rivkah', 'tirzah', 'ambika', 'jair', 'constanza', 'marga', 'ki', 'zen', 'kurtis', 'chai', 'everly', 'deanne', 'kina', 'lacie', 'sarkis', 'clover', 'rasheen', 'colter', 'mahima', 'abhiram', 'bjorn', 'ashlee', 'tilly', 'armond', 'leola', 'adarsh', 'phong', 'linh', 'elmore', 'adon', 'katja', 'kenzo', 'larsen', 'jarred', 'reza', 'carsten', 'stormy', 'bonny', 'talena', 'aniket', 'dot', 'stetson', 'calissa', 'deandra', 'marva', 'mannie', 'malina', 'alin', 'raynor', 'drea', 'elif', 'karna', 'kiya', 'cason', 'oakland', 'nicol', 'venetia', 'iram', 'armaan', 'shyann', 'sahib', 'nadiya', 'nicklas', 'zacharias', 'armani', 'meng', 'bowden', 'muskan', 'aneesa', 'andria', 'mikhael', 'ananda', 'alford', 'eshaan', 'rajveer', 'lejla', 'melford', 'jacinda', 'enoch', 'avon', 'hildegard', 'filip', 'ashlynn', 'deana', 'britta', 'amalie', 'venezia', 'jeremie', 'gladis', 'ewan', 'aren', 'vashti', 'domenico', 'laya', 'meagan', 'tyra', 'oona', 'madalyn', 'lelia', 'ericca', 'karlo', 'karrie', 'townsend', 'diamante', 'delvin', 'amr', 'annmarie', 'rianna', 'alissa', 'nyla', 'cristopher', 'milla', 'kaden', 'dione', 'neeraj', 'brannen', 'reeve', 'penney', 'yasmine', 'merri', 'khushi', 'wendi', 'shabnam', 'sherwin', 'kamara', 'darina', 'rian', 'larue', 'riah', 'deshawn', 'westin', 'daisey', 'alter', 'hernan', 'jacie', 'aadil', 'dacia', 'nikola', 'milka', 'siddhant', 'yassin', 'mubarak', 'mattia', 'saverio', 'soloman', 'erminia', 'romi', 'samarth', 'marylou', 'tarah', 'stephany', 'anette', 'feliciano', 'sravya', 'rania', 'adithi', 'sidharth', 'dulce', 'ginnie', 'sian', 'eleonora', 'aili', 'sakari', 'carli', 'palmira', 'isabell', 'sofiya', 'ona', 'darek', 'keiron', 'nawal', 'fahim', 'maika', 'theresia', 'japhet', 'steel', 'alyce', 'loyd', 'vikrant', 'signe', 'rui', 'kemal', 'saad', 'ramzi', 'kamel', 'yahia', 'bane', 'mariela', 'isaura', 'lizbet', 'odessa', 'wayman', 'kush', 'kadir', 'kadin', 'wendall', 'ariadna', 'mckenna', 'jacolby', 'anselmo', 'chetan', 'calise', 'micheline', 'tadhg', 'maher', 'macey', 'mana', 'kailani', 'francene', 'saahil', 'damir', 'carrington', 'dua', 'mizuki', 'hagop', 'wafa', 'zahira', 'armon', 'farida', 'benicio', 'latonya', 'jerzy', 'jayanth', 'anirudh', 'selden', 'niya', 'calogero', 'danilo', 'bora', 'aleksandar', 'xian', 'aden', 'karsten', 'fathima', 'whit', 'arora', 'ryland', 'abbott', 'auden', 'safiyah', 'makoto', 'gurleen', 'giorgia', 'eliana', 'mayumi', 'ishika', 'rosendo', 'raymundo', 'neva', 'galia', 'darrien', 'harlin', 'tula', 'seneca', 'heavenly', 'adem', 'kona', 'stefania', 'raffaele', 'graciella', 'kenia', 'jaxx', 'gabriele', 'haydon', 'lux', 'sruthi', 'miryam', 'mikela', 'enola', 'aedan', 'alicja', 'charolette', 'aadam', 'sinai', 'eliezer', 'yair', 'yona', 'uriel', 'devora', 'takumi', 'inari', 'beautiful', 'colman', 'ottilie', 'hiroto', 'nishi', 'gauri', 'edmundo', 'rayan', 'riana', 'ashanti', 'rayyan', 'nicolle', 'alaska', 'param', 'adelin', 'matei', 'cali', 'azucena', 'manson', 'kimani', 'leopoldo', 'akio', 'bryer', 'ajla', 'treasure', 'tammie', 'adil', 'jasleen', 'kenza', 'hamish', 'cloey', 'sayuri', 'jak', 'mazal', 'muskaan', 'hermione', 'delwyn', 'kaito', 'kadee', 'harsh', 'dade', 'kerstin', 'maisie', 'marjory', 'manpreet', 'marli', 'carys', 'lainee', 'dynasty', 'korea', 'aiko', 'girl', 'paco', 'gates', 'calista', 'kutter', 'yanni', 'tiffani', 'rainier', 'isla', 'karam', 'nyle', 'sabino', 'niharika', 'maliq', 'lofton', 'keerthi', 'kartik', 'honor', 'juna', 'breckin', 'kaleb', 'sharla', 'yael', 'yoav', 'abdi', 'mehdi', 'kolt', 'mackinley', 'alvina', 'husain', 'bina', 'mame', 'cai', 'imaad', 'zandra', 'ronal', 'rice', 'mihika', 'bowie', 'shanel', 'canton', 'sixto', 'sherrod', 'harun', 'jamarcus', 'jameel', 'jacque', 'fredy', 'kolbe', 'eagan', 'hanah', 'abhi', 'elin', 'rafaela', 'ronit', 'romina', 'kofi', 'verena', 'hayat', 'deon', 'takeo', 'shirin', 'blessing', 'sahar', 'mir', 'mateen', 'neela', 'meher', 'vanda', 'khoi', 'yann', 'avalon', 'taylar', 'jayden', 'dotty', 'aylin', 'tamera', 'gilmore', 'cruise', 'maye', 'oriana', 'tarissa', 'zowie', 'taffy', 'tuff', 'coltan', 'edgardo', 'stryder', 'zaira', 'justo', 'kenner', 'giovana', 'romana', 'dezi', 'keziah', 'milford', 'nikolay', 'jaxson', 'pharaoh', 'lynnette', 'pari', 'koen', 'edwardo', 'madalena', 'ave', 'zeta', 'zac', 'arcadia', 'evita', 'jameela', 'geraldo', 'alessandra', 'niomi', 'micha', 'muhamed', 'jazmine', 'orchid', 'amador', 'drayke', 'darrow', 'glennon', 'haroun', 'ronin', 'tera', 'clea', 'evaristo', 'vivica', 'shem', 'japheth', 'serene', 'kathrine', 'zelma', 'beauregard', 'carlina']\n",
      "Number of names : 6034\n"
     ]
    }
   ],
   "source": [
    "# get all the names in the name_by_movie_with_info dataframe\n",
    "names = name_by_movie_with_info.index.get_level_values(0).unique().tolist()\n",
    "print(names)\n",
    "print(f\"Number of names : {len(names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of name treated: 6033\r"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for name in names:\n",
    "    print(f\"Number of name treated: {iter}\", end='\\r', flush=True)\n",
    "    # get the movie containing the chosen name\n",
    "    chosen_name_movies_df = name_by_movie_with_info.loc[name, :].copy(deep=True)\n",
    "\n",
    "    # sort the movies by slope_change, get movies with significant p_value and positive slope_change and compute the top 5\n",
    "    chosen_name_movies_df.sort_values(by=['slope_change'], inplace=True)\n",
    "    chosen_name_movies_top_df = chosen_name_movies_df.query('(slope_change > 0) and (p_value < 0.1)').copy(deep=True)\n",
    "    # display(chosen_name_movies_top_df)\n",
    "    compute_top_movies(name, chosen_name_movies_top_df, movie_impact_df)\n",
    "\n",
    "    # sort the movies by slope_change, get movies with significant p_value and negative slope_change and compute the bottom 5\n",
    "    chosen_name_movies_bottom_df = chosen_name_movies_df.query('(slope_change <= 0) and (p_value < 0.1)').copy(deep=True)\n",
    "    chosen_name_movies_bottom_df.sort_values(by=['slope_change'], ascending=False, inplace=True)\n",
    "    compute_bottom_movies(name, chosen_name_movies_bottom_df, movie_impact_df)\n",
    "\n",
    "    # get the remaining movies and filter to keep only the insignificant ones and compute the insign 5\n",
    "    # remaining_chosen_name_movies_df = pd.concat([chosen_name_movies_top_df, chosen_name_movies_bottom_df])\n",
    "    chosen_name_movies_insign_df = chosen_name_movies_df.query('p_value > 0.1').copy(deep=True)\n",
    "    chosen_name_movies_insign_df.sort_values(by=['averageRating', 'numVotes'], inplace=True)\n",
    "    compute_insign_movies(name, chosen_name_movies_insign_df, movie_impact_df)\n",
    "    \n",
    "    iter = iter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">linda</th>\n",
       "      <th>t</th>\n",
       "      <td>14350910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>4070671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>9956825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>2212664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>28288095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serene</th>\n",
       "      <th>i</th>\n",
       "      <td>36544941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kathrine</th>\n",
       "      <th>i</th>\n",
       "      <td>36546325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zelma</th>\n",
       "      <th>i</th>\n",
       "      <td>36598217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beauregard</th>\n",
       "      <th>b</th>\n",
       "      <td>36699915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carlina</th>\n",
       "      <th>i</th>\n",
       "      <td>37196243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27854 rows Ã 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   movie_id\n",
       "name       status          \n",
       "linda      t       14350910\n",
       "           b        4070671\n",
       "           b        9956825\n",
       "           b        2212664\n",
       "           b       28288095\n",
       "...                     ...\n",
       "serene     i       36544941\n",
       "kathrine   i       36546325\n",
       "zelma      i       36598217\n",
       "beauregard b       36699915\n",
       "carlina    i       37196243\n",
       "\n",
       "[27854 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# movie_impact_df.set_index(['name', 'status'], inplace=True)\n",
    "display(movie_impact_df)\n",
    "\n",
    "# Export DataFrame to a CSV file in the processed data folder\n",
    "# movie_impact_df.reset_index(drop=True).sort_values(by=['name', 'status']).to_csv(os.path.join(processed_website_data_folder, 'movie_impact.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import `movie_impact` dataframe to avoid timeconsuming computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the movie_impact_df to avoid the time-consuming computation of movie_impact_df\n",
    "imported_movie_impact_df = pd.read_csv(os.path.join(processed_website_data_folder, 'movie_impact.csv'))\n",
    "imported_movie_impact_df.set_index(['name', 'status'], inplace=True)\n",
    "display(imported_movie_impact_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values in the name column\n",
    "contains_nan = imported_movie_impact_df.reset_index()['name'].isna().any()\n",
    "\n",
    "if contains_nan:\n",
    "    print(\"The `name` column contains NaN values.\")\n",
    "else:\n",
    "    print(\"The `name` column does not contain NaN values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN values in the name column\n",
    "print(f\"Length of imported_movie_impact_df before dropping NaN values : {len(imported_movie_impact_df)}\")\n",
    "imported_movie_impact_df.reset_index(inplace=True)\n",
    "imported_movie_impact_df.dropna(subset=['name'], inplace=True)\n",
    "imported_movie_impact_df.set_index(['name', 'status'], inplace=True)\n",
    "print(f\"Length of imported_movie_impact_df after dropping NaN values : {len(imported_movie_impact_df)}\")\n",
    "\n",
    "display(imported_movie_impact_df)\n",
    "movie_impact_df = imported_movie_impact_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute `name_per_year` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the indexing of name_per_year unique? True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Burley</th>\n",
       "      <th>1924</th>\n",
       "      <td>0.001596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alondria</th>\n",
       "      <th>1985</th>\n",
       "      <td>0.000196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               percentage\n",
       "name     year            \n",
       "Burley   1924    0.001596\n",
       "Alondria 1985    0.000196"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the name_per_year_df : 1903290\n"
     ]
    }
   ],
   "source": [
    "# import the babynames dataframe\n",
    "name_per_year = pd.read_csv(os.path.join(folder_processed_data_path, 'baby_name_df.csv'))\n",
    "name_per_year.drop(columns='number', inplace=True)\n",
    "name_per_year.set_index(['name', 'year'], inplace=True)\n",
    "print(f\"Is the indexing of name_per_year unique? {name_per_year.index.is_unique}\")\n",
    "display(name_per_year.sample(2))\n",
    "print(f\"Length of the name_per_year_df : {len(name_per_year)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shar</th>\n",
       "      <th>1969</th>\n",
       "      <td>0.000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genaro</th>\n",
       "      <th>1941</th>\n",
       "      <td>0.001272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             percentage\n",
       "name   year            \n",
       "shar   1969    0.000230\n",
       "genaro 1941    0.001272"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the name_per_year_df : 1903290\n"
     ]
    }
   ],
   "source": [
    "# round the percentage values to reduce the size of the future csv file for the web\n",
    "name_per_year['percentage'] = name_per_year['percentage'].round(6)\n",
    "\n",
    "# set the names in lowercases\n",
    "name_per_year.reset_index(inplace=True)\n",
    "name_per_year['name'] = name_per_year['name'].str.lower()\n",
    "name_per_year.set_index(['name', 'year'], inplace=True)\n",
    "\n",
    "display(name_per_year.sample(2))\n",
    "print(f\"Length of the name_per_year_df : {len(name_per_year)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the name_per_year_df to keep only the names in the movie_impact_df\n",
    "name_per_year_filtered = name_per_year.loc[movie_impact_df['name'].unique().tolist(), :].copy(deep=True)\n",
    "name_per_year = name_per_year_filtered.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">aadam</th>\n",
       "      <th>1987</th>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.000186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.000161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.000164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.000137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.000218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.000159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>0.000294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>0.000263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>0.000156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>0.000228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            percentage\n",
       "name  year            \n",
       "aadam 1987    0.000139\n",
       "      1988    0.000135\n",
       "      1993    0.000186\n",
       "      1994    0.000161\n",
       "      1995    0.000164\n",
       "      1996    0.000137\n",
       "      1997    0.000138\n",
       "      1998    0.000218\n",
       "      1999    0.000135\n",
       "      2000    0.000159\n",
       "      2002    0.000294\n",
       "      2003    0.000263\n",
       "      2004    0.000236\n",
       "      2005    0.000156\n",
       "      2006    0.000228"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's sort the dataframe name_per_year to anticipate the ploting\n",
    "name_per_year.sort_values(by=['name', 'year'], inplace=True)\n",
    "display(name_per_year.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the names present in name_per_year dataframe are also present in the name_by_movie dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique names in name_per_year  = 6034\n",
      "Values in name_per_year but not present in name_by_movie:\n",
      "[]\n",
      "Number of names missing  = 0\n"
     ]
    }
   ],
   "source": [
    "# Identify names in name_per_year not present in name_by_movie\n",
    "values_only_in_name_per_year = name_per_year.reset_index()[~name_per_year.reset_index()['name'].isin(name_by_movie_with_info.reset_index()['char_words'])]['name'].unique()\n",
    "\n",
    "print(f\"Number of unique names in name_per_year  = {len(name_per_year.reset_index()['name'].unique())}\")\n",
    "\n",
    "# Display the result\n",
    "print(\"Values in name_per_year but not present in name_by_movie:\")\n",
    "print(values_only_in_name_per_year)\n",
    "print(f\"Number of names missing  = {len(values_only_in_name_per_year)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique names in name_by_movie_with_info  = 6034\n",
      "Values in name_by_movie_with_info but not present in name_per_year:\n",
      "[]\n",
      "Number of names missing  = 0\n"
     ]
    }
   ],
   "source": [
    "# Identify names in name_by_movie not present in name_per_year\n",
    "values_only_in_name_by_movie = name_by_movie_with_info.reset_index()[~name_by_movie_with_info.reset_index()['char_words'].isin(name_per_year.reset_index()['name'])]['char_words'].unique()\n",
    "\n",
    "print(f\"Number of unique names in name_by_movie_with_info  = {len(name_by_movie_with_info.reset_index()['char_words'].unique())}\")\n",
    "\n",
    "# Display the result\n",
    "print(\"Values in name_by_movie_with_info but not present in name_per_year:\")\n",
    "print(values_only_in_name_by_movie)\n",
    "print(f\"Number of names missing  = {len(values_only_in_name_by_movie)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the number of names in the three dataframes in order to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique names in name_per_year = 6034\n",
      "Number of unique names in movie_impact_df = 6034\n",
      "Number of unique names in name_by_movie_with_info = 6034\n"
     ]
    }
   ],
   "source": [
    "# compute how many unique names are there in the dataframes to compare\n",
    "names_in_name_per_year = name_per_year.index.get_level_values(0).unique().tolist()\n",
    "print(f\"Number of unique names in name_per_year = {len(names_in_name_per_year)}\")\n",
    "names_in_movie_impact = movie_impact_df.reset_index()['name'].unique().tolist()\n",
    "print(f\"Number of unique names in movie_impact_df = {len(names_in_movie_impact)}\")\n",
    "names_in_name_by_movie_with_info = name_by_movie_with_info.reset_index()['char_words'].unique().tolist()\n",
    "print(f\"Number of unique names in name_by_movie_with_info = {len(names_in_name_by_movie_with_info)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute `movies` dataframe\n",
    "This dataset contains the information relative to the movie given its `wiki_ID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies in movie_impact_df : 13953\n",
      "Number of movies kept in movie_df: 13953\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mov_name</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>revenue</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>poster_url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5980485</th>\n",
       "      <td>Polish Wedding</td>\n",
       "      <td>1998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>600294.0</td>\n",
       "      <td>3401</td>\n",
       "      <td>5.5</td>\n",
       "      <td>/36De1BxBBzXyJ1eYVQlIoTUIwQm.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27988012</th>\n",
       "      <td>Vaanam</td>\n",
       "      <td>2011</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1914</td>\n",
       "      <td>7.3</td>\n",
       "      <td>/kE9kN2iFaM77suP00RHYMOoqUos.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mov_name  year  month   revenue  numVotes  averageRating  \\\n",
       "wiki_ID                                                                    \n",
       "5980485   Polish Wedding  1998    1.0  600294.0      3401            5.5   \n",
       "27988012          Vaanam  2011    4.0       NaN      1914            7.3   \n",
       "\n",
       "                                poster_url  \n",
       "wiki_ID                                     \n",
       "5980485   /36De1BxBBzXyJ1eYVQlIoTUIwQm.jpg  \n",
       "27988012  /kE9kN2iFaM77suP00RHYMOoqUos.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Number of movies in movie_impact_df : {len(movie_impact_df['movie_id'].unique())}\")\n",
    "# keep only the movies in the movie_df that are in the movie_impact_df\n",
    "simplified_movie_df = movie_df.loc[movie_impact_df['movie_id'].unique().tolist(), :].copy(deep=True)\n",
    "print(f\"Number of movies kept in movie_df: {len(simplified_movie_df)}\")\n",
    "display(simplified_movie_df.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the three datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13987</th>\n",
       "      <td>anastasia</td>\n",
       "      <td>i</td>\n",
       "      <td>16305665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24731</th>\n",
       "      <td>leilani</td>\n",
       "      <td>t</td>\n",
       "      <td>3753182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name status  movie_id\n",
       "13987  anastasia      i  16305665\n",
       "24731    leilani      t   3753182"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218193</th>\n",
       "      <td>hedy</td>\n",
       "      <td>1943</td>\n",
       "      <td>0.003047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104918</th>\n",
       "      <td>colette</td>\n",
       "      <td>1974</td>\n",
       "      <td>0.008256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  year  percentage\n",
       "218193     hedy  1943    0.003047\n",
       "104918  colette  1974    0.008256"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>mov_name</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>revenue</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>poster_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>23520462</td>\n",
       "      <td>Deep Gold</td>\n",
       "      <td>2011</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>363</td>\n",
       "      <td>3.2</td>\n",
       "      <td>/4eCQoTJ3QXDxBlXChlc7cF909WO.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9107</th>\n",
       "      <td>24517581</td>\n",
       "      <td>The Naked Face</td>\n",
       "      <td>1984</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1438</td>\n",
       "      <td>5.5</td>\n",
       "      <td>/4RHE44sgmW44pd6Klf4cfGVOm0C.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wiki_ID        mov_name  year  month  revenue  numVotes  averageRating  \\\n",
       "5323  23520462       Deep Gold  2011    4.0      NaN       363            3.2   \n",
       "9107  24517581  The Naked Face  1984    6.0      NaN      1438            5.5   \n",
       "\n",
       "                            poster_url  \n",
       "5323  /4eCQoTJ3QXDxBlXChlc7cF909WO.jpg  \n",
       "9107  /4RHE44sgmW44pd6Klf4cfGVOm0C.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Export movie_impact.csv\n",
    "display(movie_impact_df.reset_index().sample(2))\n",
    "movie_impact_df.reset_index().to_csv(os.path.join(processed_website_data_folder, 'movie_impacts.csv'), index=False)\n",
    "\n",
    "# Export name_per_year.csv\n",
    "display(name_per_year.reset_index().sample(2))\n",
    "name_per_year.reset_index().to_csv(os.path.join(processed_website_data_folder, 'name_per_year.csv'), index=False)\n",
    "\n",
    "# Export movie.csv\n",
    "display(simplified_movie_df.reset_index().sample(2))\n",
    "simplified_movie_df.reset_index().to_csv(os.path.join(processed_website_data_folder, 'movies.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_processed_data_path = './processed_data/'\n",
    "\n",
    "# import the name_by_movie dataframe\n",
    "name_by_movie_df = pd.read_csv(os.path.join(folder_processed_data_path, 'name_by_movie_ordered_df.csv'))\n",
    "name_by_movie_df.set_index(['wiki_ID', 'char_words', 'gender'], inplace=True)\n",
    "display(name_by_movie_df.sample(2))\n",
    "\n",
    "# import the movie dataframe\n",
    "movie_df = pd.read_csv(os.path.join(folder_processed_data_path, 'movie_df.csv'))\n",
    "movie_df.set_index(['wiki_ID'], inplace=True)\n",
    "display(movie_df.sample(2))\n",
    "\n",
    "# import the baby names dataframe\n",
    "baby_name_df = pd.read_csv(os.path.join(folder_processed_data_path, 'baby_name_df.csv'))\n",
    "baby_name_df.set_index(['name', 'year'], inplace=True)\n",
    "display(baby_name_df.sample(2))\n",
    "\n",
    "# create dataframe containing the release year of each movie\n",
    "release_year_df = movie_df[['year', 'numVotes']].copy(deep=True)\n",
    "display(release_year_df.sample(2))\n",
    "\n",
    "# import the name_by_movie with the slope difference\n",
    "name_by_movie_slope_diff_df = pd.read_csv(os.path.join(folder_processed_data_path, 'name_by_movie_ordered_pvalue_10_5_df.csv'))\n",
    "name_by_movie_slope_diff_df.set_index(['wiki_ID', 'char_words', 'gender'], inplace=True)\n",
    "display(name_by_movie_slope_diff_df.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing for the website\n",
    "In this notebook, we filter the `name_by_movie` dataframe in order to remove the movie character too little known to have had an impact on the baby names. We will assess the popularity of the charcter based on the number of IMDB ratings of the movie and whether its role was important by using the `order` attribute.\n",
    "\n",
    "In addition, an issue related to the limitation of the data is assessed here. The problem is that for two movies released the same year that has the same name for one of their character, we can't tell which of them had an impact on the name given to babies. To assess this problem, we will keep only the most popular movie based on the number of IMDB ratings.\n",
    "\n",
    "### Filtering of `name_by_movie` : number of ratings\n",
    "\n",
    "First, let's remove the character names of movies with less than 100 IMDB ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_by_movie_df.reset_index(inplace=True)\n",
    "movie_df.reset_index(inplace=True)\n",
    "\n",
    "name_by_movie_df_merged = name_by_movie_df.merge(release_year_df, left_on='wiki_ID', right_on='wiki_ID', how = 'left').copy(deep=True)\n",
    "print(f\"length of the initial dataframe : {len(name_by_movie_df)}\")\n",
    "print(f\"length of the merged dataframe : {len(name_by_movie_df_merged)}\")\n",
    "display(name_by_movie_df_merged.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_by_movie_df_merged_filter_nbratings = name_by_movie_df_merged[name_by_movie_df_merged['numVotes'] >= 1000].copy(deep=True)\n",
    "print(f\"length of the initial dataframe : {len(name_by_movie_df)}\")\n",
    "print(f\"length of the filtered dataframe : {len(name_by_movie_df_merged_filter_nbratings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering of `name_by_movie`  : importance of the role\n",
    "\n",
    "Now, lets remove the character names with an minor role in the movie. We will keep only the characters with a order higher or equal to the median of the set of order in the movie. First, let's compute the number of order for each movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is it normal that not all the movies in movies_df have at least one character in name_by_movie_df ? TODO\n",
    "# display(movie_df[movie_df['wiki_ID'] == 844398])\n",
    "# display(name_by_movie_df[name_by_movie_df['wiki_ID'] == 844398])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_by_movie_merged_groupby = name_by_movie_df_merged_filter_nbratings.groupby(['wiki_ID'])\n",
    "name_by_movie_merged_nunique = name_by_movie_merged_groupby['order'].nunique()\n",
    "\n",
    "# check for a specific movie\n",
    "test_movie_id = 617063\n",
    "\n",
    "for movie_id, group in name_by_movie_merged_groupby:\n",
    "    if(movie_id == (test_movie_id,)):\n",
    "        print('movie_id', movie_id)\n",
    "        print('group', group)\n",
    "\n",
    "print(f\"number of unique order = {name_by_movie_merged_nunique[test_movie_id]}\")\n",
    "name_by_movie_merged_nunique = name_by_movie_merged_nunique.to_frame()\n",
    "name_by_movie_merged_nunique.rename(columns={\"order\": \"nb_order\"}, inplace=True)\n",
    "display(name_by_movie_merged_nunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_by_movie_merged_with_nunique = name_by_movie_df_merged_filter_nbratings.merge(name_by_movie_merged_nunique, on='wiki_ID', how='left')\n",
    "display(name_by_movie_merged_with_nunique.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering\n",
    "name_by_movie_merged_important_role = name_by_movie_merged_with_nunique[name_by_movie_merged_with_nunique['order'] <= name_by_movie_merged_with_nunique['nb_order']].copy(deep=True)\n",
    "name_by_movie_merged_important_role.drop(columns=['order', 'nb_order'], inplace=True)\n",
    "print(f\"length of the initial dataframe : {len(name_by_movie_df)}\")\n",
    "print(f\"length of the filtered dataframe : {len(name_by_movie_merged_important_role)}\")\n",
    "display(name_by_movie_merged_important_role.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering  `name_by_movie` : keep three most famous character of the year only\n",
    "In a given year, several movies may have been released with the same name for one of their character. This is problematic because it is impossible to know which of the movie had an impact on the baby naming of the given name (if it had any). To solve this problem, we keep three most famous movies (based on the number of rating) for each year and name in the dataset. \n",
    "\n",
    "First, we need to remove the gender attribute which is annoying because some of the characters are twice in the dataset once for each genders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop gender column\n",
    "len_before = len(name_by_movie_merged_important_role)\n",
    "name_by_movie_merged_important_role.drop_duplicates(subset=['wiki_ID', 'char_words'], keep='first', inplace=True)\n",
    "name_by_movie_merged_important_role.drop(columns=['gender'], inplace=True)\n",
    "len_after = len(name_by_movie_merged_important_role)\n",
    "print(f\"length before : {len_before}\")\n",
    "print(f\"length after : {len_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can filter the `name_by_movie` dataframe in order to keep only the three most popular movies for each year and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_by_movie_merged_three_characters_only = name_by_movie_merged_important_role.sort_values(by='numVotes', ascending=False).groupby(['year', 'char_words']).head(3).reset_index(drop=True)\n",
    "\n",
    "display(name_by_movie_merged_three_characters_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make a first test to see if the filtering is correct for a specific case: the name Daniel, in 2001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check before\n",
    "test_word = 'Daniel'\n",
    "test_year = 2001\n",
    "test_df = name_by_movie_merged_important_role[name_by_movie_merged_important_role['char_words'] == test_word]\n",
    "test_df = test_df[test_df['year'] == test_year]\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check after\n",
    "test_df = name_by_movie_merged_three_characters_only[name_by_movie_merged_three_characters_only['char_words'] == test_word]\n",
    "test_df = test_df[test_df['year'] == test_year]\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"length of the initial dataframe : {len(name_by_movie_df)}\")\n",
    "print(f\"length of the filtered dataframe : {len(name_by_movie_merged_three_characters_only)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the custom `web_name_by_movie_df`\n",
    "Finally, we create the dataframe that will be used in the website. To do so, we add information about the movie on the `name_by_movie` dataframe created until now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(name_by_movie_merged_three_characters_only.sample(2))\n",
    "# display(movie_df)\n",
    "\n",
    "# Add movie info to the dataframe\n",
    "temp_merge_df = movie_df[['wiki_ID', 'mov_name', 'averageRating', 'poster_url']].copy(deep=True)\n",
    "web_name_by_movie_df = name_by_movie_merged_three_characters_only.merge(temp_merge_df, on='wiki_ID', how='left').copy(deep=True)\n",
    "\n",
    "# Reorder the columns\n",
    "desired_columns_order = ['char_words', 'wiki_ID', 'mov_name', 'year', 'averageRating', 'numVotes', 'poster_url']\n",
    "web_name_by_movie_df = web_name_by_movie_df[desired_columns_order].copy(deep=True)\n",
    "web_name_by_movie_df.set_index(['char_words', 'wiki_ID'], inplace=True)\n",
    "\n",
    "# Check if the indexing is unique\n",
    "print(f\"Is the indexing of web_name_by_movie_df unique ? {web_name_by_movie_df.index.is_unique}\")\n",
    "display(web_name_by_movie_df.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific check\n",
    "web_name_by_movie_df.loc['Elizabeth'][web_name_by_movie_df.loc['Elizabeth']['year'] == 1940]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering of `baby_name_df`\n",
    "The baby_name_df is too large to be loaded on the website. We will drop the column `number` and remove the names with too little years where there is data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(baby_name_df.head(2))\n",
    "web_baby_name_df = baby_name_df[['percentage']].copy(deep=True)\n",
    "display(web_baby_name_df.head(2))\n",
    "web_baby_name_count = web_baby_name_df.groupby(['name']).count()\n",
    "web_baby_name_count.rename(columns={\"percentage\": \"count\"}, inplace=True)\n",
    "display(web_baby_name_count.head(2))\n",
    "plt.hist(web_baby_name_count['count'], bins=100)\n",
    "plt.show()\n",
    "\n",
    "# merging\n",
    "web_baby_name_df.reset_index(inplace=True)\n",
    "web_baby_name_count.reset_index(inplace=True)\n",
    "display(web_baby_name_df.head(2))\n",
    "display(web_baby_name_count.head(2))\n",
    "web_name_by_movie_df_merged = web_baby_name_df.merge(web_baby_name_count, on='name', how='left').copy(deep=True)\n",
    "display(web_name_by_movie_df_merged.head(2))\n",
    "\n",
    "# filtering\n",
    "print(f\"size of the dataframe before filtering : {len(baby_name_df)}\")\n",
    "print(f\"size of the dataframe before filtering : {len(web_name_by_movie_df_merged)}\")\n",
    "web_baby_name_df = web_name_by_movie_df_merged[web_name_by_movie_df_merged['count'] >= 60].copy(deep=True)\n",
    "web_baby_name_df.drop(columns=['count'], inplace=True)\n",
    "web_baby_name_df.set_index(['name', 'year'], inplace=True)\n",
    "display(web_baby_name_df.head(2))\n",
    "print(f\"size of the dataframe after filtering : {len(web_baby_name_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's filter the dataframe web_baby_name_df to anticipate the ploting\n",
    "web_baby_name_df.sort_values(by=['year'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the TOP5/5NULLFAMOUS/BOTTOM5\n",
    "We need also a dataframe containing for each name in the `baby_name` dataset, 10 years where a variation of the baby names are significant (5 with the largest positive variation and 5 with the largest negative variation) as well as 5 popular movies where the variation is not significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(name_by_movie_slope_diff_df.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the gender because we won't consider it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop gender column\n",
    "len_before = len(name_by_movie_slope_diff_df)\n",
    "name_by_movie_slope_diff_without_gender_df = name_by_movie_slope_diff_df.copy(deep=True)\n",
    "name_by_movie_slope_diff_without_gender_df.reset_index(inplace=True)\n",
    "name_by_movie_slope_diff_without_gender_df.drop_duplicates(subset=['wiki_ID', 'char_words'], keep='first', inplace=True)\n",
    "name_by_movie_slope_diff_without_gender_df.drop(columns=['gender'], inplace=True)\n",
    "len_after = len(name_by_movie_slope_diff_without_gender_df)\n",
    "print(f\"length before : {len_before}\")\n",
    "print(f\"length after : {len_after}\")\n",
    "display(name_by_movie_slope_diff_without_gender_df.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless columns\n",
    "name_by_movie_with_slope_only = name_by_movie_slope_diff_without_gender_df.drop(columns=['order', 'p_value', 't_stat']).copy(deep=True)\n",
    "display(name_by_movie_with_slope_only.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's tackle the computing of the 5 TOP and 5 BOTTOM years with the most variation per names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_and_year_df = movie_df[['wiki_ID', 'year']].copy(deep=True)\n",
    "display(movie_id_and_year_df.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the release year into the name_by_movie_with_slope_only dataframe\n",
    "name_by_movie_with_slope_and_year = name_by_movie_with_slope_only.merge(movie_id_and_year_df, on='wiki_ID', how='left').copy(deep=True)\n",
    "display(name_by_movie_with_slope_and_year.sample(2))\n",
    "\n",
    "# check for a specific name and year\n",
    "name_by_movie_with_slope_and_year.set_index(['char_words', 'year'], inplace=True)\n",
    "display(name_by_movie_with_slope_and_year.loc['Elizabeth', 2004]) # ok, everything is fine\n",
    "name_by_movie_with_slope_and_year.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(name_by_movie_with_slope_and_year.head(2))\n",
    "name_by_year_with_slop_change = name_by_movie_with_slope_and_year.drop_duplicates(subset=['char_words', 'year'], keep='first').copy(deep=True)\n",
    "name_by_year_with_slop_change.drop(columns=['wiki_ID'], inplace=True)\n",
    "name_by_year_with_slop_change.dropna(subset='slope_change', inplace=True)\n",
    "display(name_by_year_with_slop_change.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top and bottom 5 years for each name\n",
    "top_5_years = name_by_year_with_slop_change.groupby('char_words').apply(lambda x: x.nlargest(5, 'slope_change')).reset_index(drop=True).copy(deep=True)\n",
    "bottom_5_years = name_by_year_with_slop_change.groupby('char_words').apply(lambda x: x.nsmallest(5, 'slope_change')).reset_index(drop=True).copy(deep=True)\n",
    "\n",
    "# Add a column indicating whether it is a top or bottom year\n",
    "top_5_years['top_or_bottom'] = 'top'\n",
    "bottom_5_years['top_or_bottom'] = 'bottom'\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "web_top_bottom_df = pd.concat([top_5_years, bottom_5_years], ignore_index=True).copy(deep=True)\n",
    "\n",
    "# Drop the column used for sorting and set the index columns\n",
    "web_top_bottom_df.set_index(['char_words', 'top_or_bottom'], inplace=True)\n",
    "\n",
    "display(web_top_bottom_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an issue when the are less than 5 years with a positive slope and when there are less than 5 years with a negative slope. The next cell solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(web_top_bottom_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(web_top_bottom_df.loc['Maxime',:]) ## There should be only positive value in for the top years and only negative values for the bottom years\n",
    "\n",
    "# To solve this problem :\n",
    "web_top_bottom_df_no_index = web_top_bottom_df.reset_index().copy(deep=True)\n",
    "web_top_bottom_filtered_df = web_top_bottom_df_no_index[~((web_top_bottom_df_no_index['slope_change'] < 0) & (web_top_bottom_df_no_index['top_or_bottom'] == 'top')) & ~((web_top_bottom_df_no_index['slope_change'] > 0) & (web_top_bottom_df_no_index['top_or_bottom'] == 'bottom'))].copy(deep=True)\n",
    "web_top_bottom_filtered_df.set_index(['char_words', 'top_or_bottom'], inplace=True)\n",
    "\n",
    "display(web_top_bottom_filtered_df.loc['Maxime',:]) ## There should be only positive value in for the top years and only negative values for the bottom years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_top_bottom_df = web_top_bottom_filtered_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check TOP 5 and BOTTOM 5 computation with a specific name\n",
    "name_by_year_with_slop_change.reset_index(inplace=True)\n",
    "name_by_year_with_slop_change.set_index(['char_words', 'year'], inplace=True)\n",
    "display(name_by_year_with_slop_change)\n",
    "display(name_by_year_with_slop_change.loc['Elizabeth', :])\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "# Create a scatter plot using Plotly Express\n",
    "fig = px.scatter(name_by_year_with_slop_change.loc['Elizabeth', :].reset_index(), x='year', y='slope_change', title='Interactive Scatter Plot', labels={'X': 'X-axis', 'Y': 'Y-axis'})\n",
    "\n",
    "# Add cursor tooltip\n",
    "fig.update_layout(hovermode='closest')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "display(web_top_bottom_df.loc['Elizabeth', :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check passed, we can drop the column slope_change\n",
    "web_top_bottom_df.drop(columns=['slope_change'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each name in the `web_name_by_movie` dataframe, we gather all the movies that have this name for one of its character and that are not significant. Then we take the first 5 of this list and add it into a new dataframe called `5_famous_movies_but_unsignificant_by_name`\n",
    "\n",
    "We reuse the dataframe `name_by_movie_slope_diff_without_gender_df` computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(name_by_movie_slope_diff_without_gender_df.head())\n",
    "print(f\"Length before : {len(name_by_movie_slope_diff_without_gender_df)}\")\n",
    "\n",
    "# first we can remove all the rows where the p_value is a NaN\n",
    "name_by_movie_slope_diff_without_gender_filtered = name_by_movie_slope_diff_without_gender_df.copy(deep=True)\n",
    "name_by_movie_slope_diff_without_gender_filtered.dropna(subset=['p_value'], inplace=True)\n",
    "# we can remove the columsn we don't need\n",
    "name_by_movie_slope_diff_without_gender_filtered.drop(columns=['order', 'slope_change', 't_stat'], inplace=True)\n",
    "display(name_by_movie_slope_diff_without_gender_filtered.head())\n",
    "print(f\"Length after : {len(name_by_movie_slope_diff_without_gender_filtered)}\")\n",
    "\n",
    "print(f\"Length before : {len(name_by_movie_slope_diff_without_gender_df)}\")\n",
    "# keep only non-significent rows\n",
    "name_by_movie_non_significent = name_by_movie_slope_diff_without_gender_filtered[name_by_movie_slope_diff_without_gender_filtered['p_value'] >= 0.1].copy(deep=True)\n",
    "name_by_movie_non_significent.drop(columns=['p_value'], inplace=True)\n",
    "display(name_by_movie_non_significent.head())\n",
    "print(f\"Length after : {len(name_by_movie_non_significent)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the attribute 'numVotes' from the movie_df dataframe with a merge\n",
    "temp_merge_df = movie_df[['wiki_ID', 'numVotes']].copy(deep=True)\n",
    "display(temp_merge_df.head())\n",
    "name_by_movie_non_significent_with_numvotes = name_by_movie_non_significent.merge(temp_merge_df, on='wiki_ID', how='left').copy(deep=True)\n",
    "display(name_by_movie_non_significent_with_numvotes.head())\n",
    "print(f\"length of name_by_movie_non_significent_with_numvotes : {len(name_by_movie_non_significent_with_numvotes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the DataFrame by 'name' and 'scores' in descending order\n",
    "# df_sorted = name_by_movie_non_significent_with_numvotes.sort_values(by=['char_words', 'numVotes'], ascending=[True, False])\n",
    "name_by_movie_non_significent_with_numvotes_sorted = name_by_movie_non_significent_with_numvotes.sort_values(by='numVotes', ascending=False).copy(deep=True)\n",
    "display(name_by_movie_non_significent_with_numvotes_sorted.head())\n",
    "\n",
    "# Extracting the top 5 rows for each 'name'\n",
    "web_top_famous_but_insi = name_by_movie_non_significent_with_numvotes_sorted.groupby('char_words').head(5).copy(deep=True)\n",
    "web_top_famous_but_insi.set_index(['char_words'], inplace=True)\n",
    "web_top_famous_but_insi.drop(columns=['numVotes'], inplace=True)\n",
    "display(web_top_famous_but_insi.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_website_data_folder = './processed_data/website/'\n",
    "\n",
    "display(web_name_by_movie_df.reset_index().head())\n",
    "# Export DataFrame to a CSV file in the processed data folder\n",
    "web_name_by_movie_df.reset_index().to_csv(os.path.join(processed_website_data_folder, 'web_name_by_movie_df.csv'), index=False)\n",
    "\n",
    "display(web_baby_name_df.reset_index().head())\n",
    "# Export DataFrame to a CSV file in the processed data folder\n",
    "web_baby_name_df.reset_index().to_csv(os.path.join(processed_website_data_folder, 'web_baby_name_df.csv'), index=False)\n",
    "\n",
    "display(web_top_bottom_df.reset_index().head())\n",
    "# Export DataFrame to a CSV file in the processed data folder\n",
    "web_top_bottom_df.reset_index().to_csv(os.path.join(processed_website_data_folder, 'web_top_bottom_df.csv'), index=False)\n",
    "\n",
    "display(web_top_famous_but_insi.reset_index().head())\n",
    "# Export DataFrame to a CSV file in the processed data folder\n",
    "web_top_famous_but_insi.reset_index().to_csv(os.path.join(processed_website_data_folder, 'web_top_famous_but_insi.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be set by the user\n",
    "chosen_name = 'Elizabeth'\n",
    "\n",
    "web_baby_name_df.reset_index(inplace=True)\n",
    "web_baby_name_df.set_index(['name'], inplace=True)\n",
    "\n",
    "x_values = web_baby_name_df.loc[chosen_name]['year'].values\n",
    "y_values = web_baby_name_df.loc[chosen_name]['percentage'].values\n",
    "\n",
    "# Ploting\n",
    "plt.plot(x_values, y_values)\n",
    "plt.xlabel('Years')\n",
    "plt.ylabel('Percentage of total births')\n",
    "plt.title(f'Name \"{chosen_name}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 5 years from the web data\n",
    "top_5_years = web_top_bottom_df.loc[chosen_name, 'top'].values[:,0]\n",
    "print(f\"top_5_years = {top_5_years}\")\n",
    "data_top_5_years = web_name_by_movie_df[(web_name_by_movie_df['char_words'] == chosen_name) & (web_name_by_movie_df['year'].isin(top_5_years))].copy(deep=True)\n",
    "display(data_top_5_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the bottom 5 years from the web data\n",
    "bottom_5_years = web_top_bottom_df.loc[chosen_name, 'bottom'].values[:,0]\n",
    "print(f\"bottom_5_years = {bottom_5_years}\")\n",
    "data_bottom_5_years = web_name_by_movie_df[(web_name_by_movie_df['char_words'] == chosen_name) & (web_name_by_movie_df['year'].isin(bottom_5_years))].copy(deep=True)\n",
    "display(data_bottom_5_years)\n",
    "\n",
    "# # only three movies for the chosen name 'Thomas' ? instead of 3x5=15 ? check the top 5 years seperately\n",
    "# display(web_name_by_movie_df[(web_name_by_movie_df['char_words'] == chosen_name) & (web_name_by_movie_df['year'] == bottom_5_years[0])])\n",
    "# display(web_name_by_movie_df[(web_name_by_movie_df['char_words'] == chosen_name) & (web_name_by_movie_df['year'] == bottom_5_years[1])])\n",
    "# display(web_name_by_movie_df[(web_name_by_movie_df['char_words'] == chosen_name) & (web_name_by_movie_df['year'] == bottom_5_years[2])])\n",
    "# display(web_name_by_movie_df[(web_name_by_movie_df['char_words'] == chosen_name) & (web_name_by_movie_df['year'] == bottom_5_years[3])])\n",
    "# display(web_name_by_movie_df[(web_name_by_movie_df['char_words'] == chosen_name) & (web_name_by_movie_df['year'] == bottom_5_years[4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 5 famous but insignificant movies from the web data\n",
    "id_5_famous_movies_but_insignificant = web_top_famous_but_insi.loc[chosen_name].values[:,0]\n",
    "print(f\"id_5_famous_movies_but_insignificant = {id_5_famous_movies_but_insignificant}\")\n",
    "\n",
    "web_name_by_movie_df.reset_index(inplace=True)\n",
    "data_5_famous_movies_but_insignificant = web_name_by_movie_df[(web_name_by_movie_df['char_words'] == chosen_name) & (web_name_by_movie_df['wiki_ID'].isin(id_5_famous_movies_but_insignificant))]\n",
    "display(data_5_famous_movies_but_insignificant)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
