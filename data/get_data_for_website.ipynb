{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for interactive part of the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_processed_data_path = './processed_data/'\n",
    "processed_website_data_folder = './processed_data/website/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>order</th>\n",
       "      <th>t_stat</th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>char_words</th>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8619888</th>\n",
       "      <th>Barton</th>\n",
       "      <th>M</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.277361</td>\n",
       "      <td>0.786646</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31567587</th>\n",
       "      <th>Dominic</th>\n",
       "      <th>M</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.116171</td>\n",
       "      <td>0.057954</td>\n",
       "      <td>-0.011738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            order    t_stat   p_value  slope_change\n",
       "wiki_ID  char_words gender                                         \n",
       "8619888  Barton     M         NaN -0.277361  0.786646      0.000018\n",
       "31567587 Dominic    M         0.0  2.116171  0.057954     -0.011738"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mov_name</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>revenue</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>poster_url</th>\n",
       "      <th>IMDB_ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33002544</th>\n",
       "      <td>Shehzaade</td>\n",
       "      <td>1989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0359965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12289584</th>\n",
       "      <td>Skeleton Man</td>\n",
       "      <td>2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2075</td>\n",
       "      <td>2.1</td>\n",
       "      <td>/73dDpqzg7hUlnSFJJe95ISnxA1R.jpg</td>\n",
       "      <td>tt0372832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mov_name  year  month  revenue  numVotes  averageRating  \\\n",
       "wiki_ID                                                                 \n",
       "33002544     Shehzaade  1989    NaN      NaN        52            4.5   \n",
       "12289584  Skeleton Man  2004    NaN      NaN      2075            2.1   \n",
       "\n",
       "                                poster_url    IMDB_ID  \n",
       "wiki_ID                                                \n",
       "33002544                               NaN  tt0359965  \n",
       "12289584  /73dDpqzg7hUlnSFJJe95ISnxA1R.jpg  tt0372832  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import the name by movie\n",
    "name_by_movie_df = pd.read_csv(os.path.join(folder_processed_data_path, 'name_by_movie_ordered_pvalue_10_5_df.csv'))\n",
    "name_by_movie_df.set_index(['wiki_ID', 'char_words', 'gender'], inplace=True)\n",
    "display(name_by_movie_df.sample(2))\n",
    "\n",
    "# import the movie dataframe\n",
    "movie_df = pd.read_csv(os.path.join(folder_processed_data_path, 'movie_df.csv'))\n",
    "movie_df.set_index(['wiki_ID'], inplace=True)\n",
    "display(movie_df.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute `movie_impact` dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering of `name_by_movie`  : importance of the role\n",
    "\n",
    "Now, lets remove the character names with an minor role in the movie. We will keep only the characters with a order higher or equal to the median of the set of order in the movie. First, let's compute the number of order for each movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_order</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki_ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         nb_order\n",
       "wiki_ID          \n",
       "3217           11\n",
       "3746           15\n",
       "3837           18\n",
       "3947           16\n",
       "4227            2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name_by_movie_merged_groupby = name_by_movie_df.groupby(['wiki_ID'])\n",
    "name_by_movie_merged_nunique = name_by_movie_merged_groupby['order'].count()\n",
    "\n",
    "name_by_movie_merged_nunique = name_by_movie_merged_nunique.to_frame()\n",
    "name_by_movie_merged_nunique.rename(columns={\"order\": \"nb_order\"}, inplace=True)\n",
    "display(name_by_movie_merged_nunique.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of name_by_movie_df : 172906\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of name_by_movie_df : {len(name_by_movie_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of name_by_movie_df (before): 172906\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>char_words</th>\n",
       "      <th>gender</th>\n",
       "      <th>order</th>\n",
       "      <th>t_stat</th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "      <th>nb_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165091</th>\n",
       "      <td>32171599</td>\n",
       "      <td>Ravi</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231803</td>\n",
       "      <td>0.820947</td>\n",
       "      <td>-0.00006</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94777</th>\n",
       "      <td>11223100</td>\n",
       "      <td>Heart</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         wiki_ID char_words gender  order    t_stat   p_value  slope_change  \\\n",
       "165091  32171599       Ravi      M    0.0  0.231803  0.820947      -0.00006   \n",
       "94777   11223100      Heart      M    0.0       NaN       NaN           NaN   \n",
       "\n",
       "        nb_order  \n",
       "165091         2  \n",
       "94777          2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of name_by_movie_merged_with_nunique (after): 172906\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of name_by_movie_df (before): {len(name_by_movie_df)}\")\n",
    "name_by_movie_merged_with_nunique = name_by_movie_df.reset_index().merge(name_by_movie_merged_nunique, on='wiki_ID', how='left')\n",
    "display(name_by_movie_merged_with_nunique.sample(2))\n",
    "print(f\"length of name_by_movie_merged_with_nunique (after): {len(name_by_movie_merged_with_nunique)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>char_words</th>\n",
       "      <th>gender</th>\n",
       "      <th>order</th>\n",
       "      <th>t_stat</th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "      <th>nb_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145035</th>\n",
       "      <td>25367068</td>\n",
       "      <td>Laura</td>\n",
       "      <td>F</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.22691</td>\n",
       "      <td>0.008059</td>\n",
       "      <td>0.015288</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140661</th>\n",
       "      <td>24190433</td>\n",
       "      <td>Hogan</td>\n",
       "      <td>M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         wiki_ID char_words gender  order   t_stat   p_value  slope_change  \\\n",
       "145035  25367068      Laura      F    3.0 -3.22691  0.008059      0.015288   \n",
       "140661  24190433      Hogan      M    2.0      NaN       NaN           NaN   \n",
       "\n",
       "        nb_order  \n",
       "145035         4  \n",
       "140661        14  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of name_by_movie_merged_with_nunique : 172906\n"
     ]
    }
   ],
   "source": [
    "display(name_by_movie_merged_with_nunique.sample(2))\n",
    "print(f\"length of name_by_movie_merged_with_nunique : {len(name_by_movie_merged_with_nunique)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>char_words</th>\n",
       "      <th>gender</th>\n",
       "      <th>order</th>\n",
       "      <th>t_stat</th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "      <th>nb_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>52371</td>\n",
       "      <td>Caledon</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>52371</td>\n",
       "      <td>Dewitt</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>52371</td>\n",
       "      <td>Rose</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.552929</td>\n",
       "      <td>0.148720</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>52371</td>\n",
       "      <td>De</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>52371</td>\n",
       "      <td>Jack</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.987322</td>\n",
       "      <td>0.072358</td>\n",
       "      <td>0.012744</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>52371</td>\n",
       "      <td>Charles</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.093865</td>\n",
       "      <td>0.010215</td>\n",
       "      <td>0.008629</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>52371</td>\n",
       "      <td>Bruce</td>\n",
       "      <td>M</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-2.545008</td>\n",
       "      <td>0.027236</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>52371</td>\n",
       "      <td>Calvert</td>\n",
       "      <td>F</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.216687</td>\n",
       "      <td>0.832419</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>52371</td>\n",
       "      <td>Ismay</td>\n",
       "      <td>M</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>52371</td>\n",
       "      <td>Brown</td>\n",
       "      <td>F</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>52371</td>\n",
       "      <td>Bobby</td>\n",
       "      <td>M</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1.158331</td>\n",
       "      <td>0.271259</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>52371</td>\n",
       "      <td>Archibald</td>\n",
       "      <td>M</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>52371</td>\n",
       "      <td>Lowe</td>\n",
       "      <td>M</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>52371</td>\n",
       "      <td>John</td>\n",
       "      <td>M</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-0.499025</td>\n",
       "      <td>0.627591</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>52371</td>\n",
       "      <td>Fabrizio</td>\n",
       "      <td>M</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>52371</td>\n",
       "      <td>Murdoch</td>\n",
       "      <td>M</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>52371</td>\n",
       "      <td>Lizzy</td>\n",
       "      <td>F</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>52371</td>\n",
       "      <td>Harold</td>\n",
       "      <td>M</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-1.071750</td>\n",
       "      <td>0.306783</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>52371</td>\n",
       "      <td>Andrews</td>\n",
       "      <td>M</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.561223</td>\n",
       "      <td>0.585897</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>52371</td>\n",
       "      <td>Smith</td>\n",
       "      <td>M</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.612611</td>\n",
       "      <td>0.552587</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>52371</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>M</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.782808</td>\n",
       "      <td>0.450264</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>52371</td>\n",
       "      <td>Ruth</td>\n",
       "      <td>F</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.262820</td>\n",
       "      <td>0.232767</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>52371</td>\n",
       "      <td>Dawson</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.330585</td>\n",
       "      <td>0.210250</td>\n",
       "      <td>0.012189</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>52371</td>\n",
       "      <td>William</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.268811</td>\n",
       "      <td>0.230700</td>\n",
       "      <td>0.008822</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>52371</td>\n",
       "      <td>Captain</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>52371</td>\n",
       "      <td>Astor</td>\n",
       "      <td>M</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>52371</td>\n",
       "      <td>Rossi</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>52371</td>\n",
       "      <td>Gracie</td>\n",
       "      <td>M</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-6.622880</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.011361</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>52371</td>\n",
       "      <td>Lovett</td>\n",
       "      <td>M</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>52371</td>\n",
       "      <td>Molly</td>\n",
       "      <td>F</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.375483</td>\n",
       "      <td>0.714441</td>\n",
       "      <td>-0.002190</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>52371</td>\n",
       "      <td>Lewis</td>\n",
       "      <td>M</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.271231</td>\n",
       "      <td>0.791236</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>52371</td>\n",
       "      <td>Buell</td>\n",
       "      <td>M</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>52371</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.886102</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>-0.072817</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>52371</td>\n",
       "      <td>Tommy</td>\n",
       "      <td>M</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.248063</td>\n",
       "      <td>0.237921</td>\n",
       "      <td>-0.000858</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>52371</td>\n",
       "      <td>Brock</td>\n",
       "      <td>M</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.215546</td>\n",
       "      <td>0.833286</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>52371</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>M</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.239643</td>\n",
       "      <td>0.815014</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      wiki_ID char_words gender  order    t_stat   p_value  slope_change  \\\n",
       "1891    52371    Caledon      M    NaN       NaN       NaN           NaN   \n",
       "1892    52371     Dewitt      F    NaN       NaN       NaN           NaN   \n",
       "1893    52371       Rose      F    1.0 -1.552929  0.148720      0.002796   \n",
       "1894    52371         De      M    NaN       NaN       NaN           NaN   \n",
       "1895    52371       Jack      M    0.0 -1.987322  0.072358      0.012744   \n",
       "1896    52371    Charles      M    NaN -3.093865  0.010215      0.008629   \n",
       "1897    52371      Bruce      M   10.0 -2.545008  0.027236      0.001570   \n",
       "1898    52371    Calvert      F   12.0  0.216687  0.832419     -0.000017   \n",
       "1899    52371      Ismay      M   10.0       NaN       NaN           NaN   \n",
       "1900    52371      Brown      F    3.0       NaN       NaN           NaN   \n",
       "1901    52371      Bobby      M   13.0 -1.158331  0.271259      0.001117   \n",
       "1902    52371  Archibald      M   19.0       NaN       NaN           NaN   \n",
       "1903    52371       Lowe      M   20.0       NaN       NaN           NaN   \n",
       "1904    52371       John      M   17.0 -0.499025  0.627591      0.002662   \n",
       "1905    52371   Fabrizio      M   14.0       NaN       NaN           NaN   \n",
       "1906    52371    Murdoch      M   18.0       NaN       NaN           NaN   \n",
       "1907    52371      Lizzy      F   12.0       NaN       NaN           NaN   \n",
       "1908    52371     Harold      M   34.0 -1.071750  0.306783      0.000497   \n",
       "1909    52371    Andrews      M    6.0 -0.561223  0.585897      0.000045   \n",
       "1910    52371      Smith      M    8.0 -0.612611  0.552587      0.000066   \n",
       "1911    52371     Thomas      M    6.0 -0.782808  0.450264      0.006375   \n",
       "1912    52371       Ruth      F    4.0 -1.262820  0.232767      0.001224   \n",
       "1913    52371     Dawson      M    0.0 -1.330585  0.210250      0.012189   \n",
       "1914    52371    William      M    NaN -1.268811  0.230700      0.008822   \n",
       "1915    52371    Captain      M    NaN       NaN       NaN           NaN   \n",
       "1916    52371      Astor      M   17.0       NaN       NaN           NaN   \n",
       "1917    52371      Rossi      M    NaN       NaN       NaN           NaN   \n",
       "1918    52371     Gracie      M   19.0 -6.622880  0.000037      0.011361   \n",
       "1919    52371     Lovett      M    7.0       NaN       NaN           NaN   \n",
       "1920    52371      Molly      F    3.0  0.375483  0.714441     -0.002190   \n",
       "1921    52371      Lewis      M   11.0 -0.271231  0.791236      0.000181   \n",
       "1922    52371      Buell      M   13.0       NaN       NaN           NaN   \n",
       "1923    52371      Jacob      M    NaN  3.886102  0.002537     -0.072817   \n",
       "1924    52371      Tommy      M   15.0  1.248063  0.237921     -0.000858   \n",
       "1925    52371      Brock      M    7.0 -0.215546  0.833286      0.000392   \n",
       "1926    52371       Ryan      M   15.0 -0.239643  0.815014      0.003500   \n",
       "\n",
       "      nb_order  \n",
       "1891        28  \n",
       "1892        28  \n",
       "1893        28  \n",
       "1894        28  \n",
       "1895        28  \n",
       "1896        28  \n",
       "1897        28  \n",
       "1898        28  \n",
       "1899        28  \n",
       "1900        28  \n",
       "1901        28  \n",
       "1902        28  \n",
       "1903        28  \n",
       "1904        28  \n",
       "1905        28  \n",
       "1906        28  \n",
       "1907        28  \n",
       "1908        28  \n",
       "1909        28  \n",
       "1910        28  \n",
       "1911        28  \n",
       "1912        28  \n",
       "1913        28  \n",
       "1914        28  \n",
       "1915        28  \n",
       "1916        28  \n",
       "1917        28  \n",
       "1918        28  \n",
       "1919        28  \n",
       "1920        28  \n",
       "1921        28  \n",
       "1922        28  \n",
       "1923        28  \n",
       "1924        28  \n",
       "1925        28  \n",
       "1926        28  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check case with tommy charcater in titanic\n",
    "name_by_movie_merged_with_nunique[name_by_movie_merged_with_nunique['wiki_ID'] == 52371]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the initial dataframe : 172906\n",
      "length of the filtered dataframe : 86642\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>char_words</th>\n",
       "      <th>gender</th>\n",
       "      <th>order</th>\n",
       "      <th>t_stat</th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "      <th>nb_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15117</th>\n",
       "      <td>473268</td>\n",
       "      <td>Ed</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.355571</td>\n",
       "      <td>0.728886</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164136</th>\n",
       "      <td>31893898</td>\n",
       "      <td>Freddie</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.288221</td>\n",
       "      <td>0.778536</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         wiki_ID char_words gender  order    t_stat   p_value  slope_change  \\\n",
       "15117     473268         Ed      M    1.0  0.355571  0.728886     -0.000045   \n",
       "164136  31893898    Freddie      M    1.0 -0.288221  0.778536      0.000099   \n",
       "\n",
       "        nb_order  \n",
       "15117         13  \n",
       "164136        16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filtering\n",
    "name_by_movie_merged_important_role = name_by_movie_merged_with_nunique[name_by_movie_merged_with_nunique['order'] <= (name_by_movie_merged_with_nunique['nb_order']/2)].copy(deep=True)\n",
    "# name_by_movie_merged_important_role.drop(columns=['nb_order'], inplace=True)\n",
    "print(f\"length of the initial dataframe : {len(name_by_movie_df)}\")\n",
    "print(f\"length of the filtered dataframe : {len(name_by_movie_merged_important_role)}\")\n",
    "display(name_by_movie_merged_important_role.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>char_words</th>\n",
       "      <th>gender</th>\n",
       "      <th>order</th>\n",
       "      <th>t_stat</th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "      <th>nb_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>52371</td>\n",
       "      <td>Rose</td>\n",
       "      <td>F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.552929</td>\n",
       "      <td>0.148720</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>52371</td>\n",
       "      <td>Jack</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.987322</td>\n",
       "      <td>0.072358</td>\n",
       "      <td>0.012744</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>52371</td>\n",
       "      <td>Bruce</td>\n",
       "      <td>M</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-2.545008</td>\n",
       "      <td>0.027236</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>52371</td>\n",
       "      <td>Calvert</td>\n",
       "      <td>F</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.216687</td>\n",
       "      <td>0.832419</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>52371</td>\n",
       "      <td>Ismay</td>\n",
       "      <td>M</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>52371</td>\n",
       "      <td>Brown</td>\n",
       "      <td>F</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>52371</td>\n",
       "      <td>Bobby</td>\n",
       "      <td>M</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1.158331</td>\n",
       "      <td>0.271259</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>52371</td>\n",
       "      <td>Fabrizio</td>\n",
       "      <td>M</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>52371</td>\n",
       "      <td>Lizzy</td>\n",
       "      <td>F</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>52371</td>\n",
       "      <td>Andrews</td>\n",
       "      <td>M</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.561223</td>\n",
       "      <td>0.585897</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>52371</td>\n",
       "      <td>Smith</td>\n",
       "      <td>M</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.612611</td>\n",
       "      <td>0.552587</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>52371</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>M</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.782808</td>\n",
       "      <td>0.450264</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>52371</td>\n",
       "      <td>Ruth</td>\n",
       "      <td>F</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.262820</td>\n",
       "      <td>0.232767</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>52371</td>\n",
       "      <td>Dawson</td>\n",
       "      <td>M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.330585</td>\n",
       "      <td>0.210250</td>\n",
       "      <td>0.012189</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>52371</td>\n",
       "      <td>Lovett</td>\n",
       "      <td>M</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>52371</td>\n",
       "      <td>Molly</td>\n",
       "      <td>F</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.375483</td>\n",
       "      <td>0.714441</td>\n",
       "      <td>-0.002190</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>52371</td>\n",
       "      <td>Lewis</td>\n",
       "      <td>M</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.271231</td>\n",
       "      <td>0.791236</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>52371</td>\n",
       "      <td>Buell</td>\n",
       "      <td>M</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>52371</td>\n",
       "      <td>Brock</td>\n",
       "      <td>M</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.215546</td>\n",
       "      <td>0.833286</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      wiki_ID char_words gender  order    t_stat   p_value  slope_change  \\\n",
       "1893    52371       Rose      F    1.0 -1.552929  0.148720      0.002796   \n",
       "1895    52371       Jack      M    0.0 -1.987322  0.072358      0.012744   \n",
       "1897    52371      Bruce      M   10.0 -2.545008  0.027236      0.001570   \n",
       "1898    52371    Calvert      F   12.0  0.216687  0.832419     -0.000017   \n",
       "1899    52371      Ismay      M   10.0       NaN       NaN           NaN   \n",
       "1900    52371      Brown      F    3.0       NaN       NaN           NaN   \n",
       "1901    52371      Bobby      M   13.0 -1.158331  0.271259      0.001117   \n",
       "1905    52371   Fabrizio      M   14.0       NaN       NaN           NaN   \n",
       "1907    52371      Lizzy      F   12.0       NaN       NaN           NaN   \n",
       "1909    52371    Andrews      M    6.0 -0.561223  0.585897      0.000045   \n",
       "1910    52371      Smith      M    8.0 -0.612611  0.552587      0.000066   \n",
       "1911    52371     Thomas      M    6.0 -0.782808  0.450264      0.006375   \n",
       "1912    52371       Ruth      F    4.0 -1.262820  0.232767      0.001224   \n",
       "1913    52371     Dawson      M    0.0 -1.330585  0.210250      0.012189   \n",
       "1919    52371     Lovett      M    7.0       NaN       NaN           NaN   \n",
       "1920    52371      Molly      F    3.0  0.375483  0.714441     -0.002190   \n",
       "1921    52371      Lewis      M   11.0 -0.271231  0.791236      0.000181   \n",
       "1922    52371      Buell      M   13.0       NaN       NaN           NaN   \n",
       "1925    52371      Brock      M    7.0 -0.215546  0.833286      0.000392   \n",
       "\n",
       "      nb_order  \n",
       "1893        28  \n",
       "1895        28  \n",
       "1897        28  \n",
       "1898        28  \n",
       "1899        28  \n",
       "1900        28  \n",
       "1901        28  \n",
       "1905        28  \n",
       "1907        28  \n",
       "1909        28  \n",
       "1910        28  \n",
       "1911        28  \n",
       "1912        28  \n",
       "1913        28  \n",
       "1919        28  \n",
       "1920        28  \n",
       "1921        28  \n",
       "1922        28  \n",
       "1925        28  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check case with tommy charcater in titanic\n",
    "name_by_movie_merged_important_role[name_by_movie_merged_important_role['wiki_ID'] == 52371]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the name_by_movie_df : 86642\n"
     ]
    }
   ],
   "source": [
    "name_by_movie_df = name_by_movie_merged_important_role.copy(deep=True)\n",
    "print(f\"Length of the name_by_movie_df : {len(name_by_movie_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing `name_by_movie`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>char_words</th>\n",
       "      <th>gender</th>\n",
       "      <th>order</th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "      <th>nb_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36128</th>\n",
       "      <td>66704</td>\n",
       "      <td>5079733</td>\n",
       "      <td>Beecher</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54515</th>\n",
       "      <td>104375</td>\n",
       "      <td>14261811</td>\n",
       "      <td>Musette</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index   wiki_ID char_words gender  order  p_value  slope_change  \\\n",
       "36128   66704   5079733    Beecher      F    0.0      NaN           NaN   \n",
       "54515  104375  14261811    Musette      F    2.0      NaN           NaN   \n",
       "\n",
       "       nb_order  \n",
       "36128         7  \n",
       "54515        10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove useless columns\n",
    "name_by_movie_web = name_by_movie_df.reset_index().copy(deep=True)\n",
    "name_by_movie_web.drop(columns=['t_stat'], inplace=True)\n",
    "display(name_by_movie_web.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length : 86642 -> 83633\n",
      "Is the indexing of name_by_movie_web unique? True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>order</th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "      <th>nb_order</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_words</th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Carlos</th>\n",
       "      <th>24207129</th>\n",
       "      <td>140930</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.185631</td>\n",
       "      <td>-0.007314</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oren</th>\n",
       "      <th>2444093</th>\n",
       "      <td>45222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.149138</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      index  order   p_value  slope_change  nb_order\n",
       "char_words wiki_ID                                                  \n",
       "Carlos     24207129  140930    4.0  0.185631     -0.007314        10\n",
       "Oren       2444093    45222    2.0  0.149138      0.000211         7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# drop gender column\n",
    "len_before = len(name_by_movie_web)\n",
    "\n",
    "name_by_movie_web.reset_index(inplace=True, drop=True)\n",
    "name_by_movie_web.drop_duplicates(subset=['wiki_ID', 'char_words'], keep='first', inplace=True)\n",
    "name_by_movie_web.drop(columns=['gender'], inplace=True)\n",
    "name_by_movie_web.set_index(['char_words', 'wiki_ID'], inplace=True)\n",
    "\n",
    "len_after = len(name_by_movie_web)\n",
    "print(f\"length : {len_before} -> {len_after}\")\n",
    "print(f\"Is the indexing of name_by_movie_web unique? {name_by_movie_web.index.is_unique}\")\n",
    "display(name_by_movie_web.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length : 83633 -> 61957\n"
     ]
    }
   ],
   "source": [
    "# drop NaN values\n",
    "len_before = len(name_by_movie_web)\n",
    "name_by_movie_web.dropna(subset=['p_value'], inplace=True)\n",
    "len_after = len(name_by_movie_web)\n",
    "print(f\"length : {len_before} -> {len_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length : 61957 -> 61957\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>order</th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "      <th>nb_order</th>\n",
       "      <th>year</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_words</th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Charlie</th>\n",
       "      <th>3733842</th>\n",
       "      <td>58019</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.530251</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>13</td>\n",
       "      <td>1966</td>\n",
       "      <td>7.6</td>\n",
       "      <td>21555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Willie</th>\n",
       "      <th>21575683</th>\n",
       "      <td>128330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.670954</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "      <td>5.3</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      index  order   p_value  slope_change  nb_order  year  \\\n",
       "char_words wiki_ID                                                           \n",
       "Charlie    3733842    58019    6.0  0.530251      0.000538        13  1966   \n",
       "Willie     21575683  128330    1.0  0.670954      0.000502         4  1990   \n",
       "\n",
       "                     averageRating  numVotes  \n",
       "char_words wiki_ID                            \n",
       "Charlie    3733842             7.6     21555  \n",
       "Willie     21575683            5.3       253  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add the year of release of the movie to the name_by_movie_web dataframe\n",
    "\n",
    "needed_movie_info = movie_df.reset_index()[['wiki_ID', 'year', 'averageRating', 'numVotes']].copy(deep=True)\n",
    "\n",
    "len_before_merge = len(name_by_movie_web)\n",
    "name_by_movie_with_info = name_by_movie_web.reset_index().merge(needed_movie_info, on='wiki_ID', how='left').copy(deep=True) # merge the release year into the name_by_movie_web dataframe\n",
    "len_after_merge = len(name_by_movie_with_info)\n",
    "print(f\"length : {len_before_merge} -> {len_after_merge}\")\n",
    "\n",
    "name_by_movie_with_info.set_index(['char_words', 'wiki_ID'], inplace=True)\n",
    "display(name_by_movie_with_info.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of name_by_movie_with_info : 61957\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>order</th>\n",
       "      <th>p_value</th>\n",
       "      <th>slope_change</th>\n",
       "      <th>nb_order</th>\n",
       "      <th>year</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char_words</th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>andrea</th>\n",
       "      <th>28149365</th>\n",
       "      <td>154101</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.967168</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>15</td>\n",
       "      <td>1969</td>\n",
       "      <td>5.1</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>julie</th>\n",
       "      <th>1011468</th>\n",
       "      <td>25841</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.162156</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>36</td>\n",
       "      <td>2002</td>\n",
       "      <td>7.2</td>\n",
       "      <td>148700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      index  order   p_value  slope_change  nb_order  year  \\\n",
       "char_words wiki_ID                                                           \n",
       "andrea     28149365  154101    7.0  0.967168     -0.000357        15  1969   \n",
       "julie      1011468    25841    2.0  0.162156      0.002235        36  2002   \n",
       "\n",
       "                     averageRating  numVotes  \n",
       "char_words wiki_ID                            \n",
       "andrea     28149365            5.1       292  \n",
       "julie      1011468             7.2    148700  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set the char_names in lowercase\n",
    "name_by_movie_with_info.reset_index(inplace=True)\n",
    "name_by_movie_with_info['char_words'] = name_by_movie_with_info['char_words'].str.lower()\n",
    "name_by_movie_with_info.set_index(['char_words', 'wiki_ID'], inplace=True)\n",
    "print(f\"Length of name_by_movie_with_info : {len(name_by_movie_with_info)}\")\n",
    "display(name_by_movie_with_info.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th>group_year</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, status, group_year, movie_id]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the movie_impact dataframe\n",
    "columns = ['name', 'status', 'group_year', 'movie_id']\n",
    "movie_impact_df = pd.DataFrame(columns=columns)\n",
    "display(movie_impact_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to compute TOP/BOTTOM/INSIGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_movies(name, chosen_name_movies_top_df, chosen_name_movies_df, movie_impact_df):\n",
    "    for i in range(5): # from top1 to top5\n",
    "        if(not chosen_name_movies_top_df.empty):\n",
    "            # get the year with the highest positive variation\n",
    "            top_i_year = chosen_name_movies_top_df.iloc[-1].year.astype(int)\n",
    "\n",
    "            # get the movies released close to the year with the highest positive variation [top_i_year-3, top_i_year+3]\n",
    "            top_i_year_chosen_name_movies = chosen_name_movies_df.query(f'year >= {top_i_year - 3} and year <= {top_i_year + 3}').copy(deep=True)\n",
    "\n",
    "            # keep only the three most popular movies\n",
    "            top_i_year_chosen_name_movies.sort_values(by=['numVotes'], ascending=False, inplace=True)\n",
    "            top_i_3_chosen_name_movies = top_i_year_chosen_name_movies.iloc[:3].copy(deep=True)\n",
    "\n",
    "            # add the the three popular movies to the movie_impact_df\n",
    "            for index, row in top_i_3_chosen_name_movies.iterrows():\n",
    "                movie_impact_df.loc[len(movie_impact_df)] = {'name': name, 'status': 't', 'group_year': top_i_year, 'movie_id': index}\n",
    "\n",
    "            # # remove the found movies from the chosen_name_movies_top_df to avoid picking them again for next iterations\n",
    "            # chosen_name_movies_top_df.drop(top_i_year_chosen_name_movies.index, inplace=True, errors='ignore')\n",
    "\n",
    "            # remove also the movies release in the frame [-5 years, +5 years] of the top1_year\n",
    "            chosen_name_movies_top_df.query(f'year < {top_i_year - 5} or year > {top_i_year + 5}', inplace=True)\n",
    "\n",
    "            # remove the found movies from the chosen_name_movies_df to avoid picking them again for next iterations\n",
    "            chosen_name_movies_df.drop(top_i_3_chosen_name_movies.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bottom_movies(name, chosen_name_movies_bottom_df, chosen_name_movies_df, movie_impact_df):\n",
    "    for i in range(5): # from bottom1 to bottom5\n",
    "        if(not chosen_name_movies_bottom_df.empty):\n",
    "            # get the year with the hgighest negative variation\n",
    "            bottom_i_year = chosen_name_movies_bottom_df.iloc[-1].year.astype(int)\n",
    "\n",
    "            # get the movies released close to the year with the highest negative variation [bottom_i_year-3, bottom_i_year+3]\n",
    "            bottom_i_year_chosen_name_movies = chosen_name_movies_df.query(f'year >= {bottom_i_year - 3} and year <= {bottom_i_year + 3}').copy(deep=True)\n",
    "\n",
    "            # keep only the three most popular movies\n",
    "            bottom_i_year_chosen_name_movies.sort_values(by=['numVotes'], ascending=False, inplace=True)\n",
    "            bottom_i_3_chosen_name_movies = bottom_i_year_chosen_name_movies.iloc[:3].copy(deep=True)\n",
    "\n",
    "            # add the the three popular movies to the movie_impact_df\n",
    "            for index, row in bottom_i_3_chosen_name_movies.iterrows():\n",
    "                movie_impact_df.loc[len(movie_impact_df)] = {'name': name, 'status': 'b', 'group_year': bottom_i_year, 'movie_id': index}\n",
    "\n",
    "            # # remove the found movies from the chosen_name_movies_bottom_df to avoid picking them again for next iterations\n",
    "            # chosen_name_movies_bottom_df.drop(bottom_i_year_chosen_name_movies.index, inplace=True, errors='ignore')\n",
    "\n",
    "            # remove also the movies release in the frame [-5 years, +5 years] of the bottom_i_year\n",
    "            chosen_name_movies_bottom_df.query(f'year < {bottom_i_year - 5} or year > {bottom_i_year + 5}', inplace=True)\n",
    "\n",
    "            # remove the found movies from the chosen_name_movies_df to avoid picking them again for next iterations\n",
    "            chosen_name_movies_df.drop(bottom_i_3_chosen_name_movies.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_insign_movies(name, chosen_name_movies_insign_df, movie_impact_df):\n",
    "    for i in range(5): # from insign1 to insign5\n",
    "        if(not chosen_name_movies_insign_df.empty):\n",
    "            # get the movies release the year with the highest rating and number of votes\n",
    "            insign_i_year = chosen_name_movies_insign_df.iloc[-1].year.astype(int)\n",
    "            insign_i_year_chosen_name_movies = chosen_name_movies_insign_df.query(f'year == {insign_i_year}').copy(deep=True)\n",
    "\n",
    "            # # keep only the three most popular movies\n",
    "            # insign_i_3_chosen_name_movies = insign_i_year_chosen_name_movies.iloc[:3].copy(deep=True)\n",
    "\n",
    "            # add the most popular movie to the movie_impact_df\n",
    "            # for index, row in [insign_i_year_chosen_name_movies.iloc[0]]:\n",
    "            movie_impact_df.loc[len(movie_impact_df)] = {'name': name, 'status': 'i', 'group_year': insign_i_year, 'movie_id': insign_i_year_chosen_name_movies.index[0]}\n",
    "\n",
    "            # remove the found movies from the chosen_name_movies_top_df to avoid picking them again for next iterations\n",
    "            chosen_name_movies_insign_df.drop(insign_i_year_chosen_name_movies.index, inplace=True)\n",
    "\n",
    "            # remove also the movies release in the frame [-5 years, +5 years] of the top1_year\n",
    "            chosen_name_movies_insign_df.query(f'year < {insign_i_year - 5} or year > {insign_i_year + 5}', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special case for a single name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given name by user\n",
    "chosen_name = 'elizabeth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the movie containing the chosen name\n",
    "chosen_name_movies_df = name_by_movie_with_info.loc[chosen_name, :].copy(deep=True)\n",
    "display(chosen_name_movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_name_movies_df.sort_values(by=['slope_change'], inplace=True)\n",
    "chosen_name_movies_top_df = chosen_name_movies_df.query('(slope_change > 0) and (p_value < 0.1)').copy(deep=True)\n",
    "display(chosen_name_movies_top_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the loop to do the computation for top1 to top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_top_movies(chosen_name, chosen_name_movies_top_df, movie_impact_df)\n",
    "\n",
    "display(movie_impact_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_name_movies_bottom_df = chosen_name_movies_df.query('(slope_change <= 0) and (p_value < 0.1)').copy(deep=True)\n",
    "chosen_name_movies_bottom_df.sort_values(by=['slope_change'], ascending=False, inplace=True)\n",
    "display(chosen_name_movies_bottom_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_bottom_movies(chosen_name, chosen_name_movies_bottom_df, movie_impact_df)\n",
    "\n",
    "display(movie_impact_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_chosen_name_movies_df = pd.concat([chosen_name_movies_top_df, chosen_name_movies_bottom_df])\n",
    "chosen_name_movies_insign_df = remaining_chosen_name_movies_df.query('p_value > 0.1').copy(deep=True)\n",
    "chosen_name_movies_insign_df.sort_values(by=['averageRating', 'numVotes'], inplace=True)\n",
    "display(chosen_name_movies_insign_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_insign_movies(chosen_name, chosen_name_movies_insign_df, movie_impact_df)\n",
    "display(movie_impact_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there movie duplicates in the movie_impact_df\n",
    "print(f\"number of duplicates in movie_impact_df : {movie_impact_df.duplicated(subset=['movie_id']).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalize for all the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['henry', 'duke', 'williams', 'sheila', 'arthur', 'leon', 'rick', 'rachael', 'roy', 'bryant', 'sebastian', 'lamarr', 'bart', 'lyle', 'von', 'johnson', 'lili', 'jim', 'dorothy', 'frank', 'jeffrey', 'ben', 'barbara', 'sandy', 'lyndon', 'barry', 'kimberly', 'benny', 'jennifer', 'merrick', 'edward', 'campbell', 'william', 'king', 'princess', 'robert', 'wallace', 'bruce', 'isabelle', 'james', 'alexander', 'gordon', 'vicki', 'harvey', 'alfred', 'robin', 'max', 'ivy', 'wilson', 'grayson', 'chase', 'eric', 'jerry', 'charles', 'leland', 'mary', 'herbert', 'raymond', 'susan', 'foster', 'walter', 'carter', 'emily', 'norton', 'lien', 'may', 'jade', 'master', 'sir', 'bo', 'yu', 'jennie', 'sybil', 'harold', 'lindsay', 'sam', 'aubrey', 'andrew', 'elliott', 'lionel', 'jack', 'general', 'major', 'johann', 'scott', 'cheryl', 'marion', 'alice', 'victor', 'nick', 'lee', 'tania', 'ed', 'jake', 'joe', 'bobby', 'annie', 'laura', 'fiona', 'tom', 'scarlett', 'david', 'matthew', 'henrietta', 'gerald', 'carrie', 'gareth', 'antonio', 'emmy', 'miki', 'fred', 'tommy', 'gwen', 'dane', 'guy', 'kwan', 'jason', 'heather', 'chandler', 'ram', 'kelly', 'dean', 'pauline', 'kurt', 'peter', 'veronica', 'dawson', 'stan', 'mandy', 'gregory', 'brian', 'harry', 'giovanni', 'charlie', 'michael', 'tony', 'teresa', 'mario', 'dennis', 'tim', 'patsy', 'matthews', 'kathy', 'hart', 'karen', 'gracie', 'louise', 'betty', 'camilla', 'adam', 'coco', 'rita', 'vincenzo', 'neal', 'jimmy', 'dwight', 'mallory', 'wayne', 'gale', 'mickey', 'london', 'delmar', 'george', 'homer', 'penny', 'nelson', 'teague', 'everett', 'pete', 'augusta', 'russell', 'julia', 'jordan', 'billy', 'luis', 'alan', 'sara', 'shirley', 'bob', 'philippe', 'paul', 'paris', 'janet', 'brad', 'rocky', 'joey', 'miller', 'bud', 'otto', 'parnell', 'leila', 'beverly', 'la', 'deanna', 'clark', 'kirk', 'leonard', 'terrell', 'montgomery', 'adrian', 'john', 'wade', 'ryan', 'francis', 'daniel', 'anderson', 'stanley', 'jackson', 'richard', 'henderson', 'irwin', 'timothy', 'willie', 'catherine', 'pam', 'sally', 'franklin', 'brandt', 'theodore', 'maude', 'donald', 'special', 'carla', 'mason', 'ernest', 'baxter', 'paxton', 'patrick', 'elaine', 'robinson', 'claire', 'carl', 'vernon', 'allison', 'betsy', 'iris', 'travis', 'clarice', 'martin', 'ruth', 'crawford', 'frederick', 'trinity', 'smith', 'cooper', 'judy', 'helen', 'barbra', 'ventura', 'kyle', 'ginger', 'matt', 'reese', 'connor', 'sarah', 'julie', 'jill', 'hamilton', 'cole', 'kathryn', 'jody', 'jude', 'darren', 'vincent', 'grey', 'malcolm', 'anna', 'lynn', 'brooks', 'andy', 'diamond', 'ellis', 'hadley', 'boyd', 'blair', 'geri', 'massimo', 'steve', 'edison', 'westley', 'prince', 'montoya', 'sharon', 'alvin', 'rose', 'bernardo', 'chris', 'britt', 'stephen', 'alison', 'nancy', 'ransom', 'eve', 'denise', 'elijah', 'price', 'audrey', 'joseph', 'tyler', 'eddie', 'gunther', 'ted', 'carson', 'bill', 'anthony', 'mike', 'ronald', 'parker', 'fitzgerald', 'emmett', 'anders', 'marianne', 'amanda', 'jess', 'marie', 'wellington', 'louis', 'cindy', 'watson', 'pat', 'javier', 'manolo', 'ayala', 'francisco', 'ray', 'carlos', 'caroline', 'seth', 'montel', 'eduardo', 'arturo', 'helena', 'rodriguez', 'sanchez', 'oswald', 'long', 'shaw', 'liz', 'clay', 'garrison', 'susie', 'andrews', 'lou', 'ivon', 'ruby', 'norman', 'malky', 'jenny', 'dan', 'young', 'buford', 'forrest', 'taylor', 'curran', 'benjamin', 'margo', 'green', 'angel', 'holly', 'phyllis', 'buck', 'cass', 'al', 'milly', 'jan', 'cassidy', 'tracy', 'darian', 'gina', 'rowland', 'morris', 'josh', 'august', 'hisham', 'adele', 'lillian', 'carol', 'ann', 'lane', 'spence', 'holden', 'berlin', 'skylar', 'steffi', 'angelo', 'milton', 'alma', 'judson', 'burke', 'dana', 'don', 'willow', 'terry', 'edie', 'doyle', 'charley', 'johnny', 'katie', 'marla', 'natalie', 'hugo', 'josef', 'irene', 'freeman', 'eugene', 'jerome', 'caesar', 'anton', 'dave', 'stella', 'linda', 'lorraine', 'marty', 'mikhail', 'alexei', 'marshal', 'lawrence', 'ali', 'nate', 'charlene', 'hanna', 'justine', 'neil', 'fran', 'angela', 'buddy', 'carolyn', 'lester', 'hayes', 'berkley', 'ricky', 'dupree', 'kane', 'jane', 'emile', 'zola', 'nino', 'lucien', 'moses', 'troy', 'lexie', 'willy', 'nicki', 'elizabeth', 'billie', 'bettina', 'noland', 'lev', 'ramon', 'peterson', 'chuck', 'nicolai', 'yuri', 'ellie', 'felix', 'queen', 'anne', 'thomas', 'reed', 'shirl', 'gilbert', 'sol', 'tab', 'martha', 'lindsey', 'virgil', 'hortense', 'alexis', 'basil', 'marc', 'clarence', 'randy', 'rex', 'roger', 'maria', 'hillary', 'lara', 'lord', 'bryce', 'west', 'alex', 'luc', 'kate', 'leia', 'luke', 'mace', 'natalia', 'aleksandr', 'calvert', 'molly', 'lewis', 'brock', 'constance', 'albert', 'miguel', 'alicia', 'julius', 'steven', 'marilyn', 'jasmine', 'mitchell', 'oscar', 'truman', 'grace', 'rebecca', 'gianni', 'shelby', 'edmund', 'sofia', 'sera', 'debbie', 'dietrich', 'jones', 'arnold', 'jimmie', 'maynard', 'jules', 'page', 'phillip', 'winston', 'marvin', 'brett', 'mia', 'fabienne', 'butch', 'lance', 'stephanie', 'patrice', 'cleo', 'maurice', 'akeem', 'lisa', 'darryl', 'melina', 'lori', 'douglas', 'anakin', 'verna', 'frankie', 'reagan', 'bernie', 'van', 'katrina', 'lady', 'yvonne', 'blaine', 'kenneth', 'gretchen', 'thurman', 'kitty', 'donnie', 'lilian', 'samantha', 'ross', 'eugenie', 'marco', 'darien', 'larry', 'ernie', 'bailey', 'bert', 'abel', 'melissa', 'margy', 'joyce', 'gideon', 'dorcas', 'liza', 'caleb', 'alyssa', 'jay', 'preston', 'eloise', 'missouri', 'judge', 'blake', 'ginny', 'mimi', 'nora', 'charlotte', 'gabriel', 'jean', 'oliver', 'howard', 'clarissa', 'agatha', 'jeremy', 'bishop', 'arabella', 'nolan', 'marietta', 'betsey', 'dale', 'gladys', 'cornelius', 'bennett', 'vance', 'belle', 'armand', 'dixie', 'lucy', 'judith', 'randall', 'luther', 'powell', 'kay', 'manuela', 'nina', 'marian', 'etta', 'emma', 'barton', 'benson', 'alec', 'jefferson', 'mae', 'lennie', 'dallas', 'erie', 'niles', 'margaret', 'haven', 'dinah', 'dexter', 'keller', 'noah', 'aidan', 'rachel', 'morgan', 'samara', 'henriette', 'marcia', 'hank', 'adair', 'todd', 'honey', 'lenny', 'sonny', 'enzo', 'christiana', 'simon', 'germaine', 'roland', 'ector', 'thatcher', 'jocelyn', 'marcel', 'oskar', 'emilie', 'amon', 'armin', 'hans', 'amy', 'alden', 'mark', 'rob', 'lacey', 'nico', 'delores', 'stewart', 'storm', 'casey', 'gino', 'jennings', 'taft', 'austin', 'grant', 'walker', 'orin', 'annette', 'latrell', 'sasha', 'holland', 'keith', 'louisa', 'wilbur', 'ida', 'evelyn', 'kirby', 'ron', 'isaac', 'laurie', 'curt', 'kit', 'jakie', 'clyde', 'bonnie', 'blanche', 'ivan', 'salim', 'aziz', 'annabelle', 'gray', 'sean', 'thornton', 'myrtle', 'dolly', 'prentice', 'christina', 'duncan', 'jessica', 'kirsty', 'merrill', 'graham', 'colleen', 'gerard', 'gabrielle', 'hunter', 'lehman', 'fritz', 'aloysius', 'clara', 'kendall', 'tina', 'raheem', 'vito', 'lola', 'rufus', 'wyatt', 'enrique', 'rosa', 'roderick', 'arden', 'aura', 'kent', 'chester', 'cleopatra', 'frieda', 'hercules', 'magdalene', 'jesus', 'geary', 'starr', 'jonas', 'percy', 'colby', 'mildred', 'will', 'hartwell', 'murphy', 'mollie', 'beck', 'zeb', 'jeb', 'cleve', 'jethro', 'dora', 'stuart', 'linus', 'sherman', 'prescott', 'ramsey', 'theodora', 'miles', 'becky', 'archibald', 'layton', 'lars', 'vaughn', 'christine', 'ellen', 'jacy', 'duane', 'marlow', 'lois', 'waldo', 'hardy', 'davis', 'connie', 'yale', 'alonzo', 'esther', 'truett', 'trudy', 'norval', 'modesta', 'jolly', 'brown', 'granville', 'clementine', 'angelica', 'godfrey', 'cornelia', 'lina', 'kemp', 'delbert', 'linnea', 'opal', 'pearl', 'gay', 'otis', 'katy', 'carmine', 'birdie', 'harper', 'willa', 'sterling', 'jeff', 'kathie', 'meta', 'fletcher', 'terrill', 'jamie', 'marquise', 'sue', 'dolores', 'leo', 'allen', 'buzz', 'garth', 'gil', 'bradley', 'irving', 'ethan', 'samuel', 'clayton', 'vic', 'marcy', 'shane', 'desmond', 'norma', 'gillis', 'sidney', 'jacqui', 'april', 'dorsey', 'madeleine', 'gavin', 'dutch', 'freddie', 'marlowe', 'craig', 'mabel', 'margot', 'anita', 'berta', 'ronnie', 'eleanor', 'leopold', 'evans', 'antoine', 'therese', 'bernadette', 'bridget', 'hilton', 'colonel', 'deborah', 'cassandra', 'stacy', 'christian', 'benedict', 'polly', 'dudley', 'doris', 'ophelia', 'virginia', 'nathan', 'burdette', 'che', 'dick', 'monique', 'karl', 'eli', 'trey', 'lizzie', 'rochelle', 'teddy', 'ace', 'vince', 'vern', 'de', 'viola', 'ned', 'hugh', 'philip', 'sloane', 'ferris', 'jeanie', 'cameron', 'gillian', 'abbie', 'gary', 'frances', 'antonia', 'kylie', 'mikey', 'ibn', 'mel', 'lucille', 'humphrey', 'adeline', 'millie', 'flo', 'rosemary', 'hal', 'leslie', 'webster', 'eileen', 'lloyd', 'cullen', 'ella', 'ernst', 'haywood', 'winifred', 'levy', 'conrad', 'cain', 'greg', 'cecile', 'clifford', 'phil', 'zack', 'cristal', 'carey', 'samir', 'joanna', 'kevin', 'derek', 'augusto', 'diego', 'pablo', 'mirtha', 'dwayne', 'franco', 'gennaro', 'diana', 'tonya', 'alexandra', 'link', 'walt', 'bethany', 'juliet', 'porter', 'sandra', 'earl', 'danny', 'roosevelt', 'thompson', 'rafe', 'alain', 'pierre', 'tatiana', 'olga', 'nicholas', 'jeanine', 'nigel', 'bobbi', 'payne', 'turner', 'mitch', 'gus', 'quincy', 'monroe', 'miriam', 'horatio', 'gertrude', 'dante', 'justice', 'brodie', 'randal', 'chrissy', 'missy', 'cash', 'paula', 'adelle', 'drew', 'gentry', 'doug', 'woody', 'ahmed', 'garfield', 'elliot', 'kip', 'geoffrey', 'clifton', 'katharine', 'hana', 'chad', 'faye', 'del', 'dolan', 'horace', 'logan', 'tex', 'erich', 'saul', 'jeannette', 'erica', 'patti', 'bernard', 'cyril', 'leona', 'reuben', 'rae', 'lynne', 'apollo', 'maggie', 'diane', 'murray', 'dionne', 'cher', 'amber', 'tai', 'ashton', 'madeline', 'dakota', 'thelma', 'marshall', 'darcy', 'gigi', 'erin', 'steele', 'jeannine', 'calvin', 'jarrett', 'beth', 'loretta', 'kendal', 'galvin', 'jaime', 'aurora', 'garrett', 'glenn', 'wally', 'mac', 'edna', 'elias', 'hannah', 'tatum', 'riley', 'kenny', 'persephone', 'jewel', 'reginald', 'aaron', 'clive', 'dawn', 'ronny', 'susanna', 'mick', 'oren', 'tess', 'daisy', 'dalton', 'perry', 'karin', 'sadie', 'christy', 'rolando', 'jensen', 'adams', 'harrison', 'meyer', 'delilah', 'davey', 'donna', 'slade', 'lucas', 'flora', 'ada', 'jad', 'clarke', 'lamar', 'evanna', 'monica', 'ralph', 'buster', 'ken', 'lovell', 'gene', 'sy', 'elinor', 'fanny', 'christopher', 'brandon', 'avery', 'rod', 'tyson', 'laurel', 'sylvia', 'cecil', 'susannah', 'melvin', 'jackie', 'spencer', 'star', 'bracken', 'pierce', 'duc', 'guido', 'eliseo', 'lowell', 'liane', 'luca', 'meredith', 'isobel', 'lavinia', 'denton', 'rupert', 'victoria', 'archie', 'jenner', 'isabel', 'cathy', 'judd', 'lanie', 'tomas', 'ezra', 'eduard', 'andie', 'sutton', 'muriel', 'emery', 'frazier', 'lincoln', 'selena', 'farrell', 'claude', 'maximilian', 'jameson', 'jonah', 'vanessa', 'donovan', 'brent', 'nova', 'marcus', 'beatrice', 'harmon', 'reva', 'kim', 'rodney', 'yvette', 'juanita', 'georgia', 'jonathan', 'gustav', 'damian', 'miranda', 'ward', 'vivian', 'willard', 'tiffany', 'eden', 'kathleen', 'patricia', 'nathaniel', 'terence', 'rudy', 'roman', 'ian', 'justin', 'chang', 'louie', 'kirsten', 'pepper', 'mattie', 'milo', 'gregor', 'deirdre', 'jeanne', 'pasquale', 'antonietta', 'norris', 'hilda', 'vladimir', 'rand', 'kirkland', 'burt', 'megan', 'ajay', 'jared', 'zan', 'quinn', 'bunny', 'sumner', 'courtney', 'cal', 'glover', 'mathieu', 'drake', 'sonya', 'renard', 'valentin', 'edgar', 'cyrus', 'angie', 'keaton', 'stevens', 'theresa', 'marlon', 'hayden', 'julian', 'janelle', 'carmen', 'tuan', 'richie', 'elwood', 'sunny', 'danielle', 'cady', 'leigh', 'peggy', 'celia', 'pearce', 'lydia', 'mack', 'ike', 'toby', 'sully', 'nixon', 'melinda', 'vaughan', 'althea', 'arlo', 'jessie', 'dewey', 'hope', 'floyd', 'margie', 'evan', 'glen', 'davina', 'stacey', 'della', 'myron', 'rubin', 'hattie', 'emmet', 'willem', 'sade', 'marquis', 'abbe', 'hoyt', 'belinda', 'muhammad', 'chauncey', 'cassius', 'angus', 'jasper', 'jeffery', 'ingrid', 'salvatore', 'booker', 'doreen', 'glenda', 'donnell', 'eva', 'amelia', 'lila', 'mai', 'bertram', 'bartlett', 'blythe', 'theo', 'weston', 'pamela', 'valerie', 'howell', 'bayley', 'stone', 'brennan', 'katherine', 'damien', 'hudson', 'myra', 'warren', 'mohamed', 'martinez', 'bradford', 'raquel', 'marjorie', 'anastasia', 'tyrone', 'donny', 'keeley', 'wilfred', 'adriana', 'elgin', 'cruz', 'amir', 'gloria', 'delano', 'lin', 'cliff', 'wilma', 'barney', 'cortez', 'gregorio', 'julio', 'silvia', 'cecilia', 'luisa', 'eugenia', 'amos', 'roxie', 'augustus', 'caitlin', 'flynn', 'velma', 'sunshine', 'michele', 'romy', 'romeo', 'paolo', 'rico', 'bella', 'madison', 'dayton', 'renee', 'candace', 'tully', 'barrett', 'janine', 'angelina', 'nell', 'morrison', 'clemmie', 'hayward', 'eddy', 'serge', 'irma', 'gerry', 'lena', 'luigi', 'seymour', 'mackenzie', 'annalee', 'christie', 'perez', 'sabra', 'dillon', 'chan', 'jamal', 'lulu', 'nicolo', 'georges', 'brenda', 'marley', 'ursula', 'sylvie', 'wendy', 'layla', 'ty', 'tod', 'rivers', 'chaney', 'webb', 'owen', 'lily', 'washington', 'ollie', 'clair', 'raleigh', 'royal', 'suzy', 'wanda', 'elsie', 'ashley', 'celeste', 'roberta', 'jeannie', 'tate', 'curtis', 'shawn', 'charleston', 'ludwig', 'blain', 'lawson', 'melanie', 'dorothea', 'claudia', 'thurston', 'solomon', 'simeon', 'meryl', 'lauren', 'nicole', 'robbie', 'le', 'joshua', 'trish', 'elisabeth', 'russel', 'sydney', 'tricia', 'joan', 'brandi', 'rene', 'shannon', 'wendel', 'jed', 'willis', 'ally', 'coleman', 'baylor', 'mitchel', 'secret', 'robie', 'val', 'shelley', 'holt', 'bambi', 'candy', 'nadia', 'michelle', 'cadence', 'felicity', 'gilda', 'edith', 'jesse', 'celine', 'zoe', 'chaz', 'shelly', 'palmer', 'heath', 'santos', 'lula', 'dell', 'dominic', 'tran', 'edwin', 'tanner', 'violet', 'juliette', 'barret', 'coy', 'bronson', 'egan', 'elsa', 'erik', 'pascal', 'dieter', 'lorna', 'seamus', 'sanders', 'dylan', 'houston', 'selma', 'janie', 'frida', 'antony', 'bruno', 'morton', 'cody', 'emmanuel', 'libby', 'gill', 'marnie', 'bernice', 'daryl', 'toni', 'lilly', 'hezekiah', 'hester', 'baron', 'phoebe', 'sid', 'manny', 'omar', 'elvira', 'chi', 'dmitri', 'natalya', 'boris', 'xenia', 'raj', 'simran', 'marcela', 'abby', 'scotty', 'julianne', 'tucker', 'magda', 'hector', 'baker', 'decker', 'gail', 'devlin', 'suzanne', 'janice', 'mariana', 'declan', 'andrea', 'lambert', 'gia', 'paulette', 'cy', 'vy', 'park', 'hanson', 'aron', 'dianne', 'pryce', 'ricki', 'delia', 'misty', 'anabel', 'boy', 'raja', 'nellie', 'kiri', 'allegra', 'milan', 'vera', 'elle', 'sofie', 'beatrix', 'chico', 'stanton', 'elvin', 'rogers', 'dixon', 'dustin', 'jo', 'allan', 'laurence', 'meg', 'matilda', 'maury', 'hansel', 'kala', 'chadwick', 'ritchie', 'baby', 'marybeth', 'gabe', 'zeke', 'valjean', 'lora', 'wells', 'carver', 'kira', 'sky', 'nana', 'chet', 'breeze', 'deidre', 'larson', 'channing', 'mona', 'cora', 'blaire', 'collins', 'charlton', 'neville', 'archer', 'emilio', 'marino', 'abraham', 'mina', 'manning', 'michel', 'nada', 'corwin', 'knox', 'sullivan', 'rance', 'harlen', 'trent', 'tremain', 'freddy', 'jon', 'newton', 'herman', 'maxine', 'tami', 'sammy', 'vickie', 'wes', 'regina', 'brody', 'len', 'art', 'kasper', 'alisa', 'skip', 'griffin', 'june', 'grover', 'braxton', 'dusty', 'corinne', 'sanford', 'lex', 'brice', 'rhonda', 'harris', 'trina', 'sinclair', 'brigitte', 'mauricio', 'colin', 'christ', 'orlando', 'lucia', 'nikita', 'rudi', 'maverick', 'zane', 'bret', 'cynthia', 'terri', 'nash', 'avram', 'gracey', 'cherry', 'ralston', 'nicolette', 'simone', 'kingsley', 'suzette', 'ma', 'boone', 'sheryl', 'bianca', 'chastity', 'christiane', 'ariane', 'elena', 'priya', 'arlene', 'chapman', 'tej', 'dirk', 'lacy', 'joscelyn', 'monty', 'wolf', 'kaylee', 'marin', 'cage', 'viktor', 'yelena', 'xander', 'liana', 'lorelei', 'jock', 'lorenzo', 'constantine', 'destiny', 'nikki', 'suzie', 'patty', 'rusty', 'aman', 'chesney', 'cort', 'josephine', 'denver', 'estrella', 'sapphire', 'dottie', 'valentine', 'mindy', 'esperanza', 'stevie', 'ruthie', 'romero', 'tanya', 'shaun', 'juan', 'inga', 'sheridan', 'aileen', 'corey', 'moira', 'serena', 'warner', 'callahan', 'brooke', 'maxwell', 'emil', 'andre', 'jamieson', 'samson', 'jacob', 'reena', 'richmond', 'stanford', 'santa', 'rolf', 'franz', 'lupe', 'dario', 'junior', 'christin', 'felice', 'ilse', 'marta', 'nyah', 'ambrose', 'selene', 'lucian', 'erika', 'damone', 'maribel', 'kayleigh', 'kagan', 'blane', 'iona', 'rosie', 'quentin', 'carlotta', 'angelique', 'emory', 'phillipe', 'gaston', 'etienne', 'harlan', 'tawny', 'nicolas', 'devi', 'cohen', 'maximillian', 'devine', 'annabeth', 'brendan', 'ford', 'hilary', 'hansen', 'frederic', 'brianna', 'ariel', 'cristina', 'noel', 'brady', 'evie', 'joy', 'timmy', 'evette', 'deacon', 'blade', 'jenson', 'hubert', 'pace', 'olivia', 'sheldon', 'annemarie', 'alexa', 'prentiss', 'nyssa', 'fox', 'lucius', 'henri', 'tramell', 'garner', 'keane', 'felicia', 'mitzi', 'ezekiel', 'fatima', 'roel', 'fausto', 'dominique', 'nathalie', 'mara', 'aurelia', 'jodi', 'shavonne', 'jayne', 'serra', 'river', 'tam', 'vikram', 'lucky', 'byron', 'matilde', 'guillermo', 'alejandro', 'filippo', 'philippa', 'remington', 'abdullah', 'remy', 'rocco', 'davidson', 'dwan', 'adolphus', 'rainey', 'randolph', 'giles', 'mei', 'rodrigo', 'hobie', 'gibson', 'gypsy', 'kandy', 'kristen', 'barclay', 'misha', 'ignacio', 'chong', 'debby', 'joel', 'burton', 'fulton', 'michaela', 'ana', 'reynolds', 'kamal', 'les', 'lana', 'gardner', 'haley', 'jaye', 'calder', 'staci', 'zachary', 'phoenix', 'earle', 'alfredo', 'paola', 'bobbie', 'jezebel', 'elspeth', 'athena', 'georgie', 'garland', 'larkin', 'maple', 'marvel', 'cherie', 'ibrahim', 'clarisse', 'jeremiah', 'maureen', 'kamran', 'kara', 'maya', 'selina', 'thayer', 'whitney', 'regan', 'lamont', 'roxanne', 'trevor', 'colton', 'anjali', 'rahul', 'rohan', 'ronna', 'clinton', 'sherri', 'stefan', 'carolina', 'rosina', 'rohit', 'cedar', 'owens', 'darci', 'millard', 'camden', 'catarina', 'lindy', 'curry', 'holli', 'hannibal', 'reba', 'hallie', 'jolie', 'darling', 'bridger', 'eliot', 'franky', 'robby', 'sonia', 'nisha', 'carmella', 'carlson', 'jenna', 'wyman', 'brant', 'octavius', 'rosalie', 'kiki', 'tad', 'rosalee', 'casper', 'gussie', 'gannon', 'kennedy', 'cassie', 'elder', 'cantrell', 'renaldo', 'cordell', 'loren', 'wilhelm', 'raine', 'aldo', 'wynter', 'paige', 'kermit', 'laine', 'hollis', 'werner', 'kelson', 'angeline', 'liyah', 'emerald', 'shari', 'jeanette', 'rudolph', 'jimi', 'walton', 'tito', 'mari', 'russ', 'tan', 'isabella', 'tristan', 'greta', 'tia', 'marcie', 'tyrell', 'durrell', 'minerva', 'igor', 'maxime', 'cedric', 'alberto', 'harriet', 'kyra', 'luna', 'draco', 'reno', 'sawyer', 'isak', 'jobe', 'chavez', 'rory', 'dessie', 'phelan', 'sloan', 'carlyle', 'josiah', 'enrico', 'sultan', 'zinnia', 'rajan', 'dee', 'bree', 'nashawn', 'norbert', 'axel', 'josie', 'darby', 'priscilla', 'caine', 'pernell', 'sophie', 'emiliano', 'josefa', 'colt', 'pedro', 'hazel', 'silvano', 'atlanta', 'lexi', 'xavier', 'tobias', 'tammy', 'charly', 'aline', 'rhoda', 'enos', 'denny', 'dina', 'rianne', 'taryn', 'malik', 'deja', 'brogan', 'nikolai', 'nicky', 'abigail', 'marko', 'leticia', 'aisha', 'rich', 'cale', 'rafael', 'love', 'luiz', 'early', 'noelle', 'wren', 'avi', 'guinevere', 'lancelot', 'garnett', 'dimitri', 'rina', 'graydon', 'kia', 'parrish', 'reggie', 'ravi', 'vijay', 'reilly', 'caprice', 'susana', 'gustavo', 'jorge', 'octavio', 'valeria', 'jacobo', 'daphne', 'jacoby', 'wesley', 'han', 'charisse', 'eldon', 'noreen', 'luciano', 'shay', 'tabitha', 'johnnie', 'mariella', 'millicent', 'lafayette', 'gretta', 'marlee', 'wendell', 'melody', 'kana', 'glory', 'lace', 'benton', 'wei', 'debra', 'isis', 'torrance', 'jewell', 'krystyna', 'sinead', 'india', 'carly', 'asher', 'franklyn', 'bryan', 'woodrow', 'kristi', 'penelope', 'ramey', 'asia', 'vivienne', 'bessie', 'bess', 'midori', 'alfonso', 'mortimer', 'roxy', 'bennie', 'patience', 'armando', 'chloe', 'filomena', 'maris', 'talia', 'wiley', 'tripp', 'kramer', 'kaye', 'finn', 'summer', 'sameer', 'karan', 'aryan', 'kiran', 'megha', 'leonardo', 'marguerite', 'jacqueline', 'gustave', 'presley', 'elvis', 'matty', 'fallon', 'hampton', 'darnell', 'brantley', 'ryo', 'klaus', 'dorinda', 'amar', 'shyam', 'karisma', 'tara', 'jai', 'mayer', 'landon', 'tracie', 'poppy', 'lavender', 'cormac', 'gage', 'farrah', 'ren', 'gabby', 'copeland', 'tori', 'edmond', 'vida', 'terrence', 'ethel', 'becca', 'ema', 'napoleon', 'wayland', 'giselle', 'abbey', 'nickie', 'jamison', 'hersh', 'raven', 'levin', 'merle', 'nola', 'erwin', 'abner', 'griffith', 'nicola', 'lainey', 'faith', 'fisher', 'antwone', 'ira', 'graeme', 'hari', 'abi', 'zahra', 'ryder', 'denisha', 'lukas', 'eben', 'dempsey', 'madelyne', 'villa', 'lyman', 'myles', 'elise', 'lazarus', 'deloris', 'sona', 'dion', 'grady', 'ernesto', 'roberto', 'surya', 'mathis', 'dimitrios', 'solange', 'bartholomew', 'darin', 'torrey', 'damon', 'pa', 'minnie', 'courtland', 'aditi', 'ria', 'arlen', 'jocelyne', 'atticus', 'ammon', 'ignatius', 'wolfgang', 'florence', 'vinny', 'dionna', 'darius', 'therman', 'darwin', 'aram', 'collette', 'titus', 'chance', 'lanier', 'brandy', 'zander', 'winnie', 'katarina', 'gunnar', 'shepard', 'savannah', 'bernadine', 'heidi', 'jericho', 'cosmo', 'carlton', 'matai', 'tal', 'dejah', 'gonzalo', 'silvana', 'patricio', 'juana', 'francesca', 'elmo', 'andrey', 'rani', 'lonnie', 'davy', 'carole', 'sabin', 'shelton', 'felton', 'brok', 'bowen', 'an', 'galen', 'nguyen', 'delila', 'blanca', 'esteban', 'saber', 'conan', 'kerry', 'calley', 'agnes', 'addison', 'shade', 'rain', 'briggs', 'jin', 'kallen', 'sherry', 'cherish', 'hung', 'telly', 'ocean', 'seward', 'juliano', 'rhett', 'harley', 'sanjay', 'laney', 'sampson', 'temple', 'leonora', 'olive', 'shayne', 'leroy', 'addie', 'trixie', 'traci', 'rainer', 'irena', 'shaila', 'katerina', 'emanuel', 'ivory', 'cloe', 'cheri', 'alpha', 'delta', 'echo', 'laurent', 'ulysses', 'enid', 'joanne', 'paulina', 'ronaldo', 'estelle', 'teri', 'alistair', 'anson', 'dwain', 'rosalind', 'antoinette', 'amit', 'gregg', 'wardell', 'kinsey', 'augustin', 'camille', 'arjun', 'akira', 'yuki', 'garry', 'marek', 'sabine', 'petra', 'martel', 'taj', 'wilder', 'pearson', 'sergio', 'shaina', 'laramie', 'cathryn', 'idris', 'demetrius', 'musa', 'lake', 'kelley', 'danica', 'misaki', 'roslyn', 'kalina', 'lennox', 'odin', 'graciela', 'errol', 'ava', 'cammi', 'jamaal', 'norah', 'una', 'alexia', 'eunice', 'malick', 'naomi', 'kiernan', 'natasha', 'mercy', 'cleon', 'quan', 'kimball', 'emerson', 'stoney', 'linden', 'leah', 'chesley', 'tristen', 'gifford', 'niko', 'sissy', 'georgianna', 'chandra', 'lynda', 'miya', 'mateo', 'mathilde', 'benji', 'akbar', 'lolita', 'chas', 'hennessy', 'nita', 'phillips', 'bryon', 'khan', 'sumer', 'annabel', 'olaf', 'carin', 'kansas', 'langston', 'mose', 'vita', 'indiana', 'irina', 'joanie', 'mordechai', 'tatyana', 'giovanna', 'talley', 'wil', 'bertha', 'fenton', 'merritt', 'saleem', 'tariq', 'alessandro', 'soledad', 'martine', 'cammy', 'francine', 'elmer', 'flor', 'triton', 'rome', 'marge', 'kayley', 'berry', 'blue', 'ryker', 'cinderella', 'huey', 'darik', 'judah', 'halley', 'murad', 'valentina', 'pooja', 'nikhil', 'jacques', 'carlo', 'rosanna', 'italia', 'timoteo', 'callie', 'hobart', 'carlissa', 'carsen', 'madolyn', 'collier', 'greer', 'annalise', 'arnell', 'coulter', 'lyra', 'serafina', 'marisa', 'sabrina', 'inez', 'lisbeth', 'dino', 'velvet', 'francie', 'peyton', 'abe', 'conway', 'ashby', 'elma', 'chanel', 'katey', 'silas', 'mister', 'kamen', 'manuel', 'kenyon', 'gabriella', 'jana', 'anil', 'deaundre', 'boyce', 'marcello', 'marina', 'akash', 'shalini', 'angelika', 'zak', 'wynn', 'sabian', 'kingston', 'reece', 'germain', 'passion', 'martino', 'braden', 'hussein', 'ferdinand', 'rosemarie', 'reeves', 'liam', 'rona', 'biff', 'lottie', 'nestor', 'ramona', 'silver', 'winter', 'cutter', 'riggs', 'raul', 'nichols', 'clint', 'dorian', 'parris', 'leonna', 'shoshana', 'krysta', 'cyndi', 'abilene', 'zora', 'marquez', 'cesar', 'bentley', 'julien', 'janey', 'hagen', 'parish', 'kristy', 'marcella', 'rickey', 'hawk', 'henrik', 'johan', 'teal', 'giuseppe', 'malakai', 'arya', 'helene', 'kenton', 'sapna', 'seema', 'little', 'carleton', 'robyn', 'rosetta', 'eula', 'johanna', 'thaddius', 'nan', 'joaquin', 'claudio', 'hill', 'rock', 'lashawn', 'ennis', 'aarti', 'aditya', 'suraj', 'waylon', 'tobin', 'nils', 'cleveland', 'story', 'butler', 'alana', 'monte', 'donavan', 'magnolia', 'keisha', 'hollie', 'fay', 'lorry', 'yolanda', 'deane', 'budd', 'thor', 'madge', 'cary', 'rhea', 'mihir', 'flint', 'alva', 'sunday', 'tory', 'beckett', 'cutler', 'estela', 'geraldine', 'nettie', 'consuelo', 'genevieve', 'kareem', 'royce', 'ender', 'hyrum', 'sonja', 'merlin', 'claudine', 'letha', 'gerson', 'benito', 'augustina', 'svetlana', 'raphael', 'cosette', 'mitra', 'gian', 'sun', 'piero', 'sylvester', 'shereen', 'nasia', 'maura', 'isha', 'alisha', 'lilli', 'slater', 'charli', 'midge', 'shy', 'vicky', 'rowena', 'queenie', 'noble', 'dann', 'chelsea', 'mansi', 'rehan', 'hasan', 'ila', 'gisela', 'cory', 'georgina', 'kabir', 'sheena', 'lakshmi', 'felipe', 'radha', 'niki', 'astrid', 'karla', 'sarita', 'ishmael', 'nels', 'china', 'elly', 'chantal', 'edwina', 'eris', 'langdon', 'tonny', 'caspian', 'oakley', 'breck', 'harmony', 'shah', 'ishaan', 'leanne', 'golden', 'saran', 'rishi', 'dev', 'sarina', 'ania', 'cassady', 'sophia', 'lucinda', 'pasha', 'fischer', 'benigno', 'dahlia', 'keri', 'lexy', 'gaylord', 'garcia', 'roscoe', 'iesha', 'dani', 'aramis', 'cris', 'wisdom', 'kalman', 'marisol', 'esmeralda', 'kamala', 'sharma', 'jakob', 'milena', 'avinash', 'yves', 'clare', 'patton', 'blakeley', 'roma', 'adolph', 'artis', 'carlisle', 'bilal', 'cade', 'krishna', 'jerri', 'farris', 'davian', 'amonte', 'devon', 'berk', 'kisha', 'wilton', 'veronique', 'yang', 'thaddeus', 'lan', 'hai', 'sandro', 'maryann', 'katya', 'conner', 'thunder', 'kee', 'jarrell', 'sunil', 'raoul', 'mayo', 'gautam', 'saeed', 'farah', 'neha', 'danish', 'job', 'aaliya', 'josey', 'brook', 'ezekial', 'loc', 'wali', 'mansoor', 'paloma', 'vishnu', 'allie', 'morey', 'glyn', 'marcos', 'abdul', 'khalil', 'saleh', 'rey', 'brittany', 'taras', 'ellison', 'jillian', 'evalyn', 'raychel', 'kale', 'kenji', 'shanta', 'deedee', 'darlene', 'coley', 'marsha', 'delroy', 'maddie', 'mikaela', 'lyla', 'medford', 'keegan', 'rider', 'blaze', 'allyson', 'manfred', 'johny', 'tish', 'estella', 'terra', 'gabriela', 'rowan', 'bliss', 'lorne', 'dax', 'tor', 'ari', 'sahara', 'shepherd', 'rayne', 'francesco', 'lennon', 'wagner', 'alston', 'starla', 'torrence', 'seven', 'ephraim', 'bennet', 'andreas', 'colvin', 'randa', 'pia', 'jarvis', 'fidel', 'janis', 'gaspar', 'chung', 'tin', 'kunal', 'cammie', 'yasmin', 'dashiell', 'brenner', 'gemma', 'artie', 'gao', 'montana', 'hagan', 'nasir', 'arash', 'mohammed', 'vann', 'derrick', 'lilah', 'jacey', 'jani', 'golda', 'meir', 'darrell', 'merrie', 'aviva', 'alessa', 'leonidas', 'theron', 'cornell', 'kary', 'duran', 'hale', 'bebe', 'beau', 'daly', 'puneet', 'siddharth', 'montez', 'fergus', 'sonali', 'akshay', 'esha', 'preeti', 'vivek', 'neale', 'amin', 'lenore', 'irby', 'murrell', 'zach', 'orville', 'magdalena', 'christoph', 'amjad', 'aparna', 'siobhan', 'sondra', 'ricardo', 'gaby', 'augustine', 'chantel', 'elyse', 'lew', 'elton', 'rivka', 'lanny', 'nikos', 'tea', 'lalita', 'manu', 'conor', 'sheba', 'ka', 'fern', 'hartley', 'kaela', 'regis', 'purvis', 'parthenia', 'female', 'shivani', 'lucie', 'maida', 'fabian', 'kelby', 'lea', 'deke', 'nadine', 'dominick', 'kajal', 'harland', 'bristol', 'daley', 'marylin', 'liliana', 'zoey', 'carlito', 'ming', 'chantelle', 'divya', 'geoff', 'griffen', 'crystal', 'shruti', 'peaches', 'rafi', 'tesla', 'alley', 'mala', 'shanna', 'dov', 'micah', 'malcom', 'mercedes', 'marlina', 'karthik', 'camryn', 'illeana', 'lise', 'stavros', 'iverson', 'livia', 'radley', 'carley', 'kerrigan', 'sarika', 'markus', 'marlin', 'elli', 'vi', 'delphine', 'ryu', 'damani', 'piper', 'herschel', 'clancy', 'jarius', 'rainy', 'stryker', 'kayla', 'khaled', 'swati', 'vishal', 'lang', 'laila', 'andrei', 'banks', 'rashid', 'eamonn', 'austen', 'eliza', 'son', 'majid', 'anya', 'beulah', 'renata', 'pavel', 'sahil', 'nafisa', 'tora', 'evangeline', 'obadiah', 'nikolaus', 'ahmad', 'orianna', 'arne', 'carlyn', 'jamilla', 'coral', 'nahum', 'collin', 'renato', 'marques', 'marni', 'reid', 'quinlan', 'sanjana', 'joni', 'arif', 'flavia', 'darla', 'scotti', 'anuj', 'rees', 'carroll', 'tanvi', 'darrel', 'jodie', 'sabre', 'elroy', 'jud', 'odette', 'jordana', 'santiago', 'kemper', 'shanti', 'carlin', 'indra', 'layne', 'macy', 'vidal', 'ofelia', 'anmol', 'ebenezer', 'kristoff', 'electra', 'juvenal', 'lilith', 'keoni', 'navin', 'hazen', 'lynette', 'nelly', 'giulia', 'madonna', 'vada', 'geronimo', 'simona', 'girard', 'seiji', 'edsel', 'auburn', 'rajiv', 'marianna', 'liberty', 'jordy', 'rahim', 'tasha', 'emmanuelle', 'cara', 'adina', 'claudette', 'kwame', 'arline', 'meghan', 'shana', 'autumn', 'lamia', 'santo', 'schuyler', 'randle', 'henery', 'tinsley', 'gavino', 'shimon', 'kerwin', 'deena', 'raina', 'genie', 'tillie', 'tierney', 'kaisa', 'britney', 'case', 'tessa', 'ying', 'adela', 'hailey', 'ozzie', 'morrell', 'zia', 'tyne', 'saxon', 'barron', 'ismael', 'bay', 'mila', 'oleg', 'shauna', 'francois', 'omer', 'lorena', 'mendy', 'marci', 'lemuel', 'burns', 'cecelia', 'robertson', 'marcelle', 'callum', 'dozier', 'jarod', 'kalen', 'adelina', 'patric', 'faron', 'sharif', 'bette', 'jonny', 'effie', 'audra', 'leva', 'joleen', 'siri', 'sal', 'asha', 'gaurav', 'min', 'daya', 'bradlee', 'lissa', 'kenya', 'lorenz', 'sabina', 'raghav', 'jia', 'malini', 'rodgers', 'sharice', 'israel', 'henna', 'nazareth', 'zachariah', 'alam', 'latrelle', 'delaney', 'ayesha', 'brinn', 'gable', 'claudius', 'valery', 'memory', 'kelsi', 'america', 'reema', 'keenan', 'kelsey', 'marti', 'clem', 'charis', 'valdemar', 'vivien', 'burnett', 'attila', 'dody', 'pieter', 'demon', 'usher', 'brighton', 'adrienne', 'lilliana', 'pierson', 'ilana', 'asa', 'doc', 'krishan', 'arun', 'abbas', 'kavita', 'portia', 'zakaria', 'monet', 'asif', 'skye', 'ely', 'mamie', 'andi', 'thomasine', 'prem', 'santana', 'marlo', 'barrington', 'anand', 'tejas', 'rana', 'layna', 'carrigan', 'brevin', 'gretel', 'gaye', 'dia', 'nabil', 'sunni', 'salina', 'concetta', 'janina', 'nessa', 'kristie', 'sagar', 'jose', 'neel', 'sherard', 'juliana', 'hayley', 'imran', 'cleophus', 'meena', 'ashish', 'contessa', 'iva', 'ewell', 'maudie', 'chyna', 'leander', 'tobey', 'olin', 'dugan', 'mustapha', 'corbett', 'anneliese', 'jacky', 'nisa', 'desiree', 'salome', 'keefer', 'melonie', 'lazaro', 'reinaldo', 'clement', 'tamara', 'friedrich', 'jalal', 'marcellus', 'winthrop', 'dian', 'tracey', 'rebeka', 'valeri', 'quincey', 'kelvin', 'odell', 'tien', 'agustina', 'audry', 'sami', 'fabrice', 'skyla', 'leda', 'veda', 'kwesi', 'sunita', 'rajesh', 'caterina', 'varun', 'lanna', 'arianna', 'sneha', 'sergei', 'helga', 'brain', 'maren', 'wylie', 'narissa', 'tremaine', 'weldon', 'harlow', 'aishwarya', 'leann', 'sakina', 'rama', 'langley', 'garrick', 'severin', 'harman', 'chazz', 'imaan', 'dona', 'jarret', 'stafford', 'saundra', 'ilsa', 'einar', 'imelda', 'magali', 'richardson', 'empress', 'fleming', 'terrance', 'drey', 'columbus', 'chanda', 'reymond', 'stevenson', 'laverne', 'juniper', 'kelli', 'tylar', 'danika', 'nona', 'kennard', 'lory', 'fernando', 'nehemiah', 'vinson', 'laird', 'sherwood', 'jacinto', 'waverly', 'yvan', 'danyelle', 'elissa', 'carmel', 'kenzie', 'orrin', 'byrd', 'rutherford', 'alverna', 'abie', 'eleanore', 'alim', 'paulo', 'said', 'remi', 'nevada', 'piotr', 'malerie', 'christa', 'cam', 'shiva', 'jun', 'emmit', 'starlene', 'mathew', 'adler', 'dena', 'hogan', 'faiz', 'thad', 'emme', 'lon', 'rollie', 'nandini', 'amada', 'vadim', 'radhika', 'sandhya', 'bela', 'vittoria', 'windy', 'kai', 'margery', 'chana', 'tenley', 'mikal', 'candida', 'omega', 'faris', 'maricella', 'jelena', 'anwar', 'meghana', 'precious', 'malissa', 'johannes', 'tung', 'scarlet', 'hala', 'chancellor', 'brittney', 'kris', 'karly', 'spirit', 'prudence', 'cissy', 'edson', 'fuad', 'oswaldo', 'erskine', 'ruben', 'cecily', 'tiger', 'lian', 'hong', 'riva', 'deepak', 'rush', 'denis', 'kerri', 'kei', 'winslow', 'amina', 'ashraf', 'mohammad', 'bauer', 'emmitt', 'carrol', 'hellen', 'mavis', 'riccardo', 'garvin', 'blaise', 'leeanne', 'valentino', 'lilia', 'jerrold', 'jansen', 'mathias', 'hassan', 'vinnie', 'nikolas', 'corina', 'socrates', 'khadija', 'mohit', 'levi', 'abram', 'ganesh', 'salman', 'shruthi', 'komal', 'blossom', 'herbie', 'tessie', 'lino', 'cherise', 'durward', 'yan', 'creed', 'priyanka', 'joycelyn', 'lanisha', 'pilar', 'alia', 'kaya', 'gerardo', 'ronda', 'corrine', 'clovis', 'mills', 'luan', 'tallulah', 'payton', 'nella', 'marya', 'alek', 'carlie', 'vinay', 'jonnie', 'colette', 'rudolf', 'colbie', 'arin', 'kalin', 'federico', 'gayle', 'september', 'corky', 'jonothan', 'trisha', 'caden', 'carolyne', 'tru', 'alonso', 'lourdes', 'bonita', 'perla', 'deni', 'trinidad', 'merry', 'deion', 'aiden', 'waldemar', 'meera', 'ames', 'nihal', 'amrita', 'adolf', 'whitman', 'olympia', 'cordelia', 'mira', 'autry', 'shadow', 'roby', 'farley', 'fatma', 'sana', 'lyda', 'archana', 'yuka', 'indira', 'serina', 'race', 'freedom', 'kailey', 'neena', 'aimee', 'brynn', 'karel', 'freya', 'kainan', 'trinh', 'cally', 'france', 'mahogany', 'rosy', 'hurley', 'nika', 'marleen', 'inger', 'hilliard', 'yi', 'krish', 'haider', 'kristina', 'corie', 'wright', 'marissa', 'vignesh', 'arian', 'kiley', 'landis', 'joi', 'daytona', 'duron', 'aida', 'dimitris', 'callan', 'sacha', 'sania', 'rakesh', 'karyn', 'drayton', 'ash', 'manon', 'jarrod', 'kenan', 'aide', 'mariann', 'darlena', 'nathanial', 'akram', 'krista', 'mirza', 'kincade', 'shera', 'ole', 'arlin', 'petar', 'osman', 'travers', 'sierra', 'tino', 'matthias', 'bridgette', 'amalia', 'doran', 'landry', 'diva', 'zelda', 'winfield', 'joachim', 'niels', 'hanne', 'norberto', 'baltazar', 'bubba', 'deva', 'racine', 'kishan', 'susanne', 'carola', 'megumi', 'dagny', 'taggart', 'alyson', 'khalid', 'sigrid', 'pandora', 'marius', 'akasha', 'macon', 'melville', 'sharron', 'san', 'roque', 'guthrie', 'snow', 'jermaine', 'carline', 'avni', 'pao', 'sheilah', 'cross', 'zara', 'pallavi', 'alvah', 'colson', 'lyon', 'verne', 'sanam', 'soraya', 'farid', 'martina', 'rolland', 'abhay', 'ritika', 'vinh', 'gisella', 'moshe', 'percival', 'rosalia', 'quin', 'giulio', 'kasi', 'tillman', 'margarita', 'mallika', 'joon', 'vernell', 'shilo', 'ebba', 'giacomo', 'alexandria', 'legend', 'adama', 'porfirio', 'adaline', 'german', 'easton', 'wheeler', 'bassam', 'hani', 'alba', 'llewellyn', 'mariette', 'sonam', 'ernestina', 'corrie', 'sarrah', 'ai', 'abhishek', 'naseem', 'cordero', 'dewayne', 'luz', 'rogelio', 'bedford', 'goldie', 'darrin', 'anahita', 'kimmy', 'kianna', 'micky', 'swetha', 'janette', 'rima', 'youssef', 'connell', 'babe', 'talmadge', 'pascale', 'jacki', 'ilona', 'flossie', 'marna', 'ciara', 'dori', 'kali', 'adel', 'mariam', 'misa', 'zev', 'lyn', 'jordon', 'laureen', 'cristobal', 'ester', 'pietro', 'reshma', 'pinkie', 'shivam', 'aaliyah', 'dovid', 'shan', 'haden', 'swathi', 'tianna', 'durell', 'louella', 'sandeep', 'riya', 'lauryn', 'meghna', 'amara', 'yash', 'yahya', 'risa', 'easter', 'florentino', 'anushka', 'deven', 'brianne', 'basilio', 'joana', 'mert', 'stockton', 'macklin', 'moody', 'letty', 'erickson', 'akemi', 'nadir', 'miri', 'payal', 'jolene', 'kendrick', 'kasia', 'zoran', 'amira', 'liv', 'shadrach', 'amaryllis', 'mateus', 'noam', 'elisha', 'ramiro', 'earnest', 'garnet', 'ansel', 'cindi', 'preet', 'suzanna', 'lu', 'alton', 'sigmund', 'charity', 'jory', 'marlena', 'randi', 'jennefer', 'ola', 'mya', 'lazar', 'alexandre', 'ranger', 'zena', 'howie', 'artur', 'whitley', 'uri', 'fareed', 'brielle', 'dory', 'abelardo', 'ruperto', 'venessa', 'mariko', 'cisco', 'hussain', 'madhav', 'katharina', 'tee', 'zeth', 'sirena', 'clayborn', 'glendon', 'caitlyn', 'cesario', 'cari', 'andra', 'delfino', 'georgiana', 'rochel', 'janita', 'maxim', 'morgana', 'daryll', 'baily', 'linsey', 'loki', 'manav', 'hennessey', 'mandi', 'mazie', 'miley', 'tamar', 'velda', 'karim', 'klara', 'louden', 'adelaide', 'walid', 'noor', 'zaid', 'branden', 'matias', 'ethlyn', 'shaye', 'mckay', 'cayce', 'trenton', 'jerrod', 'lizzy', 'hays', 'jaya', 'selby', 'cathleen', 'margaux', 'jannelle', 'celene', 'alberta', 'tyree', 'kristian', 'salma', 'adan', 'chandni', 'orion', 'spring', 'denzel', 'zana', 'hall', 'raffi', 'cartier', 'rosita', 'karma', 'avril', 'newman', 'sister', 'priest', 'keene', 'harding', 'vittorio', 'benoit', 'barbie', 'masha', 'esme', 'finnegan', 'gilman', 'nat', 'hamid', 'mireya', 'corliss', 'andreia', 'trace', 'marlene', 'barrie', 'eldridge', 'haris', 'kincaid', 'madden', 'creighton', 'venus', 'stephan', 'lia', 'elana', 'ami', 'wilford', 'roshni', 'ripley', 'henley', 'reyes', 'salvador', 'chip', 'gaines', 'toy', 'lucile', 'alla', 'daniele', 'lona', 'daniella', 'rosaura', 'kari', 'tiny', 'melvyn', 'guilherme', 'maud', 'asael', 'hamza', 'dayne', 'bethel', 'sita', 'brie', 'epiphany', 'ivonne', 'kieran', 'destry', 'karine', 'abu', 'zoya', 'frantz', 'hildegarde', 'bertrand', 'gisele', 'isidoro', 'krzysztof', 'sven', 'dorianne', 'rayford', 'conley', 'nazir', 'vikas', 'fernanda', 'malachi', 'leonid', 'garet', 'akiko', 'eleni', 'marika', 'tommaso', 'aspen', 'erna', 'najma', 'britton', 'karina', 'ilene', 'yousef', 'aakash', 'menno', 'sahir', 'fabio', 'trudie', 'rosario', 'benita', 'reyna', 'gertie', 'jonathon', 'zainab', 'tarek', 'jagger', 'geneva', 'leandro', 'newell', 'tevin', 'hubbard', 'hermann', 'livingston', 'jens', 'adrien', 'crispin', 'jubal', 'katara', 'marilena', 'yusuf', 'ramone', 'hao', 'katlyn', 'ozzy', 'edy', 'mercer', 'ramzy', 'rifka', 'mendel', 'kamil', 'samar', 'cydney', 'xia', 'elie', 'stefanos', 'ekaterina', 'colm', 'linn', 'mehak', 'aamir', 'carina', 'devika', 'mika', 'charisma', 'sahra', 'ayaan', 'omid', 'andersen', 'orson', 'mathilda', 'janna', 'jeet', 'griselda', 'malone', 'kolton', 'thea', 'farhan', 'palma', 'essie', 'azalea', 'korey', 'takiya', 'lolly', 'konrad', 'katia', 'viraj', 'shasta', 'ballard', 'letitia', 'elwin', 'jabbar', 'moussa', 'malachy', 'sarabeth', 'jalan', 'ayla', 'kedar', 'genaro', 'nitin', 'ina', 'prophet', 'becker', 'veronika', 'minda', 'ricci', 'chiara', 'hedy', 'rekha', 'frederica', 'cate', 'aleta', 'lillie', 'judit', 'elbert', 'geno', 'tisha', 'ela', 'danton', 'margareta', 'uma', 'martell', 'nitya', 'jedediah', 'senora', 'emilia', 'haskell', 'drexel', 'french', 'jasmin', 'keira', 'shamus', 'jemma', 'shad', 'shmuel', 'lorrie', 'mable', 'marcelino', 'carmelo', 'holmes', 'kaitlin', 'sallie', 'ariadne', 'dayna', 'amal', 'kimi', 'lei', 'nandita', 'prithvi', 'achilles', 'mervin', 'paulino', 'tye', 'jemima', 'susy', 'lucienne', 'sherrie', 'osborne', 'lorie', 'aissa', 'shawna', 'sulaiman', 'celso', 'josette', 'mikkel', 'evelyne', 'vangie', 'kennan', 'nikko', 'danni', 'maryjane', 'tao', 'margarete', 'tala', 'leyla', 'oz', 'stefanie', 'farren', 'daena', 'johnie', 'marwan', 'sinan', 'billi', 'alvaro', 'gwyneth', 'sharan', 'edi', 'tonie', 'roshan', 'mackay', 'catriona', 'kristoffer', 'delmas', 'tre', 'milburn', 'daniela', 'tabatha', 'aamna', 'lem', 'taja', 'alta', 'amer', 'winona', 'elisa', 'sheela', 'renzo', 'maja', 'jamey', 'keefe', 'coltrane', 'zakir', 'freda', 'elektra', 'jazz', 'aurelio', 'manisha', 'niall', 'rudolfo', 'rosaria', 'veta', 'ivana', 'yoko', 'hally', 'teodoro', 'konstantinos', 'rea', 'juli', 'kimber', 'sailor', 'malka', 'magnus', 'rosalinda', 'caitlynn', 'brinda', 'vilma', 'mariano', 'salem', 'suzi', 'brooklyn', 'kassie', 'quinton', 'ivey', 'tomi', 'veer', 'natale', 'pascual', 'zeus', 'vivianne', 'cecilio', 'aleksey', 'stratton', 'theophilus', 'dodie', 'hendrick', 'davide', 'lesley', 'carmela', 'betti', 'hanif', 'margherita', 'pervis', 'maddy', 'waylen', 'killian', 'aldrich', 'tennyson', 'malin', 'polo', 'zahraa', 'sayra', 'blakelee', 'carmelina', 'pattie', 'mica', 'gerrit', 'khaliq', 'myrna', 'heinz', 'ric', 'satya', 'cassy', 'destin', 'heaven', 'andromeda', 'hiram', 'nena', 'hardin', 'corbin', 'ziggy', 'gershon', 'sachin', 'alf', 'florrie', 'castor', 'selwyn', 'carissa', 'francisca', 'christophe', 'harald', 'leonie', 'bretton', 'buren', 'hermine', 'mustafa', 'olivier', 'marielle', 'naveen', 'kessler', 'amaya', 'peng', 'cardell', 'naina', 'atlas', 'kendra', 'tonia', 'issa', 'kimberley', 'mayme', 'rena', 'albino', 'elia', 'mauro', 'madigan', 'johanne', 'cristy', 'sable', 'rawley', 'mikael', 'gaia', 'ivette', 'tadd', 'inge', 'wilmer', 'sandi', 'stephane', 'laurin', 'lavelle', 'roseanna', 'lita', 'jett', 'scottie', 'lela', 'saya', 'hettie', 'phylis', 'dre', 'maeve', 'orla', 'gatlin', 'muna', 'fadi', 'gena', 'sander', 'kavya', 'aldrin', 'syed', 'santina', 'lidia', 'shanaya', 'clotilde', 'carman', 'saba', 'maryanne', 'deniz', 'lysander', 'phaedra', 'arlette', 'pavan', 'canyon', 'lark', 'farrel', 'aziza', 'gwyn', 'arlington', 'treshawn', 'izaak', 'lucio', 'melton', 'egbert', 'kyndra', 'montie', 'princeton', 'mont', 'gorman', 'wilburn', 'annika', 'pansy', 'fannie', 'madelon', 'lotus', 'lawton', 'brayson', 'can', 'medina', 'alexi', 'dennison', 'stacie', 'semaj', 'dhruv', 'heyward', 'lawyer', 'curley', 'elmira', 'elden', 'isaiah', 'syrena', 'jomar', 'dalia', 'dagen', 'didier', 'mireille', 'alina', 'rosamaria', 'om', 'tareq', 'jameelah', 'yasmeen', 'quaid', 'siddhartha', 'galina', 'elka', 'yosef', 'saffron', 'kiara', 'kristine', 'yola', 'wynne', 'rickie', 'albany', 'rodrick', 'lenin', 'celestina', 'aleksandra', 'camila', 'blakely', 'cipriano', 'nia', 'melba', 'shai', 'aoife', 'kirra', 'lachlan', 'marita', 'shama', 'bernhard', 'amie', 'davie', 'ashwin', 'edoardo', 'rivkah', 'perrin', 'kurtis', 'steward', 'brigid', 'messiah', 'rasheen', 'colter', 'julieta', 'bjorn', 'ashlee', 'armond', 'leola', 'adon', 'shreya', 'deep', 'ainsley', 'bonny', 'talena', 'noora', 'aniket', 'stetson', 'marva', 'mannie', 'malina', 'elodie', 'adi', 'lucretia', 'corin', 'cason', 'nicol', 'iram', 'caius', 'armaan', 'suri', 'lida', 'ariana', 'veena', 'eleazar', 'nadiya', 'eamon', 'meng', 'bowden', 'muskan', 'sivan', 'dow', 'leena', 'axl', 'suhani', 'alford', 'amrit', 'marija', 'melford', 'bell', 'shea', 'enoch', 'avon', 'hildegard', 'filip', 'candice', 'ashlynn', 'ridley', 'deana', 'britta', 'dasan', 'judas', 'gladis', 'abdel', 'sari', 'sage', 'dodge', 'katja', 'hutton', 'rajveer', 'maire', 'oona', 'finley', 'lelia', 'karrie', 'diamante', 'delvin', 'briana', 'annmarie', 'milla', 'kaden', 'brannen', 'penney', 'nyla', 'yasmine', 'merri', 'cannon', 'deshawn', 'westin', 'jacie', 'aadil', 'cesare', 'nikola', 'tiara', 'mattia', 'domenico', 'soloman', 'samarth', 'marylou', 'paradise', 'bao', 'tilly', 'nima', 'laszlo', 'sravya', 'ginnie', 'mystique', 'alois', 'aili', 'nidhi', 'carli', 'palmira', 'keiron', 'nawal', 'theresia', 'steel', 'loyd', 'lovely', 'cheyenne', 'nadya', 'dot', 'latif', 'kamel', 'yahia', 'sajid', 'bane', 'mariela', 'lizbet', 'wayman', 'kush', 'wendall', 'devin', 'chetan', 'ewan', 'tian', 'zenobia', 'micheline', 'tadhg', 'maher', 'habib', 'kailani', 'francene', 'damir', 'nerissa', 'hagop', 'vicente', 'aggie', 'ginette', 'armon', 'selden', 'goldy', 'joao', 'nader', 'aleksandar', 'xian', 'beryl', 'heinrich', 'karsten', 'keshav', 'anthea', 'bronwyn', 'whit', 'auden', 'safiyah', 'daimon', 'saskia', 'peg', 'ishika', 'sheikh', 'neva', 'galia', 'markie', 'darrien', 'harlin', 'tula', 'seneca', 'maha', 'stefania', 'kenia', 'jaxx', 'haydon', 'beatriz', 'enola', 'alicja', 'hughes', 'charolette', 'aadam', 'sinai', 'scout', 'samira', 'eliezer', 'uriel', 'takumi', 'colman', 'ottilie', 'arvind', 'nishi', 'gauri', 'riana', 'nicolle', 'param', 'azucena', 'florian', 'krystal', 'manson', 'leopoldo', 'bertie', 'bryer', 'reina', 'ajla', 'sergey', 'hamish', 'cloey', 'aris', 'nila', 'jak', 'yoni', 'desi', 'hermione', 'delwyn', 'kaito', 'kadee', 'dade', 'yuvraj', 'kaiser', 'kerstin', 'mehmet', 'maisie', 'stormy', 'lettie', 'manpreet', 'marli', 'carys', 'lainee', 'dara', 'anusha', 'aiko', 'hakim', 'nyle', 'paisley', 'niharika', 'leonor', 'lofton', 'kartik', 'raza', 'tae', 'sharla', 'yoav', 'keiko', 'kolt', 'lenora', 'mackinley', 'yana', 'maki', 'bina', 'colbert', 'rice', 'dagmar', 'sparkle', 'violeta', 'canton', 'sherrod', 'ahmet', 'mehdi', 'qasim', 'rogan', 'niklas', 'violetta', 'meenakshi', 'abhi', 'domingo', 'katina', 'ashleigh', 'ronit', 'romina', 'verena', 'deon', 'shirin', 'arora', 'meher', 'lam', 'khoi', 'yann', 'avalon', 'dotty', 'vega', 'gilmore', 'carmelita', 'maye', 'arielle', 'tarissa', 'kristin', 'leela', 'edgardo', 'stryder', 'kenner', 'donato', 'giovana', 'romana', 'aki', 'nikolay', 'sienna', 'alanna', 'lynnette', 'pari', 'malia', 'maguire', 'madalena', 'ave', 'kamila', 'evita', 'geraldo', 'elio', 'adelaida', 'rodolfo', 'orchid', 'amador', 'josefina', 'rosendo', 'auguste', 'drayke', 'darrow', 'glennon', 'aslan', 'dima', 'alix', 'signe', 'elif', 'bram', 'verona', 'doria', 'charmaine', 'malek', 'zelma', 'carlina']\n",
      "Number of names : 4620\n"
     ]
    }
   ],
   "source": [
    "# get all the names in the name_by_movie_with_info dataframe\n",
    "names = name_by_movie_with_info.index.get_level_values(0).unique().tolist()\n",
    "print(names)\n",
    "print(f\"Number of names : {len(names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of name treated: 4619\r"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for name in names:\n",
    "    print(f\"Number of name treated: {iter}\", end='\\r', flush=True)\n",
    "    # get the movie containing the chosen name\n",
    "    chosen_name_movies_df = name_by_movie_with_info.loc[name, :].copy(deep=True)\n",
    "\n",
    "    # sort the movies by slope_change, get movies with significant p_value and positive slope_change and compute the top 5\n",
    "    chosen_name_movies_df.sort_values(by=['slope_change'], inplace=True)\n",
    "    chosen_name_movies_top_df = chosen_name_movies_df.query('(slope_change > 0) and (p_value < 0.1)').copy(deep=True)\n",
    "    # display(chosen_name_movies_top_df)\n",
    "    compute_top_movies(name, chosen_name_movies_top_df, chosen_name_movies_df, movie_impact_df)\n",
    "\n",
    "    # sort the movies by slope_change, get movies with significant p_value and negative slope_change and compute the bottom 5\n",
    "    chosen_name_movies_bottom_df = chosen_name_movies_df.query('(slope_change <= 0) and (p_value < 0.1)').copy(deep=True)\n",
    "    chosen_name_movies_bottom_df.sort_values(by=['slope_change'], ascending=False, inplace=True)\n",
    "    compute_bottom_movies(name, chosen_name_movies_bottom_df, chosen_name_movies_df, movie_impact_df)\n",
    "\n",
    "    # get the remaining movies and filter to keep only the insignificant ones and compute the insign 5\n",
    "    # remaining_chosen_name_movies_df = pd.concat([chosen_name_movies_top_df, chosen_name_movies_bottom_df])\n",
    "    chosen_name_movies_insign_df = chosen_name_movies_df.query('p_value > 0.1').copy(deep=True)\n",
    "    chosen_name_movies_insign_df.sort_values(by=['averageRating', 'numVotes'], inplace=True)\n",
    "    compute_insign_movies(name, chosen_name_movies_insign_df, movie_impact_df)\n",
    "    \n",
    "    iter = iter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th>group_year</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6138</th>\n",
       "      <td>gideon</td>\n",
       "      <td>i</td>\n",
       "      <td>1993</td>\n",
       "      <td>11471094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13401</th>\n",
       "      <td>nicolas</td>\n",
       "      <td>i</td>\n",
       "      <td>2002</td>\n",
       "      <td>2563837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15885</th>\n",
       "      <td>conway</td>\n",
       "      <td>i</td>\n",
       "      <td>2005</td>\n",
       "      <td>2891096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14420</th>\n",
       "      <td>charly</td>\n",
       "      <td>i</td>\n",
       "      <td>1998</td>\n",
       "      <td>27894922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18114</th>\n",
       "      <td>landis</td>\n",
       "      <td>i</td>\n",
       "      <td>2003</td>\n",
       "      <td>23470870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14282</th>\n",
       "      <td>carlyle</td>\n",
       "      <td>i</td>\n",
       "      <td>1983</td>\n",
       "      <td>19250997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18921</th>\n",
       "      <td>keefe</td>\n",
       "      <td>i</td>\n",
       "      <td>1982</td>\n",
       "      <td>20917102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9885</th>\n",
       "      <td>laurel</td>\n",
       "      <td>i</td>\n",
       "      <td>2006</td>\n",
       "      <td>23961694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>michael</td>\n",
       "      <td>t</td>\n",
       "      <td>1938</td>\n",
       "      <td>62111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>kurt</td>\n",
       "      <td>t</td>\n",
       "      <td>2009</td>\n",
       "      <td>28386410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name status  group_year  movie_id\n",
       "6138    gideon      i        1993  11471094\n",
       "13401  nicolas      i        2002   2563837\n",
       "15885   conway      i        2005   2891096\n",
       "14420   charly      i        1998  27894922\n",
       "18114   landis      i        2003  23470870\n",
       "14282  carlyle      i        1983  19250997\n",
       "18921    keefe      i        1982  20917102\n",
       "9885    laurel      i        2006  23961694\n",
       "1729   michael      t        1938     62111\n",
       "1583      kurt      t        2009  28386410"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# movie_impact_df.set_index(['name', 'status'], inplace=True)\n",
    "display(movie_impact_df.sample(10))\n",
    "\n",
    "# Export DataFrame to a CSV file in the processed data folder\n",
    "# movie_impact_df.reset_index(drop=True).sort_values(by=['name', 'status']).to_csv(os.path.join(processed_website_data_folder, 'movie_impact.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import `movie_impact` dataframe to avoid timeconsuming computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group_year</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">henry</th>\n",
       "      <th>t</th>\n",
       "      <td>2009</td>\n",
       "      <td>3213691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>2009</td>\n",
       "      <td>5016250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>2009</td>\n",
       "      <td>29446866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>1933</td>\n",
       "      <td>73488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>1933</td>\n",
       "      <td>73375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doria</th>\n",
       "      <th>i</th>\n",
       "      <td>1955</td>\n",
       "      <td>36348682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charmaine</th>\n",
       "      <th>i</th>\n",
       "      <td>2010</td>\n",
       "      <td>36478252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>malek</th>\n",
       "      <th>i</th>\n",
       "      <td>2011</td>\n",
       "      <td>36563324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zelma</th>\n",
       "      <th>i</th>\n",
       "      <td>1939</td>\n",
       "      <td>36598217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carlina</th>\n",
       "      <th>i</th>\n",
       "      <td>2012</td>\n",
       "      <td>37196243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19542 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  group_year  movie_id\n",
       "name      status                      \n",
       "henry     t             2009   3213691\n",
       "          t             2009   5016250\n",
       "          t             2009  29446866\n",
       "          t             1933     73488\n",
       "          t             1933     73375\n",
       "...                      ...       ...\n",
       "doria     i             1955  36348682\n",
       "charmaine i             2010  36478252\n",
       "malek     i             2011  36563324\n",
       "zelma     i             1939  36598217\n",
       "carlina   i             2012  37196243\n",
       "\n",
       "[19542 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import the movie_impact_df to avoid the time-consuming computation of movie_impact_df\n",
    "imported_movie_impact_df = pd.read_csv(os.path.join(processed_website_data_folder, 'movie_impacts.csv'))\n",
    "imported_movie_impact_df.set_index(['name', 'status'], inplace=True)\n",
    "display(imported_movie_impact_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `name` column contains NaN values.\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in the name column\n",
    "contains_nan = imported_movie_impact_df.reset_index()['name'].isna().any()\n",
    "\n",
    "if contains_nan:\n",
    "    print(\"The `name` column contains NaN values.\")\n",
    "else:\n",
    "    print(\"The `name` column does not contain NaN values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of imported_movie_impact_df before dropping NaN values : 19542\n",
      "Length of imported_movie_impact_df after dropping NaN values : 19538\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>group_year</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">henry</th>\n",
       "      <th>t</th>\n",
       "      <td>2009</td>\n",
       "      <td>3213691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>2009</td>\n",
       "      <td>5016250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>2009</td>\n",
       "      <td>29446866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>1933</td>\n",
       "      <td>73488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>1933</td>\n",
       "      <td>73375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doria</th>\n",
       "      <th>i</th>\n",
       "      <td>1955</td>\n",
       "      <td>36348682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charmaine</th>\n",
       "      <th>i</th>\n",
       "      <td>2010</td>\n",
       "      <td>36478252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>malek</th>\n",
       "      <th>i</th>\n",
       "      <td>2011</td>\n",
       "      <td>36563324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zelma</th>\n",
       "      <th>i</th>\n",
       "      <td>1939</td>\n",
       "      <td>36598217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carlina</th>\n",
       "      <th>i</th>\n",
       "      <td>2012</td>\n",
       "      <td>37196243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19538 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  group_year  movie_id\n",
       "name      status                      \n",
       "henry     t             2009   3213691\n",
       "          t             2009   5016250\n",
       "          t             2009  29446866\n",
       "          t             1933     73488\n",
       "          t             1933     73375\n",
       "...                      ...       ...\n",
       "doria     i             1955  36348682\n",
       "charmaine i             2010  36478252\n",
       "malek     i             2011  36563324\n",
       "zelma     i             1939  36598217\n",
       "carlina   i             2012  37196243\n",
       "\n",
       "[19538 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# drop NaN values in the name column\n",
    "print(f\"Length of imported_movie_impact_df before dropping NaN values : {len(imported_movie_impact_df)}\")\n",
    "imported_movie_impact_df.reset_index(inplace=True)\n",
    "imported_movie_impact_df.dropna(subset=['name'], inplace=True)\n",
    "imported_movie_impact_df.set_index(['name', 'status'], inplace=True)\n",
    "print(f\"Length of imported_movie_impact_df after dropping NaN values : {len(imported_movie_impact_df)}\")\n",
    "\n",
    "display(imported_movie_impact_df)\n",
    "movie_impact_df = imported_movie_impact_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute `name_per_year` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the indexing of name_per_year unique? True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jimmi</th>\n",
       "      <th>1979</th>\n",
       "      <td>0.000184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charleigh</th>\n",
       "      <th>2003</th>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                percentage\n",
       "name      year            \n",
       "Jimmi     1979    0.000184\n",
       "Charleigh 2003    0.001438"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the name_per_year_df : 1903290\n"
     ]
    }
   ],
   "source": [
    "# import the babynames dataframe\n",
    "name_per_year = pd.read_csv(os.path.join(folder_processed_data_path, 'baby_name_df.csv'))\n",
    "name_per_year.drop(columns='number', inplace=True)\n",
    "name_per_year.set_index(['name', 'year'], inplace=True)\n",
    "print(f\"Is the indexing of name_per_year unique? {name_per_year.index.is_unique}\")\n",
    "display(name_per_year.sample(2))\n",
    "print(f\"Length of the name_per_year_df : {len(name_per_year)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>noah</th>\n",
       "      <th>1917</th>\n",
       "      <td>0.010907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cooper</th>\n",
       "      <th>1957</th>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             percentage\n",
       "name   year            \n",
       "noah   1917    0.010907\n",
       "cooper 1957    0.000144"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the name_per_year_df : 1903290\n"
     ]
    }
   ],
   "source": [
    "# round the percentage values to reduce the size of the future csv file for the web\n",
    "name_per_year['percentage'] = name_per_year['percentage'].round(6)\n",
    "\n",
    "# set the names in lowercases\n",
    "name_per_year.reset_index(inplace=True)\n",
    "name_per_year['name'] = name_per_year['name'].str.lower()\n",
    "name_per_year.set_index(['name', 'year'], inplace=True)\n",
    "\n",
    "display(name_per_year.sample(2))\n",
    "print(f\"Length of the name_per_year_df : {len(name_per_year)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the name_per_year_df to keep only the names in the movie_impact_df\n",
    "name_per_year_filtered = name_per_year.loc[movie_impact_df.reset_index()['name'].unique().tolist(), :].copy(deep=True)\n",
    "name_per_year = name_per_year_filtered.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">aadam</th>\n",
       "      <th>1987</th>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.000112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            percentage\n",
       "name  year            \n",
       "aadam 1987    0.000028\n",
       "      1988    0.000028\n",
       "      1993    0.000082\n",
       "      1994    0.000055\n",
       "      1995    0.000056\n",
       "      1996    0.000028\n",
       "      1997    0.000028\n",
       "      1998    0.000112\n",
       "      1999    0.000028\n",
       "      2000    0.000055\n",
       "      2002    0.000193\n",
       "      2003    0.000163\n",
       "      2004    0.000135\n",
       "      2005    0.000054\n",
       "      2006    0.000131"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's sort the dataframe name_per_year to anticipate the ploting\n",
    "name_per_year.sort_values(by=['name', 'year'], inplace=True)\n",
    "display(name_per_year.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the names present in name_per_year dataframe are also present in the name_by_movie dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique names in name_per_year  = 4620\n",
      "Values in name_per_year but not present in name_by_movie:\n",
      "[]\n",
      "Number of names missing  = 0\n"
     ]
    }
   ],
   "source": [
    "# Identify names in name_per_year not present in name_by_movie\n",
    "values_only_in_name_per_year = name_per_year.reset_index()[~name_per_year.reset_index()['name'].isin(name_by_movie_with_info.reset_index()['char_words'])]['name'].unique()\n",
    "\n",
    "print(f\"Number of unique names in name_per_year  = {len(name_per_year.reset_index()['name'].unique())}\")\n",
    "\n",
    "# Display the result\n",
    "print(\"Values in name_per_year but not present in name_by_movie:\")\n",
    "print(values_only_in_name_per_year)\n",
    "print(f\"Number of names missing  = {len(values_only_in_name_per_year)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique names in name_by_movie_with_info  = 4620\n",
      "Values in name_by_movie_with_info but not present in name_per_year:\n",
      "[]\n",
      "Number of names missing  = 0\n"
     ]
    }
   ],
   "source": [
    "# Identify names in name_by_movie not present in name_per_year\n",
    "values_only_in_name_by_movie = name_by_movie_with_info.reset_index()[~name_by_movie_with_info.reset_index()['char_words'].isin(name_per_year.reset_index()['name'])]['char_words'].unique()\n",
    "\n",
    "print(f\"Number of unique names in name_by_movie_with_info  = {len(name_by_movie_with_info.reset_index()['char_words'].unique())}\")\n",
    "\n",
    "# Display the result\n",
    "print(\"Values in name_by_movie_with_info but not present in name_per_year:\")\n",
    "print(values_only_in_name_by_movie)\n",
    "print(f\"Number of names missing  = {len(values_only_in_name_by_movie)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the number of names in the three dataframes in order to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique names in name_per_year = 4620\n",
      "Number of unique names in movie_impact_df = 4620\n",
      "Number of unique names in name_by_movie_with_info = 4620\n"
     ]
    }
   ],
   "source": [
    "# compute how many unique names are there in the dataframes to compare\n",
    "names_in_name_per_year = name_per_year.reset_index()['name'].unique().tolist()\n",
    "print(f\"Number of unique names in name_per_year = {len(names_in_name_per_year)}\")\n",
    "names_in_movie_impact = movie_impact_df.reset_index()['name'].unique().tolist()\n",
    "print(f\"Number of unique names in movie_impact_df = {len(names_in_movie_impact)}\")\n",
    "names_in_name_by_movie_with_info = name_by_movie_with_info.reset_index()['char_words'].unique().tolist()\n",
    "print(f\"Number of unique names in name_by_movie_with_info = {len(names_in_name_by_movie_with_info)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute `movies` dataframe\n",
    "This dataset contains the information relative to the movie given its `wiki_ID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies in movie_impact_df : 10232\n",
      "Number of movies kept in movie_df: 10232\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mov_name</th>\n",
       "      <th>year</th>\n",
       "      <th>votes</th>\n",
       "      <th>rating</th>\n",
       "      <th>poster_url</th>\n",
       "      <th>imdb_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>715207</th>\n",
       "      <td>Sleepaway Camp</td>\n",
       "      <td>1983</td>\n",
       "      <td>36853</td>\n",
       "      <td>6.2</td>\n",
       "      <td>/2XW01n41n0Fi8jSn0ShTRtL0HwM.jpg</td>\n",
       "      <td>tt0086320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8454631</th>\n",
       "      <td>China Moon</td>\n",
       "      <td>1994</td>\n",
       "      <td>7466</td>\n",
       "      <td>6.3</td>\n",
       "      <td>/qt2cjzyRUNuKEliK7p7LCpYAgRW.jpg</td>\n",
       "      <td>tt0109417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mov_name  year  votes  rating  \\\n",
       "wiki_ID                                        \n",
       "715207   Sleepaway Camp  1983  36853     6.2   \n",
       "8454631      China Moon  1994   7466     6.3   \n",
       "\n",
       "                               poster_url    imdb_id  \n",
       "wiki_ID                                               \n",
       "715207   /2XW01n41n0Fi8jSn0ShTRtL0HwM.jpg  tt0086320  \n",
       "8454631  /qt2cjzyRUNuKEliK7p7LCpYAgRW.jpg  tt0109417  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Number of movies in movie_impact_df : {len(movie_impact_df['movie_id'].unique())}\")\n",
    "# keep only the movies in the movie_df that are in the movie_impact_df\n",
    "simplified_movie_df = movie_df.loc[movie_impact_df['movie_id'].unique().tolist(), :].copy(deep=True)\n",
    "print(f\"Number of movies kept in movie_df: {len(simplified_movie_df)}\")\n",
    "\n",
    "# remove useless columns\n",
    "simplified_movie_df.drop(columns=['month', 'revenue'], inplace=True)\n",
    "simplified_movie_df.rename(columns={'averageRating': 'rating', 'numVotes': 'votes', 'IMDB_ID': 'imdb_id'}, inplace=True)\n",
    "\n",
    "display(simplified_movie_df.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the three datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th>group_year</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14886</th>\n",
       "      <td>14886</td>\n",
       "      <td>tara</td>\n",
       "      <td>i</td>\n",
       "      <td>2012</td>\n",
       "      <td>14413223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18999</th>\n",
       "      <td>18999</td>\n",
       "      <td>myrna</td>\n",
       "      <td>i</td>\n",
       "      <td>1969</td>\n",
       "      <td>22288927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index   name status  group_year  movie_id\n",
       "14886  14886   tara      i        2012  14413223\n",
       "18999  18999  myrna      i        1969  22288927"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78780</th>\n",
       "      <td>chris</td>\n",
       "      <td>1958</td>\n",
       "      <td>0.141645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92900</th>\n",
       "      <td>cory</td>\n",
       "      <td>1952</td>\n",
       "      <td>0.001543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name  year  percentage\n",
       "78780  chris  1958    0.141645\n",
       "92900   cory  1952    0.001543"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_ID</th>\n",
       "      <th>mov_name</th>\n",
       "      <th>year</th>\n",
       "      <th>votes</th>\n",
       "      <th>rating</th>\n",
       "      <th>poster_url</th>\n",
       "      <th>imdb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4669</th>\n",
       "      <td>18968628</td>\n",
       "      <td>The Cartier Affair</td>\n",
       "      <td>1984</td>\n",
       "      <td>252</td>\n",
       "      <td>4.9</td>\n",
       "      <td>/vscv4j9kebeYed55nBarhjyPCXf.jpg</td>\n",
       "      <td>tt0087036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4188</th>\n",
       "      <td>229047</td>\n",
       "      <td>Enough</td>\n",
       "      <td>2002</td>\n",
       "      <td>46622</td>\n",
       "      <td>5.7</td>\n",
       "      <td>/w3GZUYczsU9Mlfij9MCEo0OqoQ6.jpg</td>\n",
       "      <td>tt0278435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wiki_ID            mov_name  year  votes  rating  \\\n",
       "4669  18968628  The Cartier Affair  1984    252     4.9   \n",
       "4188    229047              Enough  2002  46622     5.7   \n",
       "\n",
       "                            poster_url    imdb_id  \n",
       "4669  /vscv4j9kebeYed55nBarhjyPCXf.jpg  tt0087036  \n",
       "4188  /w3GZUYczsU9Mlfij9MCEo0OqoQ6.jpg  tt0278435  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Export movie_impact.csv\n",
    "display(movie_impact_df.reset_index().sample(2))\n",
    "movie_impact_df.reset_index(drop=True).to_csv(os.path.join(processed_website_data_folder, 'movie_impacts.csv'), index=False)\n",
    "\n",
    "# Export name_per_year.csv\n",
    "display(name_per_year.reset_index().sample(2))\n",
    "name_per_year.reset_index().to_csv(os.path.join(processed_website_data_folder, 'name_per_year.csv'), index=False)\n",
    "\n",
    "# Export movie.csv\n",
    "display(simplified_movie_df.reset_index().sample(2))\n",
    "simplified_movie_df.reset_index().to_csv(os.path.join(processed_website_data_folder, 'movies.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
