{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> THIS NOTEBOK REQUIRES THE `convert_ids.ipynb` and a good portion of `preprocessing.ipynb` TO BE RAN FIRST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordering Characters in Movies by importance\n",
    "The website [TMDB claims that](https://www.themoviedb.org/bible/movie/59f3b16d9251414f20000003#59f73ca49251416e7100000e) roles for characters are ordered by importance, namely that major roles are always credited before small parts. \n",
    "\n",
    "Let's scrape that data and add that to our dataframe of `name_by_movie_df.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import token from config.py\n",
    "from config import TMDB_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = '../raw_data/'\n",
    "tmp_dir = '../tmp_data/'\n",
    "processed_dir = '../processed_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request setup\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {TMDB_API_TOKEN}\"\n",
    "}\n",
    "\n",
    "def fetch_url(movie_id):\n",
    "    \"\"\"Fetches the url for a given movie ID\"\"\"\n",
    "    url = f\"https://api.themoviedb.org/3/movie/{movie_id}/credits?language=en-US\"\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 577922\n",
    "\n",
    "# Request the pageprops for a page\n",
    "response = requests.get(fetch_url(test_id), headers=headers).json()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ids dataframe\n",
    "external_ids = pd.read_csv(tmp_dir + 'movies_external_ids.csv')\n",
    "display(external_ids.head())\n",
    "\n",
    "# Import name_by_movie dataframe\n",
    "name_by_movie = pd.read_csv(tmp_dir + 'name_by_movie_df.csv')\n",
    "display(name_by_movie.head())\n",
    "\n",
    "# To save time, only consider the tmdb_ids that are in the name_by_movie dataframe\n",
    "tmdb_ids_list = name_by_movie.merge(external_ids, left_on='wiki_ID', right_on='wikipedia_ID')['TMDB_ID'].dropna().astype(int).astype(str).unique()\n",
    "display(tmdb_ids_list.shape)\n",
    "\n",
    "# Set TMDB_ID as index\n",
    "print(f\"Is the TMDB_ID column in external_ids unique? {external_ids['TMDB_ID'].dropna().is_unique}\")\n",
    "lookup_ids = external_ids.dropna(subset=['TMDB_ID']).set_index('TMDB_ID').copy(deep=True)\n",
    "display(lookup_ids.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While running the code below, we realised that there was an overwhelming amounts of uncredited characters indicated by `(uncredited)` in the TMDB data, which didn't have any name. We decided to remove these characters from our analysis, as they would not be useful, to save space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every movie ID (TMDB IDs), request the credits\n",
    "tmp_ids = []\n",
    "tmp_names = []\n",
    "tmp_order = []\n",
    "tmp_gender = []\n",
    "\n",
    "for movie_id, idx in zip(tmdb_ids_list, range(len(tmdb_ids_list))):\n",
    "    # Skip until idx is 15516\n",
    "    if idx < 15516:\n",
    "        continue\n",
    "\n",
    "    # Request\n",
    "    url = fetch_url(movie_id)\n",
    "    response = requests.get(url, headers=headers).json()\n",
    "\n",
    "    # If case doesn't exist, skip\n",
    "    if 'cast' not in response or not response['cast']:\n",
    "        continue    \n",
    "\n",
    "    # Response contains a list called cast, an ordered list of characters by importance\n",
    "    for char in response['cast']:\n",
    "        # If name contains '(uncredited)' or '(voice)', skip\n",
    "        if '(uncredited)' in char['character'] or '(voice)' in char['character']:\n",
    "            continue\n",
    "\n",
    "        # Store values\n",
    "        tmp_ids.append(movie_id)\n",
    "        tmp_names.append(char['character'])\n",
    "        tmp_order.append(char['order'])\n",
    "        tmp_gender.append(char['gender'])\n",
    "\n",
    "    # Prettyyyy progress\n",
    "    clear_output(wait=True)   \n",
    "    print(f\"Finished {idx+1}/{len(tmdb_ids_list)} ({movie_id})\")\n",
    "\n",
    "# Save the credits in a dataframe\n",
    "credits_df = pd.DataFrame({'TMDB_ID': tmp_ids, 'credits': tmp_names, 'order': tmp_order, 'gender': tmp_gender})\n",
    "credits_df['credits'] = credits_df['credits'].str.split() # Split the names into a list by space\n",
    "credits_df = credits_df.explode('credits')\n",
    "display(credits_df)\n",
    "\n",
    "# Save as tmp\n",
    "credits_df.to_csv(tmp_dir + 'credits_tmp_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform some simple processing on the dataset we've just scraped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicate on tmdb_id, credits and gender, but we keep the one that has the lowest order\n",
    "credits_sorted_df = credits_df.sort_values(by='order', ascending=True)\n",
    "credits_cleaned_df = credits_sorted_df.drop_duplicates(subset=['TMDB_ID', 'credits', 'gender'], keep='first').copy(deep=True)\n",
    "display(credits_cleaned_df)\n",
    "\n",
    "# There are roles with gender 0,3 = none, 1 = female, 2 = male\n",
    "display(credits_cleaned_df.groupby('gender').count())\n",
    "\n",
    "# Show how many genders are not 1 or 2\n",
    "print(f\"There are {credits_cleaned_df[(credits_cleaned_df['gender'] != 1) & (credits_cleaned_df['gender'] != 2)].index.shape[0]} roles without any gender equal to 1 or 2\")\n",
    "\n",
    "# Save in tmp\n",
    "credits_cleaned_df.to_csv(tmp_dir + 'credits_gender_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the data with characters dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import credits_df\n",
    "credits_df = pd.read_csv(tmp_dir + 'credits_gender_df.csv')\n",
    "\n",
    "# Plot for fun the top 5 most used character names\n",
    "credits_df['credits'].value_counts().head(10).plot(kind='bar')\n",
    "\n",
    "# There are a lot of titles (officer, doctor, ...) but this is all taken care\n",
    "# of when merging with the name_by_movie dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to merge the credits_df (b) with the name_by_movie (a) dataframe. Matching the character names bits to movie_id is easy. However for the genders it's a bit tricky:\n",
    "- If we have a value M or F in (a), we ideally want to get the data from (b) with the matched gender.\n",
    "    - If we have M in (a) and M in (b), we match that order value\n",
    "    - If we have M in (a) and F in (b), we discard that order value and put NaN\n",
    "- If we have NaN in (a) and either M or F in (b), we match that order value of the one that is lower in order.\n",
    "\n",
    "We first merge the two dataframes through a left join on `movie_id` and `char_words` (the name), ignoring genders and creating all possible combinations.\n",
    "\n",
    "Lets put these rules into code as a `adjust_order` function. It will overwrite the order value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_order(row):\n",
    "    if pd.notna(row['gender_x']) and pd.notna(row['gender_y']):\n",
    "        # If gender is specified in both and matches, keep the order from (b)\n",
    "        if row['gender_x'] == row['gender_y']:\n",
    "            return row['order']\n",
    "        else:\n",
    "            # If gender does not match, set order to NaN = row is not a valid match\n",
    "            return np.nan\n",
    "    elif pd.isna(row['gender_x']):\n",
    "        # If gender is NaN in (a), take the order from (b)\n",
    "        return row['order']\n",
    "    else:\n",
    "        # When gender is missing from our original df, we keep the order regardless of the gender\n",
    "        return row['order']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overwriting the order value will help us eliminate those that we ha overwritten/invalidated, and then we'll remove them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the credits_df genders so that 1 is female, 2 is male, 0 is NaN\n",
    "gender_map = {1: 'F', 2: 'M', 3: np.nan, 0: np.nan}\n",
    "credits_df_gender_mapped = credits_df.copy(deep=True)\n",
    "credits_df_gender_mapped['gender'] = credits_df_gender_mapped['gender'].map(gender_map)\n",
    "\n",
    "# Add the wiki_ID to the credits_df with the help of the lookup table\n",
    "credits_df_wiki_ids = credits_df_gender_mapped.merge(lookup_ids, left_on='TMDB_ID', right_index=True).copy(deep=True)\n",
    "# display(credits_df_wiki_ids)\n",
    "\n",
    "# Merge the credits_df with the name_by_movie dataframe\n",
    "name_with_order = name_by_movie.merge(credits_df_wiki_ids, left_on=['wiki_ID', 'char_words'], right_on=['wikipedia_ID', 'credits'], how='left').copy(deep=True)\n",
    "display(name_with_order)\n",
    "\n",
    "# Adjust the order\n",
    "name_with_order['adjusted_order'] = name_with_order.apply(adjust_order, axis=1)\n",
    "display(name_with_order)\n",
    "\n",
    "# Sort by adjusted order and keep first best occurence of wiki_ID, char_words and gender_x\n",
    "name_with_order_sorted = name_with_order.sort_values(by='adjusted_order')\n",
    "unique_characters = name_with_order_sorted.drop_duplicates(subset=['wiki_ID', 'char_words', 'gender_x'], keep='first')\n",
    "display(unique_characters)\n",
    "\n",
    "# Keep only important comulmns: wiki_ID, char_words, order\n",
    "name_with_order_clean = unique_characters[['wiki_ID', 'char_words', 'order', 'gender_x']].copy(deep=True)\n",
    "name_with_order_clean = name_with_order_clean.sort_values(by='wiki_ID')\n",
    "# rename columns for consistency\n",
    "name_with_order_clean.columns = ['wiki_ID', 'char_words', 'order', 'gender']\n",
    "display(name_with_order_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute how many characters don't have an order\n",
    "print(\"Number of character names with an order: {} out of {} ({:.2f}%)\".format(name_with_order_clean['order'].notna().sum(), name_with_order_clean.shape[0], name_with_order_clean['order'].notna().sum()/name_with_order_clean.shape[0]*100))\n",
    "\n",
    "# Save in processed\n",
    "name_with_order_clean.to_csv(processed_dir + 'name_by_movie_ordered_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "With this extra information, for the rest of this project:\n",
    "- The order of the characters are indicated by a number in the `order` column, which are each relative to one movie.\n",
    "- The lower the `order` value, the more important the characeter, and thus the character's name, are.\n",
    "- Characters with NaN values do not have a particular order, so they should be treated as having an infintely large order value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
